---
title: "2019 Spliceome project: Downstream MAJIQ analysis"
author: "Angel Liang"
date: "09/02/2021"
output: html_document
---

# Set the running environment

## Packages and directories

```{r message=FALSE, warning=FALSE}

library(tidyverse)
library(gtools)
# windowsFonts("Helvetica" = windowsFont("Helvetica"))
library(RColorBrewer)
library(data.table)
data.table::setDTthreads(threads = 48)

library(genefilter)

library(future.apply)
library(furrr)
options(future.globals.maxSize = 1500000000000, future.fork.enable = TRUE)
plan(multicore)
memory.limit(100000)

library(rtracklayer)
library(qualV)

library(ggplot2)
library(kohonen)
library(genefilter)
# library(gplots)
# library(lattice)
# library(svglite)
# library(scales)
library(ComplexHeatmap)
library(dendextend)

library(Seurat)
library(umap)
library(Rtsne)

library(biomaRt)
# ensembl_mart <- useEnsembl(biomart = "ensembl", dataset = "hsapiens_gene_ensembl", version = 98)

library(systemPipeR)
# library(GOstats)
library(PFAM.db)
# library(bc3net)
# 
# library(ggdendro)
# library(Rfast)

vector_experiment_metadata_initial <- c("2019_msc_spliceome", "majiq")

vector_experiment_metadata_main <- vector_experiment_metadata_initial

source_dir <- "/mnt/LTS/projects/2019_hmsc_spliceome/Kassem_OB/analysis_majiq/source/"

star_output_dir <- "/mnt/scratch/2019_hmsc_spliceome/2_STAR/"

majiq_results_dir <- "/mnt/scratch/2019_hmsc_spliceome/3_MAJIQ/"

R_processing_results_dir <- "/mnt/LTS/projects/2019_hmsc_spliceome/Kassem_OB/analysis_majiq/R_processing_results/"

reference_data_dir <- "/mnt/LTS/reference_data/"

if (dir.exists(R_processing_results_dir) == FALSE) {
  dir.create(R_processing_results_dir, recursive = TRUE)
}

vector_timepoints_raw <- c("ud", "6h", "12h", "24h", "3d", "6d", "9d", "12d")
vector_OBseries_timepoints_edited <- c("MSC", "6h", "12h", "1d", "3d", "6d", "9d", "12d")

vector_of_comparisons_final <- read.delim("/mnt/LTS/projects/2019_hmsc_spliceome/Kassem_OB/list_of_timepoint_comparisons_final.txt", sep = "\t", header = FALSE, stringsAsFactors = FALSE) %>% unlist

tibble_ref_gtf_path <- "/mnt/LTS/reference_data/hg38_ensembl_reference/gtf/Homo_sapiens.GRCh38.98.sorted.gtf"

# import the reference and recon GTFs with first/last exon information as well as flaggged NMD info.
tibble_ref_gtf <- rtracklayer::import("/mnt/LTS/reference_data/hg38_ensembl_reference/gtf/Homo_sapiens.GRCh38.98_NMD_PTC_E4.gtf") %>% as_tibble
tibble_recon_gtf <- rtracklayer::import("/mnt/LTS/projects/2019_hmsc_spliceome/Kassem_OB/analysis_NMD_classifier/results/alltimepoints_denovo_reconstructed_stringtiemerged_NMD_PTC_E4.gtf") %>% as_tibble

```

## define functions

### annotate differential exon

```{r}

# FUNCTION to extract the information from matched GTF entries.
# input: a list containing ref + recon GTF entries, a single element of a list of all the matches for each exon.
# things to annotate: gene name, strand, all exons are NMD in the reference GTF, first/last/only exon in reference or recon. GTF
# this function appends to the original table before GTF entry match.

annotate_differential_exon <- function(list_matched_ref_recon_gtf, original_tibble) {
  
  # print(paste("now processing junction number", index))
  
  # DEBUG ######
  
  # list_matched_ref_recon_gtf <- list_gtf_matching_exon_entries[[1]]
  
  ##############
  
  # gene name
  matched_gene_names <- NA
  
  if (nrow(list_matched_ref_recon_gtf[["reference_gtf_match"]]) != 0) {
    
    matched_gene_names <- paste(list_matched_ref_recon_gtf[["reference_gtf_match"]]$gene_name %>% unique, collapse = ",")
    
  }
  
  # transcript name (ref)
  matched_ref_transcript_names <- NA
  
  if (nrow(list_matched_ref_recon_gtf[["reference_gtf_match"]]) != 0) {
    
    matched_ref_transcript_names <- paste(list_matched_ref_recon_gtf[["reference_gtf_match"]]$transcript_id %>% unique, collapse = ",")
    
  }
  
  # transcript name (recon)
  matched_recon_transcript_names <- NA
  
  if (nrow(list_matched_ref_recon_gtf[["reconstructed_gtf_match"]]) != 0) {
    
    matched_recon_transcript_names <- paste(list_matched_ref_recon_gtf[["reconstructed_gtf_match"]]$transcript_id %>% unique, collapse = ",")
    
  }
  
  # KNOWN NMD annotation - reference
  NMD_biotype_reference <- FALSE
  
  if (nrow(list_matched_ref_recon_gtf[["reference_gtf_match"]]) != 0) {
    
    if (all(list_matched_ref_recon_gtf[["reference_gtf_match"]]$transcript_biotype == "nonsense_mediated_decay")) {
      
      NMD_biotype_reference <- TRUE 
      
    }
    
  }
  
  # flagged NMD candidates - reference
  NMD_flagged_ref <- FALSE
  
  if (nrow(list_matched_ref_recon_gtf[["reference_gtf_match"]]) != 0) {
    
    if (all(list_matched_ref_recon_gtf[["reference_gtf_match"]]$NMD_candidate == TRUE)) {
      
      NMD_flagged_ref <- TRUE 
      
    }
    
  } 
  
  # flagged NMD candidates - recon
  NMD_flagged_recon <- FALSE
  
  if (nrow(list_matched_ref_recon_gtf[["reconstructed_gtf_match"]]) != 0) {
    
    if (all(list_matched_ref_recon_gtf[["reconstructed_gtf_match"]]$NMD_candidate == TRUE)) {
      
      NMD_flagged_recon <- TRUE 
      
    }
    
  } 
  
  # PTC-containing exons or poison exon candidates - reference and recon
  poison_exon_candidate_ref <- NA
  poison_exon_candidate_recon <- NA
  
  if (nrow(list_matched_ref_recon_gtf[["reference_gtf_match"]]) != 0) {
    
    poison_exon_candidate_ref_temp <- list_matched_ref_recon_gtf[["reference_gtf_match"]]$poison_exon_candidate %>% unique 
    
    if (any(is.na(poison_exon_candidate_ref_temp)) != TRUE) {
      
      poison_exon_candidate_ref <- TRUE
      
    }
    
  }
  
  if (nrow(list_matched_ref_recon_gtf[["reconstructed_gtf_match"]]) != 0) {
    
    poison_exon_candidate_ref_temp <- list_matched_ref_recon_gtf[["reconstructed_gtf_match"]]$poison_exon_candidate %>% unique 
    
    if (any(is.na(poison_exon_candidate_ref_temp)) != TRUE) {
      
      poison_exon_candidate_recon <- TRUE
      
    }
    
  }
  
  contains_PTC_ref <- NA
  contains_PTC_recon <- NA
  
  if (nrow(list_matched_ref_recon_gtf[["reference_gtf_match"]]) != 0) {
    
    contains_PTC_ref_temp <- list_matched_ref_recon_gtf[["reference_gtf_match"]]$contains_PTC %>% unique 
    
    if (any(is.na(contains_PTC_ref_temp)) != TRUE) {
      
      contains_PTC_ref <- TRUE
      
    }
    
  }
  
  if (nrow(list_matched_ref_recon_gtf[["reconstructed_gtf_match"]]) != 0) {
    
    contains_PTC_recon_temp <- list_matched_ref_recon_gtf[["reconstructed_gtf_match"]]$contains_PTC %>% unique 
    
    if (any(is.na(contains_PTC_recon_temp)) != TRUE) {
      
      contains_PTC_recon <- TRUE
      
    }
    
  }
  
  # first/last/only exon - reference and recon
  first_or_last_exon_reference <- NA
  
  if (nrow(list_matched_ref_recon_gtf[["reference_gtf_match"]]) != 0) {
    
    first_or_last_exon_reference_temp <- list_matched_ref_recon_gtf[["reference_gtf_match"]]$first_or_last_exon %>% unique 
    
    if (all(is.na(first_or_last_exon_reference_temp)) != TRUE) {
      
      first_or_last_exon_reference <- first_or_last_exon_reference_temp %>% na.omit %>% paste(collapse = ",")
      
    }
    
  }
  
  first_or_last_exon_recon <- NA
  
  if (nrow(list_matched_ref_recon_gtf[["reconstructed_gtf_match"]]) != 0) {
    
    first_or_last_exon_recon_temp <- list_matched_ref_recon_gtf[["reconstructed_gtf_match"]]$first_or_last_exon %>% unique 
    
    if (all(is.na(first_or_last_exon_recon_temp)) != TRUE) {
      
      first_or_last_exon_recon <- first_or_last_exon_recon_temp %>% na.omit %>% paste(collapse = ",")
      
    }
    
  }
  
  return(purrr::splice(original_tibble, 
                       "matched_gene_names" = matched_gene_names,
                       "matched_ref_transcript_names" = matched_ref_transcript_names,
                       "matched_recon_transcript_names" = matched_recon_transcript_names,
                       "NMD_biotype_reference" = NMD_biotype_reference,
                       "NMD_flagged_ref" = NMD_flagged_ref,
                       "NMD_flagged_recon" = NMD_flagged_recon,
                       "poison_exon_candidate_ref" = poison_exon_candidate_ref,
                       "poison_exon_candidate_recon" = poison_exon_candidate_recon,
                       "contains_PTC_ref" = contains_PTC_ref,
                       "contains_PTC_recon" = contains_PTC_recon,
                       "first_or_last_exon_reference" = first_or_last_exon_reference,
                       "first_or_last_exon_recon" = first_or_last_exon_recon
  ))
  
}

```

### function to split a whole table by a delimiter in a column

```{r}

split_delimited_columns_in_table <- function(input_table, target_colname, split, columns_to_deduplicate = NULL) {
  
  # DEBUG ###
  # input_table <- test
  # target_colname <- c("Proteins", "Positions.within.proteins", "Fasta.headers", "Leading.proteins")
  # split = "\\;"
  # columns_to_deduplicate <- c("id")
  ###########
  
  # list-ify the target column
  list_target_column_strsplit_per_element <- input_table[, target_colname] %>% array_tree(margin = 2) %>% purrr::map(~.x %>% unlist %>% strsplit(., split = split))
  
  # map length
  vector_sum_lengths <- list_target_column_strsplit_per_element %>% purrr::map(~length(.x %>% unlist)) %>% unlist(use.names = FALSE) %>% unique
  
  # check. if the split lengths are different, then die.
  if (length(vector_sum_lengths) != 1) {
    
    stop("split lengths are uneven across specified columns.")
    
  }
  
  # repeat table according to the split lengths
  vector_split_lengths <- purrr::map_depth(.x = list_target_column_strsplit_per_element, .depth = 2, .f = ~length(.x)) %>% 
    purrr::map(~unlist(.x)) %>%
    purrr::pmap(.f = ~max(...)) %>%
    unlist
  
  row_indices_of_table_repeated_by_split <- purrr::map2(.x = 1:nrow(input_table), .y = vector_split_lengths, .f = ~rep(x = .x, times = .y)) %>% unlist
  
  input_table_repeated_by_split <- input_table[row_indices_of_table_repeated_by_split, ]
  
  # replace target column with split values
  input_table_repeated_by_split[, target_colname] <- list_target_column_strsplit_per_element %>% purrr::map(~unlist(.x)) %>% purrr::reduce(cbind)
  
  split_table <- input_table_repeated_by_split
  
  # if specified, append an index to a particular column
  if (is.null(columns_to_deduplicate) == FALSE) {
    
    # get the duplicated row indices where split lengths > 1
    indices_of_duplicates <- which(vector_split_lengths > 1)
    
    # get the repetition number where split lengths > 1
    repetition_numbers_of_duplicates <- vector_split_lengths[which(vector_split_lengths > 1)]
    
    # list-ify the columns to be appended
    list_deduplicated_columns <- input_table[, columns_to_deduplicate] %>% array_tree(margin = 2) %>% purrr::map(~array_tree(.x))
    
    # map over each column, split the target element and add _[0-9]+
    list_deduplicated_columns_split <- purrr::map(.x = list_deduplicated_columns, .f = function(a1) {
      
      # map a subset each of the L2 (elements of a column)
      a1[indices_of_duplicates] <- purrr::map2(.x = a1[indices_of_duplicates], .y = repetition_numbers_of_duplicates, 
                  .f = ~rep(.x, times = .y) %>% unlist %>% paste(., 1:.y, sep = "_"))
      
      return(a1 %>% unlist)
      
    } )
    
    # tibblise
    tibble_deduplicated_columns_split <- list_deduplicated_columns_split %>% as_tibble
    
    # add back every row onto the split table
    for (dedupe_colname in columns_to_deduplicate) {
      
      split_table[, dedupe_colname] <- tibble_deduplicated_columns_split[, dedupe_colname]
      
    }
    
  }
  
  return(split_table)
  
}

```

### Enrichment/Gene Ontology

```{r}

# function to do Benjamini-Hochberg FDR correction for Gene Ontology output tables from GOHyperGall

## takes the output of the GOHyperGall GO enrichment table and over-writes the Padj column with benjamini-corrected values from the Phyper column
## spits out the resulting table with modified single column.

## NOTE: BENJAMINI PVALUES ABOVE 0.05 ARE RENAMED NA

GOHyperGAll_benjamini_correction <- function(raw_GOHyperGAll_table)

  {
  
  benjamini_GOHyperGAll_table <- raw_GOHyperGAll_table
  
  benjamini_GOHyperGAll_table <- benjamini_GOHyperGAll_table[benjamini_GOHyperGAll_table$SampleMatch > 1, ]
  
  if (benjamini_GOHyperGAll_table %>% nrow == 0) {
    benjamini_GOHyperGAll_table <- tibble()
  } else {
    benjamini_GOHyperGAll_table[, "Padj"] <- p.adjust(p = benjamini_GOHyperGAll_table[, "Phyper"], method = "BH", n = length(benjamini_GOHyperGAll_table[, "Phyper"]))
    
    # benjamini_GOHyperGAll_table[benjamini_GOHyperGAll_table$Padj > 0.05, "Padj"] <- NA
  }

  return(benjamini_GOHyperGAll_table)
  
  }

# the equivalent for bc3net::enrichment() output table

bc3net_benjamini_correction <- function(raw_bc3net_table)

  {
  
  benjamini_bc3net_table <- raw_bc3net_table
  
  benjamini_bc3net_table_processed <- benjamini_bc3net_table[benjamini_bc3net_table$genes > 1, ]
  
  if (nrow(benjamini_bc3net_table_processed) != 0) {
  
  benjamini_bc3net_table_processed[, "padj"] <- p.adjust(p = benjamini_bc3net_table_processed[, "pval"], method = "BH", n = length(benjamini_bc3net_table_processed[, "pval"]))
  
  # benjamini_bc3net_table_processed[benjamini_bc3net_table_processed$padj > 0.05, "padj"] <- NA
  
  } else {
    
    benjamini_bc3net_table_processed <- benjamini_bc3net_table
    
    benjamini_bc3net_table_processed[, "padj"] <- NA
    
  }
  
  return(benjamini_bc3net_table_processed)
  
}

# bc3net::enrichment() does not show captured genes for each family enriched, so we have to add it in. but in doing so, i want to avoid a purrr within a purrr

# this function selects genes from the background in each family which are ONLY input genes.

filtering_genehits_from_background_catalogue <- function(catalogue, genehit_vector){
  
  filtered_catalogue <- purrr::map(.x = catalogue, .f = ~intersect(.x, genehit_vector))
  
  return(filtered_catalogue)
  
}

```

```{r}

# FUNCTION TO EXTRACT TRANSCRIPTS WITH JUNCTION-FLANKING EXONS.
# NOTE: to be used with purrr
# details of ONE junction: $chr, $start, $end, $strand
# tibble_gtf_table: rtracklayer::import(...) %>% as_tibble. can be any GTF. reconstructed or reference.
# index: loop progress marker to be used with imap

extract_junction.flanking.exons <- function(query_chr, query_start, query_end, query_strand, tibble_gtf_table, tolerance_left = 1, tolerance_right = 1, tolerance_inside = 1, tolerance_outside = 0, match_consecutive = TRUE, return_type = "exon") {
  
  # DEBUG ###
  # query_chr = b1$chr
  # query_start = b1$vector_alt_segment_starts
  # query_end = b1$vector_alt_segment_ends
  # query_strand = "*"
  # tibble_gtf_table = a2
  # tolerance_left = 0
  # tolerance_right = 0
  # tolerance_inside = 0
  # tolerance_outside = 0
  # match_consecutive = TRUE
  # return_type = ".*"
  ###########################
  
  # print(paste("now processing junction number", index))
  
  if (query_strand == "." | query_strand == 0 | query_strand == "*") {
    
    tibble_gtf_subset_flanking_exons <- tibble_gtf_table[tibble_gtf_table$seqnames == query_chr %>% trimws, ] %>% .[.$start <= ((query_end %>% type.convert) + 1 + tolerance_outside + tolerance_left) & .$end >= ((query_start %>% type.convert) - 1 - tolerance_outside - tolerance_left), ] %>% .[!(.$start <= ((query_end %>% type.convert) - tolerance_inside - tolerance_right) & .$end >= ((query_start %>% type.convert) + tolerance_inside + tolerance_left)), ]
    
  } else if (query_strand == "+" | query_strand == "-") {
    
    tibble_gtf_subset_flanking_exons <- tibble_gtf_table[tibble_gtf_table$seqnames == query_chr %>% trimws, ] %>% .[.$strand == query_strand %>% trimws, ] %>% .[.$start <= ((query_end %>% type.convert) + 1 + tolerance_right) & .$end >= ((query_start %>% type.convert) - 1 - tolerance_left), ] %>% .[!(.$start <= ((query_end %>% type.convert) - tolerance_inside - tolerance_right) & .$end >= ((query_start %>% type.convert) + tolerance_inside + tolerance_left)), ]
    
  } else {
    
    stop("Could not match the strand information in the transposed differential-only UNION_junc_coor_table. Make sure that the \"strand\" column in the UNION_junc_coor_table contains only +, - or .")
    
  }
  
  if (tibble_gtf_subset_flanking_exons %>% nrow > 0) {
    
    tibble_gtf_subset_flanking_exons <- tibble_gtf_subset_flanking_exons %>% dplyr::filter(str_detect(string = `type`, pattern = return_type))
    
  }
  
  list_of_junction_associated_transcripts <- tibble_gtf_subset_flanking_exons$transcript_id %>% unique %>% array_tree %>% flatten
  
  # make a list for each transcript that directly flanks a junction.
  # then filter so that there are only a) exon PAIRS which b) are directly connected in the mature (spliced) transcript
  
  if (match_consecutive == TRUE) {
    
    list_of_tibbles_flanking_exon_gtf.entries_per_transcript <- purrr::map(.x = list_of_junction_associated_transcripts, .f = ~tibble_gtf_subset_flanking_exons[tibble_gtf_subset_flanking_exons$transcript_id == .x, ] %>% dplyr::arrange(exon_number %>% type.convert)) %>% set_names(list_of_junction_associated_transcripts) %>% keep(.x = ., .p = ~nrow(.x) == 2) %>% keep(.x = ., .p = ~abs((.x[2, "exon_number"] %>% paste %>% type.convert) - (.x[1, "exon_number"] %>% paste %>% type.convert)) == 1)
    
  } else if (match_consecutive == FALSE) {
    
    list_of_tibbles_flanking_exon_gtf.entries_per_transcript <- purrr::map(.x = list_of_junction_associated_transcripts, .f = ~tibble_gtf_subset_flanking_exons[tibble_gtf_subset_flanking_exons$transcript_id == .x, ] %>% dplyr::arrange(exon_number %>% type.convert)) %>% set_names(list_of_junction_associated_transcripts) %>% keep(.x = ., .p = ~nrow(.x) == 2)
    
  }
  
  return(list_of_tibbles_flanking_exon_gtf.entries_per_transcript)
  
}

# END extract_junction.flanking.exons_JUM() ###

```

```{r}

# FUNCTION TO EXTRACT REFERENCE EXONS WHICH OVERLAP EXACTLY WITH QUERY EXONS
# NOTE: to be used with purrr
# input: spliceregion_list: a list containing details of ONE junction: $chr, $vector_alt_segment_starts, $vector_alt_segment_ends
# tibble_gtf_table: rtracklayer::import(...) %>% as_tibble. can be any GTF. reconstructed or reference.
# index: loop progress marker to be used with imap

extract_matching.exons <- function(query_chr, query_start, query_end, query_strand, tibble_gtf_table, tolerance_left = 0, tolerance_right = 0, tolerance_inside = 0, tolerance_outside = 0, return_type = "exon") {

  # DEBUG ###################
  # index <- 1
  # spliceregion_list <- wide_tibble_of_all_unique_VSR_and_exon_coords_array.tree_not_IR[[index]]
  # # tibble_gtf_table <- tibble_ref_gtf
  # tibble_gtf_table <- tibble_recon_gtf
  # stranded = FALSE
  ###########################

  # print(paste("now processing junction number", index))
  
  if (query_strand == "." | query_strand == 0 | query_strand == "*") {
    
    # +/- 1 nt tolerance
    tibble_gtf_subset_overlapping_exons <- tibble_gtf_table[tibble_gtf_table$seqnames == query_chr %>% trimws, ] %>% 
      .[which(.$start > ((query_start %>% as.numeric) - 1 - tolerance_left - tolerance_outside) & .$end < ((query_end %>% as.numeric) + 1 + tolerance_right + tolerance_outside)), ] %>% 
      .[which((.$start < ((query_start %>% as.numeric) + 1 + tolerance_left + tolerance_inside) & .$end > ((query_end %>% as.numeric) - 1 - tolerance_right - tolerance_inside))), ] %>% 
      .[which(.$type == return_type), ]
    
  } else if (query_strand == "+" | query_strand == "-") {
    
    # +/- 1 nt tolerance
    tibble_gtf_subset_overlapping_exons <- tibble_gtf_table[tibble_gtf_table$seqnames == query_chr %>% trimws &
                                                              tibble_gtf_table$strand == query_strand %>% trimws, ] %>% 
      .[which(.$start > ((query_start %>% as.numeric) - 1 - tolerance_left - tolerance_outside) & .$end < ((query_end %>% as.numeric) + 1 + tolerance_right + tolerance_outside)), ] %>% 
      .[which((.$start < ((query_start %>% as.numeric) + 1 + tolerance_left + tolerance_inside) & .$end > ((query_end %>% as.numeric) - 1 - tolerance_right - tolerance_inside))), ] %>% 
      .[which(.$type == return_type), ]
    
  } else {
    
    stop("Could not match the strand information in the transposed differential-only UNION_junc_coor_table. Make sure that the \"strand\" column in the UNION_junc_coor_table contains only +, - or .")
    
  }
  
  return(tibble_gtf_subset_overlapping_exons)
  
}

```

```{r}

extract_overlapping_features <- function(query_chr, query_start, query_end, query_strand, tibble_gtf_table, left_query_shift = 0, right_query_shift = 0, left_tolerance = 0, right_tolerance = 0, return_type) {
    
    # DEBUG ###################
    # index <- 1
    # spliceregion_list <- wide_tibble_of_all_unique_VSR_and_exon_coords_array.tree_not_IR[[index]]
    # # tibble_gtf_table <- tibble_ref_gtf
    # tibble_gtf_table <- tibble_recon_gtf
    # stranded = FALSE
    ###########################
    
    # cat(query_chr, "\n")
    # cat(query_start, "\n")
    # cat(query_end, "\n")
    # cat(query_strand, "\n")
    # print(tibble_gtf_table, "\n")
    # cat(left_query_shift, "\n")
    # cat(right_query_shift, "\n")
    # cat(left_tolerance, "\n")
    # cat(right_tolerance, "\n")
    
    # print(paste("now processing junction number", index))
    
    # left_query_shift <<- left_query_shift
    # right_query_shift <<- right_query_shift
    # left_tolerance <<- left_tolerance
    # right_tolerance <<- right_tolerance
    
    if (!(query_strand == "+" | query_strand == "-")) {
        
        # +/- 1 nt tolerance
        tibble_gtf_subset_matching_exons <- tibble_gtf_table[tibble_gtf_table$seqnames == query_chr %>% trimws, ] %>% 
            .[which(.$end >= ((query_start %>% as.numeric) + left_query_shift - left_tolerance) & .$start <= ((query_end %>% as.numeric) + right_query_shift + right_tolerance)), ] %>% 
            .[which(.$type == return_type), ]
        
    } else if (query_strand == "+" | query_strand == "-") {
        
        # +/- 1 nt tolerance
        tibble_gtf_subset_matching_exons <- tibble_gtf_table[tibble_gtf_table$seqnames == query_chr %>% trimws &
                                                                 tibble_gtf_table$strand == query_strand %>% trimws, ] %>% 
            .[which(.$end >= ((query_start %>% as.numeric) + left_query_shift - left_tolerance) & .$start <= ((query_end %>% as.numeric) + right_query_shift + right_tolerance)), ] %>% 
            .[which(.$type == return_type), ]
        
    }
    
    return(tibble_gtf_subset_matching_exons)
    
}

## END extract_overlapping_features() ###

```

```{r}

# FUNCTION TO EXTRACT COMMON STRING FROM TWO INPUT STRINGS IN ONE STEP, A SIMPLIFICATION OF QUALV

extract_common_string <- function(input_string_a, input_string_b) {
  
  # debug ###
  # 
  # input_string_a <- "ud_absolute.psi_1"
  # input_string_b <- "ud_absolute.psi_2"
  
  ###########
  
  vector_of_letters_a <- strsplit(input_string_a, "") %>% unlist
  vector_of_letters_b <- strsplit(input_string_b, "") %>% unlist 

  raw_LCS <- qualV::LCS(vector_of_letters_a, vector_of_letters_b)
  vector_common_string <- raw_LCS$LCS %>% paste(collapse = "")
  
  return(vector_common_string)
    
}

# END extract_common_string()

# FUNCTION TO TAKE THE AVERAGE VALUE OF A MATRIX OF TIMEPOINTS WITH THREE REPLICATES EACH (3 column compartments at a time)
## replicates of the same timepoint must be all grouped together.
calculate_average_values_from_replicate_columns <- function(input_matrix, number_of_replicates, append_average_to_column_name = TRUE) {
  
  # DEBUG ######
  
  # input_matrix <- wide_tibble_of_psisigma_results_allcomparisons_final_ud.only[, col_indices_observations]
  # number_of_replicates <- 3
  
  ##############
  
  # sanity check - if the number of columns is not an integer multiple of the number of replicates, there's something wrong
  if (ncol(input_matrix) %% number_of_replicates != 0) {
    
    stop("the number of columns in the matrix is not an integer multiple of the number of replicates specified. please check the matrix and try again.")
    
  }
  
  # get the row numbers to subset
  ## start of each compartment
  a <- seq(1, (ncol(input_matrix) - number_of_replicates + 1), number_of_replicates)
  ## end of each compartment
  b <- seq(number_of_replicates, ncol(input_matrix), number_of_replicates)
  # create list of compartments
  c <- purrr::map2(.x = a, .y = b, .f = ~.x:.y)
  # map each column into each compartment
  d <- purrr::map(.x = c, .f = ~input_matrix[, .x])
  # apply the average
  e <- purrr::map(.x = d, .f = ~apply(X = .x, MARGIN = 1, FUN = function(X){mean(X, na.rm = TRUE)}))
  # retrieve the column names of each compartment
  column_names <- purrr::map(.x = d, .f = ~colnames(.x) %>% purrr::reduce(extract_common_string))
  
  if (append_average_to_column_name == TRUE) {
    
    column_names <- paste(column_names, "average", sep = "")
    
  }
  
  # reframe into tibble, return
  f <- e %>% set_names(column_names) %>% as_tibble
  
}

# END calculate_average_values_from_replicate_columns()

```


```{r}

# FUNCTION TO EXTRACT TRANSCRIPTS WITH JUNCTION-FLANKING CDS regions.
# NOTE: to be used with purrr
# input: spliceregion_list: a list containing details of ONE junction: $chr, $start, $end, $strand
# tibble_gtf_table: rtracklayer::import(...) %>% as_tibble. can be any GTF. reconstructed or reference.
# index: loop progress marker to be used with imap
# NOTE 29/4/2020: RELAXED THE CONSECUTIVE EXON CRITERION. This is because there can be some novel exon skip events not annotated in reference. To reduce even more complicated calculations, however, we still need to match within the SAME transcript.

extract_junction.flanking.CDS_JUM <- function(spliceregion_list, tibble_gtf_table, match_consecutive = TRUE) {
  
  # DEBUG ###################
  
  # spliceregion_list <- a1$contributing_junctions %>% .[[2]]
  # tibble_gtf_table <- ref_tibble_with_first.last
  # tibble_gtf_table <- tibble_recon_gtf
  # index <- 1
  # match_consecutive = FALSE
  
  ###########################
  
  # print(paste("now processing junction number", index))
  
  if (spliceregion_list$strand == "." | spliceregion_list$strand == 0 | spliceregion_list$strand == "*") {
    
    tibble_gtf_subset_flanking_exons <- tibble_gtf_table[which(tibble_gtf_table$seqnames == spliceregion_list$chr %>% trimws), ] %>% .[which(.$start <= ((spliceregion_list$end %>% as.numeric) + 2) & .$end >= ((spliceregion_list$start %>% as.numeric) - 2)), ] %>% .[which(!(.$start <= ((spliceregion_list$end %>% as.numeric) - 2) & .$end >= ((spliceregion_list$start %>% as.numeric) + 2))), ] %>% .[which(.$type == "CDS"), ]
    
  } else if (spliceregion_list$strand == "+" | spliceregion_list$strand == "-") {
    
    tibble_gtf_subset_flanking_exons <- tibble_gtf_table[which(tibble_gtf_table$seqnames == spliceregion_list$chr %>% trimws), ] %>% .[which(.$strand == spliceregion_list$strand %>% trimws), ] %>% .[which(.$start <= ((spliceregion_list$end %>% as.numeric) + 2) & .$end >= ((spliceregion_list$start %>% as.numeric) - 2)), ] %>% .[which(!(.$start <= ((spliceregion_list$end %>% as.numeric) - 2) & .$end >= ((spliceregion_list$start %>% as.numeric) + 2))), ] %>% .[which(.$type == "CDS"), ]
    
  } else {
    
    stop("Could not match the strand information in the transposed differential-only UNION_junc_coor_table. Make sure that the \"strand\" column in the UNION_junc_coor_table contains only +, - or .")
    
  }
  
  list_of_junction_associated_transcripts <- tibble_gtf_subset_flanking_exons$transcript_id %>% unique %>% array_tree %>% flatten
  
  # make a list for each transcript that directly flanks a junction.
  # then filter so that there are only a) exon PAIRS which b) are directly connected in the mature (spliced) transcript
  
  if (match_consecutive == TRUE) {
    
    list_of_tibbles_flanking_exon_gtf.entries_per_transcript <- purrr::map(.x = list_of_junction_associated_transcripts, .f = ~tibble_gtf_subset_flanking_exons[tibble_gtf_subset_flanking_exons$transcript_id == .x, ] %>% dplyr::arrange(exon_number %>% as.numeric)) %>% set_names(list_of_junction_associated_transcripts) %>% keep(.x = ., .p = ~nrow(.x) == 2) %>% keep(.x = ., .p = ~abs((.x[2, "exon_number"] %>% paste %>% as.numeric) - (.x[1, "exon_number"] %>% paste %>% as.numeric)) == 1)
    
  } else if (match_consecutive == FALSE) {
    
    list_of_tibbles_flanking_exon_gtf.entries_per_transcript <- purrr::map(.x = list_of_junction_associated_transcripts, .f = ~tibble_gtf_subset_flanking_exons[tibble_gtf_subset_flanking_exons$transcript_id == .x, ] %>% dplyr::arrange(exon_number %>% as.numeric)) %>% set_names(list_of_junction_associated_transcripts) %>% keep(.x = ., .p = ~nrow(.x) == 2)
    
  }
  
  return(list_of_tibbles_flanking_exon_gtf.entries_per_transcript)
  
}

```


```{r}

# FUNCTION TO EXTRACT TRANSCRIPTS WITH JUNCTION-FLANKING EXONS.
# NOTE: to be used with purrr
# input: spliceregion_list: a list containing details of ONE junction: $chr, $start, $end, $strand
# tibble_gtf_table: rtracklayer::import(...) %>% as_tibble. can be any GTF. reconstructed or reference.
# index: loop progress marker to be used with imap

extract_junction.flanking.exons_JUM <- function(spliceregion_list, tibble_gtf_table, match_consecutive = TRUE) {
  
  # DEBUG ###################
  
  # spliceregion_list <- UNION_junc_coor_table_array.tree[[50]]
  # tibble_gtf_table <- tibble_ref_gtf
  # tibble_gtf_table <- tibble_recon_gtf
  # index <- 50
  
  ###########################
  
  # print(paste("now processing junction number", index))
  
  if (spliceregion_list$strand == "." | spliceregion_list$strand == 0 | spliceregion_list$strand == "*") {
    
    tibble_gtf_subset_flanking_exons <- tibble_gtf_table[tibble_gtf_table$seqnames == spliceregion_list$chr %>% trimws, ] %>% .[.$start <= ((spliceregion_list$end %>% as.numeric) + 2) & .$end >= ((spliceregion_list$start %>% as.numeric) - 2), ] %>% .[!(.$start <= ((spliceregion_list$end %>% as.numeric) - 2) & .$end >= ((spliceregion_list$start %>% as.numeric) + 2)), ] %>% .[.$type == "exon", ]
    
  } else if (spliceregion_list$strand == "+" | spliceregion_list$strand == "-") {
    
    tibble_gtf_subset_flanking_exons <- tibble_gtf_table[tibble_gtf_table$seqnames == spliceregion_list$chr %>% trimws, ] %>% .[.$strand == spliceregion_list$strand %>% trimws, ] %>% .[.$start <= ((spliceregion_list$end %>% as.numeric) + 2) & .$end >= ((spliceregion_list$start %>% as.numeric) - 2), ] %>% .[!(.$start <= ((spliceregion_list$end %>% as.numeric) - 2) & .$end >= ((spliceregion_list$start %>% as.numeric) + 2)), ] %>% .[.$type == "exon", ]
    
  } else {
    
    stop("Could not match the strand information in the transposed differential-only UNION_junc_coor_table. Make sure that the \"strand\" column in the UNION_junc_coor_table contains only +, - or .")
    
  }
  
  list_of_junction_associated_transcripts <- tibble_gtf_subset_flanking_exons$transcript_id %>% unique %>% array_tree %>% flatten
  
  # make a list for each transcript that directly flanks a junction.
  # then filter so that there are only a) exon PAIRS which b) are directly connected in the mature (spliced) transcript
  
  if (match_consecutive == TRUE) {
    
    list_of_tibbles_flanking_exon_gtf.entries_per_transcript <- purrr::map(.x = list_of_junction_associated_transcripts, .f = ~tibble_gtf_subset_flanking_exons[tibble_gtf_subset_flanking_exons$transcript_id == .x, ] %>% dplyr::arrange(exon_number %>% as.numeric)) %>% set_names(list_of_junction_associated_transcripts) %>% keep(.x = ., .p = ~nrow(.x) == 2) %>% keep(.x = ., .p = ~abs((.x[2, "exon_number"] %>% paste %>% as.numeric) - (.x[1, "exon_number"] %>% paste %>% as.numeric)) == 1)
    
  } else if (match_consecutive == FALSE) {
    
    list_of_tibbles_flanking_exon_gtf.entries_per_transcript <- purrr::map(.x = list_of_junction_associated_transcripts, .f = ~tibble_gtf_subset_flanking_exons[tibble_gtf_subset_flanking_exons$transcript_id == .x, ] %>% dplyr::arrange(exon_number %>% as.numeric)) %>% set_names(list_of_junction_associated_transcripts) %>% keep(.x = ., .p = ~nrow(.x) == 2)
    
  }
  
  return(list_of_tibbles_flanking_exon_gtf.entries_per_transcript)
  
}

```
### FUNCTION TO PLOT PCA FOR TIMEPOINT AND REPLICATE

```{r}

plot_PCA_for_timepoint_and_replicate <- function(matrixtable, timepoint_order = NULL, replicate_order = NULL, plot_shapes = TRUE, text_labels = FALSE, point_or_label_size = 2, legend_position = "right", PCA_depths_y = NULL, PCA_depths_x = NULL, save_dir = NULL, save_name = NULL, graph_title = NULL, width = 10, height = 10) {
  
  # DEBUG ###
  # matrixtable <- tibble_matrix_estimated_psi %>% na.omit
  # timepoint_order = temp_condition_names %>% unique
  # replicate_order = c("r1", "r2", "r3", "r4", "r5", "r6", "r7", "r8")
  # plot_shapes = TRUE
  # legend_position = "none"
  # PCA_depths_y = c(2, 3, 4)
  # PCA_depths_x = c(1, 2, 3)
  # save_dir = R_processing_results_dir
  # save_name = paste(vector_experiment_metadata_main %>% paste(collapse = "_"), "_no_na_psi_values.txt", sep = "")
  # graph_title = "2019_spliceome/MAJIQ"
  # width = 10
  # height = 10
  # text_labels <- FALSE
  # point_or_label_size <- 4
  ###########
  
  PCA_result <- prcomp(matrixtable)
  
  ## measure PC variance #
  PCA_stdev <- tibble("PC" = 1:(PCA_result[["sdev"]] %>% length), "stdev" = PCA_result[["sdev"]])
  
  PCA_variance <- tibble(PC = PCA_stdev$PC, variance = PCA_stdev$stdev ^ 2)
  PCA_variance <- add_column(PCA_variance, variance_explained = PCA_variance$variance/sum(PCA_variance$variance) * 100)
  
  ggplot_barplot_variance_explained <- ggplot(PCA_variance) + 
    geom_col(aes(x = PC, y = variance_explained, fill = PC)) +
    scale_fill_gradientn(colours = heat.colors(n = (PCA_result[["sdev"]] %>% length))) +
    ggtitle(paste("PCA variance distribution\n", graph_title, sep = "")) +
    guides(size = FALSE) + 
    xlab("PC") +
    ylab("Variance explained (%)") +
    theme_bw() +
    theme(text = element_text(family = "Helvetica"))
  
  ggsave(plot = ggplot_barplot_variance_explained, filename = paste(save_dir, "PCA_barplot_stdevs_", save_name, ".pdf", sep = ""), device = "pdf", dpi = 600, width = 45, height = 25, units = "cm")
  
  ## measure PC loadings #
  ## column names of the matrix need to be split by a "|", like this: timepoint|replicatenumber
  PCA_loadings <- PCA_result[["rotation"]] %>% as_tibble(rownames = "sample")
  PCA_loadings <- add_column(PCA_loadings, "timepoint" = gsub(x = PCA_loadings$sample, pattern = "(.*)\\|(.*)", replacement = "\\1") %>% factor(x = ., levels = timepoint_order), .after = "sample")
  PCA_loadings <- add_column(PCA_loadings, "replicatenumber" = gsub(x = PCA_loadings$sample, pattern = "(.*)\\|(.*)", replacement = "\\2") %>% factor(x = ., levels = replicate_order), .after = "sample")
  PCA_loadings <- add_column(PCA_loadings, 
                             "condition_names" = gsub(x = PCA_loadings$sample, pattern = "(.*)\\|(.*)", replacement = "\\1"),
                             "replicate_names" = gsub(x = PCA_loadings$sample, pattern = "(.*)\\|(.*)", replacement = "\\2"), 
                             .after = "sample")
  # append som_cluster number according to the order of timepoints specified by the user
  PCA_loadings <- dplyr::left_join(PCA_loadings, tibble("condition_names" = levels(PCA_loadings$timepoint), "cluster_number" = 1:length(levels(PCA_loadings$timepoint))), by = "condition_names") %>% 
    dplyr::relocate(cluster_number, .after = "sample")

  # plot PCA for multiple depths all in one go.
  purrr::map2(.x = PCA_depths_x, .y = PCA_depths_y, .f = function(.x, .y) {
    
    pc_x <- .x
    pc_y <- .y
    
    ggplot_plot <- ggplot(PCA_loadings) + 
      (if (text_labels == FALSE) {geom_point(aes(x = !!(paste("PC", pc_x, sep = "") %>% as.name), y = !!(paste("PC", pc_y, sep = "") %>% as.name), shape = replicatenumber, color = timepoint), size = point_or_label_size)} else if (text_labels == TRUE) {geom_text(aes(x = !!(paste("PC", pc_x, sep = "") %>% as.name), y = !!(paste("PC", pc_y, sep = "") %>% as.name), label = PCA_loadings$cluster_number, color = timepoint), size = point_or_label_size, position = position_dodge(width = 4))}) +
      scale_color_brewer(name = "Timepoint", palette = "Spectral", breaks = timepoint_order, limits = timepoint_order) +
      scale_shape_manual(name = "Replicate", values = 1:length(replicate_order)) +
      ggtitle(paste("PCA loadings\n", graph_title, sep = "")) +
      guides(size = FALSE) + 
      xlab(paste("PC", pc_x, " (", PCA_variance[pc_x, "variance_explained"] %>% signif(3), "%)", sep = "")) +
      ylab(paste("PC", pc_y, " (", PCA_variance[pc_y, "variance_explained"] %>% signif(3), "%)", sep = "")) +
      theme_bw() +
      theme(text = element_text(family = "Helvetica"), legend.position = legend_position)
    
    ggsave(plot = ggplot_plot, filename = paste(save_dir, "PCA_loadings_", save_name, "_PC", pc_y, "_vs_PC_", pc_x, ".pdf", sep = ""), device = "pdf", dpi = 600, width = width, height = height, units = "cm")
    
  } )
  
}

```

### FUNCTION TO PLOT UMAP FOR TIMEPOINT AND REPLICATE

NOTE: the matrixtable must be transposed, with one row per variable.

```{r}

plot_UMAP_for_timepoint_and_replicate <- function(transposed_matrixtable, timepoint_order = NULL, replicate_order = NULL, plot_shapes = TRUE, centroid_labels = TRUE, point_size = 5, centroid_label_size = 4, legend_position = "none", PCA_depths_y = NULL, PCA_depths_x = NULL, input_colour_limits = NULL, input_colour_value = NULL, save_dir = NULL, save_name = NULL, graph_title = NULL, width = 10, height = 10) {
  
  # DEBUG ###
  # transposed_matrixtable <- df_matrix_absolute_psi_in_sample_replicate_format %>% na.omit %>% t
  # timepoint_order <- temp_condition_names
  # replicate_order <- c("r1", "r2", "r3", "r4", "r5", "r6", "r7", "r8")
  # plot_shapes <- FALSE
  # legend_position <- "none"
  # centroid_labels <- TRUE
  # point_size <- 1
  # centroid_label_size <- 1
  # PCA_depths_y <- c(2, 3, 4)
  # PCA_depths_x <- c(1, 2, 3)
  # save_dir <- R_processing_results_dir
  # save_name <- "total_RNA_psisigma_pooled_replicates_no_na"
  # graph_title <- "Total RNA/PSI-Sigma"
  # width <- 40
  # height <- 40
  ###########
  
  tibble_umap_result <- umap::umap(transposed_matrixtable) %>% .$layout %>% 
    as_tibble(rownames = "condition|replicate", .name_repair = "unique") %>%
    setNames(nm = c("condition|replicate", "V1", "V2")) %>%
    add_column("condition_names" = gsub(x = .$`condition|replicate`, pattern = "(.*)\\|(.*)", replacement = "\\1"),
               "replicate_names" = gsub(x = .$`condition|replicate`, pattern = "(.*)\\|(.*)", replacement = "\\2")
               )
  
  # centroid labels: make a separate file containing the centroid locations
  tibble_centroid_locations <- tibble_umap_result %>% 
    dplyr::group_by(condition_names) %>% 
    dplyr::summarise("centroid_x" = mean(V1),
                     "centroid_y" = mean(V2)) %>%
    add_column("cluster_number" = paste(1:nrow(.)), .after = "condition_names")
  
  # append som_cluster info
  tibble_umap_result_plot <- dplyr::left_join(tibble_umap_result, tibble_centroid_locations, by = "condition_names")
  
  if (is.null(input_colour_limits) == TRUE) {
    
    input_colour_limits <- c(tibble_umap_result_plot$condition_names %>% unique)
    
  }
  
  if (is.null(input_colour_value) == TRUE) {
    
    input_colour_value <- rainbow(n = (timepoint_order %>% length))
    
  }
  
  # plot UMAP for multiple depths all in one go.
  ggplot() +
    (if (plot_shapes == TRUE) {geom_point(aes(x = tibble_umap_result_plot$V1, y = tibble_umap_result_plot$V2, shape = tibble_umap_result_plot$replicate_names, color = tibble_umap_result_plot$condition_names, fill = tibble_umap_result_plot$condition_names), size = point_size) } else {geom_blank(aes(x = tibble_umap_result_plot$V1, y = tibble_umap_result_plot$V2))}) +
    scale_shape_manual(name = "Replicate", values = 1:length(replicate_order)) +
    (if (centroid_labels == TRUE) {geom_text(aes(x = tibble_centroid_locations$centroid_x, y = tibble_centroid_locations$centroid_y, label = tibble_centroid_locations$cluster_number, color = tibble_centroid_locations$condition_names), size = centroid_label_size)} else {geom_blank(aes(x = tibble_centroid_locations$centroid_x, y = tibble_centroid_locations$centroid_y))}) +
    scale_fill_manual(name = "Timepoint", breaks = input_colour_limits, limits = input_colour_limits, values = input_colour_value) +
    scale_colour_manual(name = "Timepoint", breaks = input_colour_limits, limits = input_colour_limits, values = input_colour_value) +
    # scale_color_brewer(name = "Timepoint", palette = "Spectral", breaks = timepoint_order, limits = timepoint_order) +
    ggtitle(paste("UMAP projection\n", graph_title, sep = "")) +
    guides(size = FALSE) + 
    xlab("UMAP_1") +
    ylab("UMAP_2") +
    theme_bw() +
    theme(text = element_text(family = "Helvetica"), legend.position = legend_position) +
    ggsave(filename = paste(save_dir, "UMAP_", save_name, ".pdf", sep = ""), device = "pdf", dpi = 600, width = width, height = height, units = "cm") +
    ggsave(filename = paste(save_dir, "UMAP_", save_name, ".svg", sep = ""), device = "svg", dpi = 600, width = width, height = height, units = "cm")
  
  write.table(x = tibble_centroid_locations, file = paste(save_dir, "UMAP_", save_name, "_cluster_legend.txt", sep = ""), sep = "\t", quote = FALSE, row.names = FALSE, col.names = TRUE)
  
}

```

### FUNCTION TO PLOT tSNE FOR TIMEPOINT AND REPLICATE

NOTE: the matrixtable must be transposed, with one row per variable.

```{r}

plot_tSNE_for_timepoint_and_replicate <- function(transposed_matrixtable, timepoint_order = NULL, replicate_order = NULL, plot_shapes = TRUE, centroid_labels = TRUE, point_size = 5, centroid_label_size = 4, legend_position = "none", PCA_depths_y = NULL, PCA_depths_x = NULL, input_colour_limits = NULL, input_colour_value = NULL, save_dir = NULL, save_name = NULL, graph_title = NULL, width = 10, height = 10) {
  
  # DEBUG ###
  # transposed_matrixtable <- wide_tibble_matrix_processed_sorted_tibbles %>% as.data.frame %>% t
  # save_dir <- R_processing_results_dir
  # save_name <- "total_RNA"
  # graph_title <- "Total RNA"
  # timepoint_order <- long_tibble_processed_sorted_tibbles$sample_name %>% unique
  # replicate_order <- c("r1", "r2", "r3", "r4", "r5", "r6", "r7", "r8")
  # width <- 40
  # height <- 40
  # point_size <- 1
  # centroid_label_size <- 1
  # plot_shapes <- FALSE
  # centroid_labels <- TRUE
  # legend_position <- "none"
  ###########
  
  tibble_tsne_result <- Rtsne::Rtsne(X = transposed_matrixtable %>% unique, perplexity = 1, check_duplicates = FALSE, verbose = TRUE, num_threads = 0) %>% .$Y %>% 
    as_tibble(.name_repair = "unique") %>%
    add_column("condition_names" = rownames(transposed_matrixtable %>% unique), .before = 1) %>%
    setNames(nm = c("condition|replicate", "V1", "V2")) %>%
    add_column("condition_names" = gsub(x = .$`condition|replicate`, pattern = "(.*)\\|(.*)", replacement = "\\1"),
               "replicate_names" = gsub(x = .$`condition|replicate`, pattern = "(.*)\\|(.*)", replacement = "\\2")
    )
  
  # centroid labels: make a separate file containing the centroid locations
  tibble_centroid_locations <- tibble_tsne_result %>% 
    dplyr::group_by(condition_names) %>% 
    dplyr::summarise("centroid_x" = mean(V1),
                     "centroid_y" = mean(V2)) %>%
    add_column("cluster_number" = paste(1:nrow(.)), .after = "condition_names")
  
  # append som_cluster info
  tibble_tsne_result_plot <- dplyr::left_join(tibble_tsne_result, tibble_centroid_locations, by = "condition_names")
  
  if (is.null(input_colour_limits) == TRUE) {
    
    input_colour_limits <- c(tibble_tsne_result_plot$condition_names %>% unique)
    
  }
  
  if (is.null(input_colour_value) == TRUE) {
    
    input_colour_value <- rainbow(n = (timepoint_order %>% length))
    
  }
  
  # plot UMAP for multiple depths all in one go.
  ggplot() + 
    (if (plot_shapes == TRUE) {geom_point(aes(x = tibble_tsne_result_plot$V1, y = tibble_tsne_result_plot$V2, shape = tibble_tsne_result_plot$replicate_names, color = tibble_tsne_result_plot$condition_names, fill = tibble_tsne_result_plot$condition_names), size = point_size) } else {geom_blank(aes(x = tibble_tsne_result_plot$V1, y = tibble_tsne_result_plot$V2))}) +
    scale_shape_manual(name = "Replicate", values = 1:length(replicate_order)) +
    (if (centroid_labels == TRUE) {geom_text(aes(x = tibble_centroid_locations$centroid_x, y = tibble_centroid_locations$centroid_y, label = tibble_centroid_locations$cluster_number, color = tibble_centroid_locations$condition_names), size = centroid_label_size)} else {geom_blank(aes(x = tibble_centroid_locations$centroid_x, y = tibble_centroid_locations$centroid_y))}) +
    scale_fill_manual(name = "Timepoint", breaks = input_colour_limits, limits = input_colour_limits, values = input_colour_value) +
    scale_colour_manual(name = "Timepoint", breaks = input_colour_limits, limits = input_colour_limits, values = input_colour_value) +
    # scale_color_brewer(name = "Timepoint", palette = "Spectral", breaks = timepoint_order, limits = timepoint_order) +
    ggtitle(paste("tSNE projection\n", graph_title, sep = "")) +
    guides(size = FALSE) + 
    xlab("tSNE_1") +
    ylab("tSNE_2") +
    theme_bw() +
    theme(text = element_text(family = "Helvetica"), legend.position = legend_position) +
    ggsave(filename = paste(save_dir, "tSNE_", save_name, ".pdf", sep = ""), device = "pdf", dpi = 600, width = width, height = height, units = "cm") +
    ggsave(filename = paste(save_dir, "tSNE_", save_name, ".svg", sep = ""), device = "svg", dpi = 600, width = width, height = height, units = "cm")
  
  write.table(x = tibble_centroid_locations, file = paste(save_dir, "tSNE_", save_name, "_cluster_legend.txt", sep = ""), sep = "\t", quote = FALSE, row.names = FALSE, col.names = TRUE)
  
}

```

# Generate files for MAJIQ

# Import and process MAJIQ tables

## read the MAJIQ sql file

```{r}

library(DBI)
library(RSQLite)

SQLiteConnection_splicegraph <- DBI::dbConnect(RSQLite::SQLite(), paste(majiq_results_dir, "build_groups/splicegraph.sql", sep = ""))

# SQLiteConnection_splicegraph <- DBI::dbConnect(RSQLite::SQLite(), "/mnt/scratch/2020_RNA_Atlas/total_RNA_splicing/3_majiqtest/build_groups/splicegraph.sql")

list_majiq_build_info <- purrr::map(
  .x = DBI::dbListTables(SQLiteConnection_splicegraph),
  .f = ~DBI::dbReadTable(SQLiteConnection_splicegraph, .x) %>% as_tibble(rownames = "rowname")
) %>% set_names(nm = DBI::dbListTables(SQLiteConnection_splicegraph))

# process raw counts
tibble_raw_counts <- dplyr::bind_rows(
  list_majiq_build_info$junction_reads %>% dplyr::mutate("junc_IR_coords" = paste(`junction_start`, "-", `junction_end`, sep = ""), "junc_or_IR" = "junc") %>% dplyr::rename("Gene ID" = "junction_gene_id"),
  list_majiq_build_info$intron_retention_reads %>% dplyr::mutate("junc_IR_coords" = paste(`intron_retention_start`, "-", `intron_retention_end`, sep = ""), "junc_or_IR" = "IR") %>% dplyr::rename("Gene ID" = "intron_retention_gene_id")
) %>% 
  dplyr::mutate("experiment_name" = gsub(x = `experiment_name`, pattern = "\\_Aligned\\.sortedByCoord\\.out", replacement = ""))

data.table::fwrite(x = tibble_raw_counts, file = paste(R_processing_results_dir, vector_experiment_metadata_main %>% paste(collapse = "_"), "_temp_tibble_raw_counts.txt", sep = ""), sep = "\t", quote = FALSE, row.names = FALSE, col.names = TRUE)

```

## Import the sorted.out tables, denominator tables and db tables.

```{r}

plan(future::multicore)
options(mc.cores = 96)

# add gene names using reference
# tibble_ref_gtf <- rtracklayer::import(tibble_ref_gtf_path) %>% as_tibble

list_majiq_psi_filtered_by_read_counts <- furrr::future_map2(
  .x = list.files(path = paste(majiq_results_dir, "psi_raw/", sep = ""), pattern = ".*\\_fixed.tsv", recursive = FALSE, full.names = TRUE, include.dirs = FALSE),
  .y = list.files(path = paste(majiq_results_dir, "psi_raw/", sep = ""), pattern = ".*\\_fixed.tsv", recursive = FALSE, full.names = FALSE, include.dirs = FALSE),
  .f = function(a1, a2) {
    
    # DEBUG ###
    # a1 <- list.files(path = paste(majiq_results_dir, "psi_raw/", sep = ""), pattern = ".*\\_fixed.tsv", recursive = FALSE, full.names = TRUE, include.dirs = FALSE) %>% .[[2]]
    # a2 <- list.files(path = paste(majiq_results_dir, "psi_raw/", sep = ""), pattern = ".*\\_fixed.tsv", recursive = FALSE, full.names = FALSE, include.dirs = FALSE) %>% .[[2]]
    ###########
    
    cat(a2, "\n")
    
    tibble_majiq_psi <- read.delim(file = a1, header = TRUE, sep = "\t", stringsAsFactors = FALSE, check.names = FALSE, na.strings = c("na", "NA", "N/A", ""), skip = 7) %>% 
      tibble::as_tibble() 
    
    tibble_majiq_psi_old <- read.delim(file = gsub(x = a1, pattern = "\\_fixed", replacement = ""), header = TRUE, sep = "\t", stringsAsFactors = FALSE, check.names = FALSE, na.strings = c("na", "NA", "N/A", "")) %>% 
      tibble::as_tibble() %>% dplyr::select(`Gene ID`, `LSV ID`, `A5SS`, `A3SS`, `ES`) %>% dplyr::rename("gene_id" = "Gene ID", "lsv_id" = "LSV ID")
    
    tibble_raw_counts <- data.table::fread(file = paste(R_processing_results_dir, vector_experiment_metadata_initial %>% paste(collapse = "_"), "_temp_tibble_raw_counts.txt", sep = ""), sep = "\t", stringsAsFactors = FALSE, header = TRUE, check.names = FALSE) %>% 
      tibble::as_tibble() %>%
      dplyr::rename("gene_id" = "Gene ID")
    
    # # add gene names using reference
    # tibble_ref_gtf <- rtracklayer::import(tibble_ref_gtf_path) %>% as_tibble
    
    tibble_gene_names <- tibble_majiq_psi %>%
      dplyr::left_join(., tibble_majiq_psi_old) %>%
      dplyr::mutate("condition_names" = a2 %>% gsub(pattern = "\\.psi\\_fixed\\.tsv", replacement = "")) %>% 
      dplyr::rename("chr" = "seqid") %>%
      dplyr::select(-de_novo_junctions, -exons_coords, -ucsc_lsv_link)
    
    # separate the junctions and ir_coords columns into a long tibble
    long_tibble0 <- tibble_gene_names %>%
      split_delimited_columns_in_table(input_table = ., target_colname = c(colnames(tibble_gene_names)[grep(x = colnames(tibble_gene_names), pattern = "psi", ignore.case = FALSE)], "junctions_coords"), split = "\\;")
      
    long_tibble1 <- dplyr::bind_rows(
      long_tibble0[!is.na(long_tibble0$`ir_coords`), ] %>% dplyr::select(-`junctions_coords`) %>% dplyr::mutate("junc_or_IR" = "IR") %>% dplyr::rename("junc_IR_coords" = "ir_coords"),
      long_tibble0 %>% dplyr::select(-`ir_coords`) %>% dplyr::mutate("junc_or_IR" = "junc") %>% dplyr::rename("junc_IR_coords" = "junctions_coords")
    )
    
    plan(list(tweak(multicore, workers = 8)))
    
    # only the PSI values attributed to "junctions" actually describe IR.
    # therefore we group up every chr/junc_ir_coords and if there is mixed IR and junction event, it must be an IR event.
    # in those cases, we will rename junction coord as IR.
    long_tibble_split_by_chr_coords <- furrr::future_map(
      .x = long_tibble1 %>% dplyr::group_split(`lsv_id`, `chr`, `junc_IR_coords`),
      .f = function(a1) {
        
        # DEBUG ###
        # a1 <- long_tibble1 %>% dplyr::group_split(`LSV ID`, `chr`, `junc_IR_coords`) %>% .[[2]]
        ###########
        
        # test %>% purrr::map(~any(.x$junc_or_IR == "IR")) %>% unlist %>% which
        
        if (any(a1$junc_or_IR == "IR")) {
          return(a1[a1$junc_or_IR == "junc", ] %>% .[1, ] %>% dplyr::mutate("junc_or_IR" = "IR"))
        } else {
          return(a1)
        }
        
      }, .progress = TRUE )
    
    long_tibble <- long_tibble_split_by_chr_coords %>% 
      data.table::rbindlist() %>% 
      tibble::as_tibble() %>% 
      unique %>% 
      dplyr::distinct(`lsv_id`, `junc_IR_coords`, `chr`, `junc_or_IR`, .keep_all = TRUE) %>%
      readr::type_convert()
    
    # join the raw counts onto the tibble
    long_tibble_with_counts <- dplyr::left_join(
      long_tibble,
      tibble_raw_counts[, c("reads", "gene_id", "junc_IR_coords", "junc_or_IR", "experiment_name")] %>% dplyr::rename("read_counts" = "reads", "condition_names" = "experiment_name") %>% dplyr::mutate("condition_names" = `condition_names` %>% gsub(pattern = "\\.psi\\_fixed\\.tsv", replacement = ""))
    ) 
    
    long_tibble_with_counts <- long_tibble_with_counts %>% dplyr::mutate("gene_id" = gsub(x = `gene_id`, pattern = "([^\\:]+)\\:([^\\:]+)", replacement = "\\2"), "junc_IR_coords_start" = gsub(x = `junc_IR_coords`, pattern = "([^\\-]+)\\-([^\\-]+)", replacement = "\\1") %>% type.convert, "junc_IR_coords_end" = gsub(x = `junc_IR_coords`, pattern = "([^\\-]+)\\-([^\\-]+)", replacement = "\\2") %>% type.convert)
    
    # filter for read counts
    # tibble_filtered <- long_tibble_with_counts[is.na(long_tibble_with_counts$read_counts) == FALSE, ] %>% .[.$read_counts >= 15, ]
    tibble_filtered <- long_tibble_with_counts
    
    # write.table(x = tibble_filtered, file = paste(R_processing_results_dir, "temp_tibble_filtered_by_read_count_", a2 %>% gsub(pattern = "\\.psi\\.tsv", replacement = ""), ".txt", sep = ""), sep = "\t", quote = FALSE, row.names = FALSE, col.names = TRUE)
    
    return(tibble_filtered)
    
  }, .progress = TRUE)

```

## make long and wide tables

### detect VSRs from LSVs

```{r}

list_tibble_majiq_psi_table_processed_for_wide <- purrr::map(
  .x = list_majiq_psi_filtered_by_read_counts,
  .f = function(a1) {
    
    # DEBUG ###
    # a1 <- list_majiq_psi_filtered_by_read_counts[[1]]
    ###########
    
    condition_name <- a1$condition_names %>% unique
    
    colnames(a1)[grepl(x = colnames(a1), pattern = "psi") | (colnames(a1) == "read_counts")] <- paste(colnames(a1)[grepl(x = colnames(a1), pattern = "psi") | (colnames(a1) == "read_counts")], "_", condition_name, sep = "")
    
    a1 <- a1 %>% dplyr::select(-condition_names)
    
    return(a1)
    
  } )

# full_join all tables
wide_tibble_psi0 <- list_tibble_majiq_psi_table_processed_for_wide %>% 
  purrr::reduce(dplyr::full_join)

# convert NA values to zero values for PSI
wide_tibble_psi1 <- wide_tibble_psi0 %>% 
  dplyr::mutate(across(.cols = contains("E(PSI) per LSV"), .fns = function(x) {x[is.na(x)] <- 0; return(x)}))

# remove junctions with zero read counts - dw we decided to keep them because each junction reflects a different isoform of origin
# wide_tibble_psi <- wide_tibble_psi[!wide_tibble_psi %>% dplyr::arrange(gene_name) %>% dplyr::select(contains("read_counts")) %>% rowMeans(na.rm = TRUE) %>% is.na, ]

colnames(wide_tibble_psi1) <- gsub(x = colnames(wide_tibble_psi1), pattern = "24h", replacement = "1d")
colnames(wide_tibble_psi1) <- gsub(x = colnames(wide_tibble_psi1), pattern = "ud", replacement = "MSC")

# data.table::fwrite(x = wide_tibble_psi, file = paste(R_processing_results_dir, vector_experiment_metadata_initial %>% paste(collapse = "_"), "_wide_tibble_psi.txt", sep = ""), sep = "\t", quote = FALSE, row.names = FALSE, col.names = TRUE)

plan(multicore)
options(mc.cores = 32)

# this is the wide_tibble_psi with VSR_coords
wide_tibble_psi <- furrr::future_map(
  .x = wide_tibble_psi1 %>% dplyr::group_split(chr, gene_name, strand),
  .f = function(a1) {
    
    # DEBUG ###
    # a1 <- wide_tibble_psi[wide_tibble_psi$strand == "-", ] %>% dplyr::group_split(chr, gene_name) %>% .[[1]]
    ###########
    
    tibble_lsv_to_vsr_flag_table <- dplyr::bind_rows(
      tibble("coord" = purrr::map2(.x = a1$junc_IR_coords %>% gsub(pattern = "([^\\-]+)\\-([^\\-]+)", replacement = "\\1"), .y = a1$junc_IR_coords %>% gsub(pattern = "([^\\-]+)\\-([^\\-]+)", replacement = "\\2"), .f = ~min(c(.x, .y) %>% type.convert)) %>% unlist, "flag" = 1),
      tibble("coord" = purrr::map2(.x = a1$junc_IR_coords %>% gsub(pattern = "([^\\-]+)\\-([^\\-]+)", replacement = "\\1"), .y = a1$junc_IR_coords %>% gsub(pattern = "([^\\-]+)\\-([^\\-]+)", replacement = "\\2"), .f = ~max(c(.x, .y) %>% type.convert)) %>% unlist, "flag" = -1)
    ) %>% dplyr::arrange(`coord`)
    
    vec_cumulative_sum <- tibble_lsv_to_vsr_flag_table$flag %>% purrr::accumulate(sum, .dir = "forward")
    
    tibble_vsrs <- purrr::map2(
      # starts
      .x = tibble_lsv_to_vsr_flag_table[which(vec_cumulative_sum == 1 & c(0, vec_cumulative_sum[1:(length(vec_cumulative_sum) - 1)]) == 0), ] %>% .$coord,
      # ends
      .y = tibble_lsv_to_vsr_flag_table[which(vec_cumulative_sum == 0 & c(0, vec_cumulative_sum[1:(length(vec_cumulative_sum) - 1)]) == 1), ] %>% .$coord,
      .f = ~tibble("chr" = a1$chr %>% unique, "start" = .x, "end" = .y, "strand" = a1$strand %>% unique)
    ) %>% rbindlist(fill = TRUE, use.names = TRUE) %>% as_tibble
    
    vector_corresponding_VSRs_per_row <- purrr::map2(
      .x = a1$junc_IR_coords_start %>% type.convert,
      .y = a1$junc_IR_coords_end %>% type.convert,
      .f = function(b1, b2) {
        
        # DEBUG ###
        # b1 <- a1$junc_IR_coords_start %>% .[[1]]
        # b2 <- a1$junc_IR_coords_end %>% .[[1]]
        ###########
        
        tibble_vsrs[which(tibble_vsrs$start <= b1 & tibble_vsrs$end >= b2), ] %>%
          dplyr::mutate("VSR_coords" = paste(`chr`, ":", `start`, "-", `end`, ":", `strand`, sep = "")) %>%
          .$VSR_coords %>%
          return
        
      } ) %>% unlist
    
    return(a1 %>% dplyr::mutate("VSR_coords" = vector_corresponding_VSRs_per_row, .after = "gene_id"))
    
  }, .progress = TRUE ) %>% data.table::rbindlist() %>% tibble::as_tibble() %>% suppressMessages() %>% suppressWarnings()

data.table::fwrite(x = wide_tibble_psi, file = paste(R_processing_results_dir, vector_experiment_metadata_initial %>% paste(collapse = "_"), "_wide_tibble_psi.txt", sep = ""), sep = "\t", quote = FALSE, row.names = FALSE, col.names = TRUE)

wide_tibble_psi <- data.table::fread(file = paste(R_processing_results_dir, vector_experiment_metadata_initial %>% paste(collapse = "_"), "_wide_tibble_psi.txt", sep = ""), sep = "\t", stringsAsFactors = FALSE, header = TRUE) %>% as_tibble

```

### long

```{r}

long_tibble_psi <- list_majiq_psi_filtered_by_read_counts %>%
  data.table::rbindlist(use.names = TRUE, fill = TRUE) %>% 
  as_tibble %>%
  dplyr::left_join(., wide_tibble_psi[, c("chr", "strand", "junc_IR_coords", "VSR_coords")] %>% unique)

data.table::fwrite(x = long_tibble_psi, file = paste(R_processing_results_dir, vector_experiment_metadata_initial %>% paste(collapse = "_"), "_long_tibble_psi.txt", sep = ""), sep = "\t", quote = FALSE, row.names = FALSE, col.names = TRUE)

long_tibble_psi <- data.table::fread(file = paste(R_processing_results_dir, vector_experiment_metadata_initial %>% paste(collapse = "_"), "_long_tibble_psi.txt", sep = ""), sep = "\t", stringsAsFactors = FALSE, header = TRUE) %>% as_tibble

```


# Annotate with reference and recon information

## annotate with reference and recon GTF info

```{r}

wide_tibble_psi <- data.table::fread(file = paste(R_processing_results_dir, vector_experiment_metadata_main %>% paste(collapse = "_"), "_wide_tibble_psi.txt", sep = ""), sep = "\t", stringsAsFactors = FALSE, header = TRUE) %>% as_tibble

# get entries of junction-flanking exon matches
list_junction_entries <- tibble(
  "chr" = wide_tibble_psi$chr,
  "start" = gsub(x = wide_tibble_psi$junc_IR_coords, pattern = "(.*)\\-(.*)", replacement = "\\1"),
  "end" = gsub(x = wide_tibble_psi$junc_IR_coords, pattern = "(.*)\\-(.*)", replacement = "\\2")
) %>% purrr::array_tree() %>% type.convert %>% suppressMessages() %>% suppressWarnings()

plan(multicore)
options(mc.cores = 96)

list_gtf_matching_exon_entries <- furrr::future_map(
  .x = list_junction_entries, 
  .f = function(a1) {
    
    # DEBUG ###
    # a1 <- list_junction_entries[[1]]
    ###########
    
    splice(
      a1, 
      list(
        "reference_gtf_match" = extract_junction.flanking.exons(query_chr = a1$chr %>% as.character, query_start = a1$start, query_end = a1$end, query_strand = "*", tibble_gtf_table = tibble_ref_gtf, tolerance_left = 1, tolerance_right = 1, tolerance_inside = 0, tolerance_outside = 0, match_consecutive = TRUE, return_type = "exon") %>% rbindlist %>% as_tibble, 
        "reconstructed_gtf_match" = extract_junction.flanking.exons(query_chr = a1$chr %>% as.character, query_start = a1$start, query_end = a1$end, query_strand = "*", tibble_gtf_table = tibble_recon_gtf, tolerance_left = 1, tolerance_right = 1, tolerance_inside = 0, tolerance_outside = 0, match_consecutive = TRUE, return_type = "exon") %>% rbindlist %>% as_tibble)) %>% return
    
  }, .progress = TRUE) %>% suppressMessages() %>% suppressWarnings()

list_gtf_matching_exon_entries_extracted <- purrr::map2(.x = list_gtf_matching_exon_entries, .y = list_junction_entries, .f = ~annotate_differential_exon(.x, .y) %>% as_tibble)

tibble_gtf_matching_exon_entries_extracted <- list_gtf_matching_exon_entries_extracted %>% rbindlist %>% as_tibble

# write table 
write.table(x = tibble_gtf_matching_exon_entries_extracted, file = paste(R_processing_results_dir, vector_experiment_metadata_main %>% paste(collapse = "_"), "_tibble_gtf_matching_exon_entries_extracted_NMD.first.last_info.txt", sep = ""), sep = "\t", row.names = FALSE, quote = FALSE)

```

## plot PCA based on estimated PSI

```{r}

wide_tibble_psi <- data.table::fread(file = paste(R_processing_results_dir, vector_experiment_metadata_main %>% paste(collapse = "_"), "_wide_tibble_psi.txt", sep = ""), sep = "\t", stringsAsFactors = FALSE, header = TRUE) %>% as_tibble

tibble_matrix_estimated_psi <- wide_tibble_psi %>% dplyr::select(matches("^E\\(PSI\\)"))

temp_condition_names <- gsub(x = colnames(tibble_matrix_estimated_psi), pattern = ".*\\_BM\\_MSC\\_to\\_OB\\_([^\\_]+)\\_B(.*)", replacement = "\\1")
temp_replicate_names <- gsub(x = colnames(tibble_matrix_estimated_psi), pattern = ".*\\_BM\\_MSC\\_to\\_OB\\_([^\\_]+)\\_B(.*)", replacement = "r\\2")

colnames(tibble_matrix_estimated_psi) <- paste(temp_condition_names, "|", temp_replicate_names, sep = "")

tibble_matrix_estimated_psi_with_na <- tibble_matrix_estimated_psi
tibble_matrix_estimated_psi_with_na[is.na(tibble_matrix_estimated_psi_with_na)] <- 0

# PCA
set.seed(8)
plot_PCA_for_timepoint_and_replicate(matrixtable = tibble_matrix_estimated_psi %>% na.omit, timepoint_order = temp_condition_names %>% unique, replicate_order = c("r1", "r2", "r3", "r4", "r5", "r6", "r7", "r8"), plot_shapes = TRUE, PCA_depths_y = c(2, 3, 4), PCA_depths_x = c(1, 2, 3), save_dir = R_processing_results_dir, save_name = paste(vector_experiment_metadata_main %>% paste(collapse = "_"), "_no_na_psi_values.txt", sep = ""), graph_title = "2019_spliceome/MAJIQ", width = 10, height = 10, point_or_label_size = 3)

set.seed(8)
plot_PCA_for_timepoint_and_replicate(matrixtable = tibble_matrix_estimated_psi_with_na, timepoint_order = temp_condition_names %>% unique, replicate_order = c("r1", "r2", "r3", "r4", "r5", "r6", "r7", "r8"), plot_shapes = TRUE, PCA_depths_y = c(2, 3, 4), PCA_depths_x = c(1, 2, 3), save_dir = R_processing_results_dir, save_name = paste(vector_experiment_metadata_main %>% paste(collapse = "_"), "_with_na_psi_values.txt", sep = ""), graph_title = "2019_spliceome/MAJIQ", width = 10, height = 10, point_or_label_size = 3)

```

## annotate LSVs according to their constituent junction info

```{r}

summarised_tibble_annotation <- tibble_gtf_matching_exon_entries_extracted %>%
  dplyr::group_by(chr, start, end) %>%
  dplyr::summarise(
    "chr" = `chr` %>% paste(collapse = ";"),
    "start" = `start` %>% paste(collapse = ";"),
    "end" = `end` %>% paste(collapse = ";"),
    "matched_gene_names" = `matched_gene_names` %>% paste(collapse = ";"),
    "matched_ref_transcript_names" = `matched_ref_transcript_names` %>% paste(collapse = ";"),
    "matched_recon_transcript_names" = `matched_recon_transcript_names` %>% paste(collapse = ";"),
    "NMD_biotype_reference" = `NMD_biotype_reference` %>% unique %>% all == TRUE,
    "NMD_flagged_ref" = `NMD_flagged_ref` %>% unique %>% all == TRUE,
    "NMD_flagged_recon" = `NMD_flagged_recon` %>% unique %>% all == TRUE,
    "any_NMD" = any(c(grep(x = `NMD_flagged_ref`, pattern = "TRUE") %>% na.omit,
                      grep(x = `NMD_flagged_recon`, pattern = "TRUE") %>% na.omit)),
    "poison_exon_candidate_ref" = any(`poison_exon_candidate_ref` == TRUE),
    "poison_exon_candidate_recon" = any(`poison_exon_candidate_recon` == TRUE),
    "contains_PTC_ref" = any(`contains_PTC_ref` == TRUE),
    "contains_PTC_recon" = any(`contains_PTC_recon` == TRUE),
    "first_or_last_exon_reference" = `first_or_last_exon_reference` %>% paste(collapse = ";"),
    "first_or_last_exon_recon" = `first_or_last_exon_recon` %>% paste(collapse = ";"),
    "any_first_exon" = any(c(grep(x = `first_or_last_exon_reference`, pattern = "first_exon") %>% na.omit, 
                             grep(x = `first_or_last_exon_recon`, pattern = "first_exon") %>% na.omit)),
    "any_last_exon" = any(c(grep(x = `first_or_last_exon_reference`, pattern = "last_exon") %>% na.omit, 
                            grep(x = `first_or_last_exon_recon`, pattern = "last_exon") %>% na.omit))
  )

```

<!-- ### IR ENTRIES -->

<!-- ```{r} -->

<!-- options(mc.cores = 8) -->

<!-- # for IR event entries, complicated. First retrieve the matched/recon transcripts. then find transcripts with overlapping exons. -->
<!-- # These IR-spanning transcripts must have at least ONE start/end coord/gene name in common with the junction-matched transcripts. -->
<!-- # return their corresponding annotations. -->
<!-- # NOTE: it seems like JUM only associates one junction ID with each IR event (which makes sense). However, my small sample size of 52 IR junctions isn't enough to fully conclude this is the case. -->
<!-- ## array tree-ify the AS_event_IDs for looping -->
<!-- as.event.id_array.tree_IR <- wide_tibble_all_splicemodes_split_with_na[row.indices_IR_events, ] %>% .$AS_event_ID %>% unique %>% array_tree -->

<!-- ## look up the annotation tibble for each AS_event_ID, summarise. -->
<!-- list_as.event.id_with_summarised_annotation_IR <- future_imap(.x = as.event.id_array.tree_IR, .f = function(.x, .y) { -->

<!--   # message("now processing entry number: ", .y) -->

<!--   # DEBUG ### -->
<!--   # .x <- as.event.id_array.tree_IR[[3]] -->
<!--   # tibble_ref_gtf <- tibble_ref_gtf -->
<!--   # tibble_recon_gtf <- tibble_recon_gtf -->
<!--   ########### -->

<!--   subset_tibble_annotation <- tibble_of_AS.event.ID_joined_to_annotation[tibble_of_AS.event.ID_joined_to_annotation$AS_event_ID == .x, ] %>% unique -->

<!--   chr <- subset_tibble_annotation$chr %>% paste -->
<!--   start <- subset_tibble_annotation$start %>% paste -->
<!--   end <- subset_tibble_annotation$end %>% paste -->
<!--   strand <- subset_tibble_annotation$strand %>% paste -->
<!--   vec_ref_transcripts_matched_to_junction <- subset_tibble_annotation$matched_ref_transcript_names %>% strsplit(split = ",") %>% unlist -->
<!--   vec_recon_transcripts_matched_to_junction <- subset_tibble_annotation$matched_recon_transcript_names %>% strsplit(split = ",") %>% unlist -->

<!--   # check reference annotation - but only if the junction was matched to reference in the first place. -->
<!--   tibble_all_confirmed_IR_entries_ref <- "uninit" -->

<!--   if (all(is.na(vec_ref_transcripts_matched_to_junction)) != TRUE) { -->

<!--     # match IR region to reference -->
<!--     tibble_ref_gtf_subset_IR_overlap <- tibble_ref_gtf[tibble_ref_gtf$seqnames == chr %>% trimws, ] %>% .[.$strand == strand %>% trimws, ] %>% .[.$start <= ((start %>% as.numeric) - 2) & .$end >= ((end %>% as.numeric) + 2), ] %>% .[.$type == "exon", ] -->

<!--     # get all the entries which matched to the junction -->
<!--     tibble_ref_gtf_subset_junction_matching_entries <- tibble_ref_gtf[tibble_ref_gtf$type == "exon", ] %>% .[which(.$transcript_id %in% vec_ref_transcripts_matched_to_junction), ] -->

<!--     # extract all the start coords of the junction-matched entries -->
<!--     vector_junction_matched_start_coords <- tibble_ref_gtf_subset_junction_matching_entries[, "start"] -->
<!--     # find which IR matched entry has any same start coord -->
<!--     tibble_ref_gtf_subset_IR_overlap_start.matched <- dplyr::semi_join(tibble_ref_gtf_subset_IR_overlap, vector_junction_matched_start_coords) -->

<!--     # extract all the end coords of the junction-matched entries -->
<!--     vector_junction_matched_end_coords <- tibble_ref_gtf_subset_junction_matching_entries[, "end"] -->
<!--     # find which IR matched entry has any same end coord -->
<!--     tibble_ref_gtf_subset_IR_overlap_end.matched <- dplyr::semi_join(tibble_ref_gtf_subset_IR_overlap, vector_junction_matched_end_coords) -->

<!--     # extract all the gene names of the junction-matched entries -->
<!--     vector_junction_matched_gene_names <- tibble_ref_gtf_subset_junction_matching_entries[, "gene_name"] -->
<!--     # find which IR matched entry has any same gene name -->
<!--     tibble_ref_gtf_subset_IR_overlap_gene.name.matched <- dplyr::semi_join(tibble_ref_gtf_subset_IR_overlap, vector_junction_matched_gene_names) -->

<!--     tibble_union_start.and.end.matched <- list(tibble_ref_gtf_subset_IR_overlap_start.matched,  -->
<!--                                                tibble_ref_gtf_subset_IR_overlap_end.matched, -->
<!--                                                tibble_ref_gtf_subset_IR_overlap_gene.name.matched) %>% purrr::reduce(dplyr::union) -->

<!--     if (nrow(tibble_union_start.and.end.matched) == 0) { -->

<!--       tibble_all_confirmed_IR_entries_ref <- "uninit" -->

<!--     } else if (nrow(tibble_union_start.and.end.matched) > 0) { -->

<!--       tibble_all_confirmed_IR_entries_ref <- tibble_union_start.and.end.matched -->

<!--     } -->

<!--   } -->

<!--   # check recon annotation - but only if the junction was matched to recon in the first place. -->
<!--   tibble_all_confirmed_IR_entries_recon <- "uninit" -->

<!--   if (all(is.na(vec_recon_transcripts_matched_to_junction)) != TRUE) { -->

<!--     # match IR region to recon GTF -->
<!--     tibble_recon_gtf_subset_IR_overlap <- tibble_recon_gtf[tibble_recon_gtf$seqnames == chr %>% trimws, ] %>% .[.$strand == strand %>% trimws, ] %>% .[.$start <= ((start %>% as.numeric) - 2) & .$end >= ((end %>% as.numeric) + 2), ] %>% .[.$type == "exon", ] -->

<!--     # get all the entries which matched to the junction -->
<!--     tibble_recon_gtf_subset_junction_matching_entries <- tibble_recon_gtf[tibble_recon_gtf$type == "exon", ] %>% .[which(.$transcript_id %in% vec_recon_transcripts_matched_to_junction), ] -->

<!--     # extract all the start coords of the junction-matched entries -->
<!--     vector_junction_matched_start_coords <- tibble_recon_gtf_subset_junction_matching_entries[, "start"] -->
<!--     # find which IR matched entry has any same start coord -->
<!--     tibble_recon_gtf_subset_IR_overlap_start.matched <- dplyr::semi_join(tibble_recon_gtf_subset_IR_overlap, vector_junction_matched_start_coords) -->

<!--     # extract all the end coords of the junction-matched entries -->
<!--     vector_junction_matched_end_coords <- tibble_recon_gtf_subset_junction_matching_entries[, "end"] -->
<!--     # find which IR matched entry has any same end coord -->
<!--     tibble_recon_gtf_subset_IR_overlap_end.matched <- dplyr::semi_join(tibble_recon_gtf_subset_IR_overlap, vector_junction_matched_end_coords, by = "end") -->

<!--     tibble_union_start.and.end.matched <- list(tibble_recon_gtf_subset_IR_overlap_start.matched,  -->
<!--                                                tibble_recon_gtf_subset_IR_overlap_end.matched) %>% purrr::reduce(dplyr::union) -->

<!--     if (nrow(tibble_union_start.and.end.matched) == 0) { -->

<!--       tibble_all_confirmed_IR_entries_recon <- "uninit" -->

<!--     } else if (nrow(tibble_union_start.and.end.matched) > 0) { -->

<!--       tibble_all_confirmed_IR_entries_recon <- tibble_union_start.and.end.matched -->

<!--     } -->

<!--   } -->

<!--   # we now have enough info. to write up the final summary -->
<!--   summarised_tibble_annotation <- tibble("AS_event_ID" = .x,  -->
<!--                                          "contributing_junction_IDs" = subset_tibble_annotation$junction_ID %>% paste(collapse = ";"), -->
<!--                                          "chr" = subset_tibble_annotation$chr %>% paste(collapse = ";"), -->
<!--                                          "start" = subset_tibble_annotation$start %>% paste(collapse = ";"), -->
<!--                                          "end" = subset_tibble_annotation$end %>% paste(collapse = ";"), -->
<!--                                          "strand" = subset_tibble_annotation$strand %>% paste(collapse = ";"), -->
<!--                                          "matched_gene_names" = subset_tibble_annotation$matched_gene_names %>% paste(collapse = ";"), -->
<!--                                          "matched_ref_transcript_names" = if (tibble_all_confirmed_IR_entries_ref != "uninit"){tibble_all_confirmed_IR_entries_ref$transcript_id %>% paste(collapse = ";")} else {subset_tibble_annotation$matched_ref_transcript_names %>% paste(collapse = ";")}, -->
<!--                                          "matched_recon_transcript_names" = if (tibble_all_confirmed_IR_entries_recon != "uninit"){tibble_all_confirmed_IR_entries_recon$transcript_id %>% paste(collapse = ";")} else {subset_tibble_annotation$matched_recon_transcript_names %>% paste(collapse = ";")}, -->
<!--                                          "NMD_biotype_reference" = if (tibble_all_confirmed_IR_entries_ref == "uninit") { -->
<!--                                            FALSE -->
<!--                                          } else { -->
<!--                                            all(tibble_all_confirmed_IR_entries_ref$transcript_biotype == "nonsense_mediated_decay") -->
<!--                                          }, -->
<!--                                          "NMD_flagged_ref" = if (tibble_all_confirmed_IR_entries_ref == "uninit") { -->
<!--                                            FALSE -->
<!--                                          } else { -->
<!--                                            all(tibble_all_confirmed_IR_entries_ref$NMD_candidate == TRUE) -->
<!--                                          }, -->
<!--                                          "NMD_flagged_recon" = if (tibble_all_confirmed_IR_entries_recon == "uninit") { -->
<!--                                            FALSE -->
<!--                                          } else { -->
<!--                                            all(tibble_all_confirmed_IR_entries_recon$NMD_candidate == TRUE) -->
<!--                                          }, -->
<!--                                          "poison_exon_candidate_ref" = if (tibble_all_confirmed_IR_entries_ref == "uninit") { -->
<!--                                            FALSE -->
<!--                                          } else { -->
<!--                                            any(tibble_all_confirmed_IR_entries_ref$poison_exon_candidate == TRUE) -->
<!--                                          }, -->
<!--                                          "poison_exon_candidate_recon" = if (tibble_all_confirmed_IR_entries_recon == "uninit") { -->
<!--                                            FALSE -->
<!--                                          } else { -->
<!--                                            any(tibble_all_confirmed_IR_entries_recon$poison_exon_candidate == TRUE) -->
<!--                                          }, -->
<!--                                          "contains_PTC_ref" = if (tibble_all_confirmed_IR_entries_ref == "uninit") { -->
<!--                                            FALSE -->
<!--                                          } else { -->
<!--                                            any(tibble_all_confirmed_IR_entries_ref$contains_PTC == TRUE) -->
<!--                                          }, -->
<!--                                          "contains_PTC_recon" = if (tibble_all_confirmed_IR_entries_recon == "uninit") { -->
<!--                                            FALSE -->
<!--                                          } else { -->
<!--                                            any(tibble_all_confirmed_IR_entries_recon$contains_PTC == TRUE) -->
<!--                                          }, -->
<!--                                          "first_or_last_exon_reference" = subset_tibble_annotation$first_or_last_exon_reference %>% paste(collapse = ";"), -->
<!--                                          "first_or_last_exon_recon" = subset_tibble_annotation$first_or_last_exon_recon %>% paste(collapse = ";"), -->
<!--                                          "any_first_exon" = any(c(grep(x = subset_tibble_annotation$first_or_last_exon_reference, pattern = "first_exon") %>% na.omit,  -->
<!--                                                                   grep(x = subset_tibble_annotation$first_or_last_exon_recon, pattern = "first_exon") %>% na.omit)), -->
<!--                                          "any_last_exon" = any(c(grep(x = subset_tibble_annotation$first_or_last_exon_reference, pattern = "last_exon") %>% na.omit,  -->
<!--                                                                  grep(x = subset_tibble_annotation$first_or_last_exon_recon, pattern = "last_exon") %>% na.omit)) -->
<!--   ) %>% add_column("any_NMD" = any(c(grep(x = .$NMD_flagged_ref, pattern = "TRUE") %>% na.omit, -->
<!--                                      grep(x = .$NMD_flagged_recon, pattern = "TRUE") %>% na.omit)), .after = "NMD_flagged_recon") -->

<!--   return(summarised_tibble_annotation) -->

<!-- }, .progress = TRUE, .options = future_options(globals = c("tibble_of_AS.event.ID_joined_to_annotation", "dplyr", "tibble", "data.table", "tibble_ref_gtf", "tibble_recon_gtf"))) -->

<!-- # , .options = future_options(globals = c("tibble_ref_gtf", "tibble_recon_gtf", "tibble_of_AS.event.ID_joined_to_annotation", "tibble::enframe")) -->

<!-- tibble_as.event.id_with_summarised_annotation_IR <- list_as.event.id_with_summarised_annotation_IR %>% rbindlist %>% as_tibble -->

<!-- ``` -->

# dpsi

## import dpsi tables

```{r}

options(mc.cores = 32)

list_tibbles_dpsi <- furrr::future_map2(
  .x = list.files(path = paste(majiq_results_dir, "deltapsi/", sep = ""), pattern = ".*0.15\\.tsv", recursive = FALSE, full.names = TRUE, include.dirs = FALSE),
  .y = list.files(path = paste(majiq_results_dir, "deltapsi/", sep = ""), pattern = ".*0.15\\.tsv", recursive = FALSE, full.names = FALSE, include.dirs = FALSE),
  .f = function(a1, a2) {
    
    # DEBUG ###
    # a1 <- list.files(path = paste(majiq_results_dir, "deltapsi/", sep = ""), pattern = ".*\\.tsv", recursive = FALSE, full.names = TRUE, include.dirs = FALSE) %>% .[1]
    # a2 <- list.files(path = paste(majiq_results_dir, "deltapsi/", sep = ""), pattern = ".*\\.tsv", recursive = FALSE, full.names = FALSE, include.dirs = FALSE) %>% .[1]
    ###########
    
    # create comparison name: MAJIQ does comparisons by doing 2nd minus 1st.
    # comparison 1 and 2: the same order as they were declared by the user.
    string_comparison_name <- a2 %>% gsub(pattern = "([^\\_]+)\\_([^\\_]+)\\.deltapsi\\_0\\.15\\.tsv", replacement = "\\2_minus_\\1")
    
    string_comparison_1_name <- a2 %>% gsub(pattern = "([^\\_]+)\\_([^\\_]+)\\.deltapsi\\_0\\.15\\.tsv", replacement = "\\1")
    
    string_comparison_2_name <- a2 %>% gsub(pattern = "([^\\_]+)\\_([^\\_]+)\\.deltapsi\\_0\\.15\\.tsv", replacement = "\\2")
    
    tibble_majiq_deltapsi <- data.table::fread(file = a1, header = TRUE, sep = "\t", stringsAsFactors = FALSE, check.names = FALSE, na.strings = c("na", "NA", "N/A", ""), skip = 10) %>% 
      as_tibble
    
    # # add gene names using reference
    # tibble_ref_gtf <- rtracklayer::import(tibble_ref_gtf_path) %>% as_tibble
    
    tibble_majiq_dpsi_old <- read.delim(file = gsub(x = a1, pattern = "\\_0\\.15", replacement = ""), header = TRUE, sep = "\t", stringsAsFactors = FALSE, check.names = FALSE, na.strings = c("na", "NA", "N/A", "")) %>% 
      tibble::as_tibble() %>% dplyr::select(`Gene ID`, `LSV ID`, `A5SS`, `A3SS`, `ES`) %>% dplyr::rename("gene_id" = "Gene ID", "lsv_id" = "LSV ID")
    
    tibble_raw_counts <- data.table::fread(file = paste(R_processing_results_dir, vector_experiment_metadata_initial %>% paste(collapse = "_"), "_temp_tibble_raw_counts.txt", sep = ""), sep = "\t", stringsAsFactors = FALSE, header = TRUE, check.names = FALSE) %>% 
      tibble::as_tibble() %>%
      dplyr::rename("gene_id" = "Gene ID")
    
    tibble_gene_names <- tibble_majiq_deltapsi %>%
      dplyr::left_join(., tibble_majiq_dpsi_old) %>%
      dplyr::mutate("gene_id" = gsub(x = `gene_id`, pattern = "gene\\:", replacement = "")) %>%
      dplyr::rename("chr" = "seqid", "LSV ID" = "lsv_id") %>%
      dplyr::select(-lsv_type, -num_junctions, -num_exons, -exons_coords, -ucsc_lsv_link) %>%
      dplyr::mutate(
        "comparison_name" = string_comparison_name,
        "comparison_1" = string_comparison_1_name,
        "comparison_2" = string_comparison_2_name)
    
    # rename mean_psi columns to be non-sample type specific
    colnames(tibble_gene_names)[grep(x = colnames(tibble_gene_names), pattern = "mean_psi")] <- paste("mean_psi_", c(1, 2), sep = "")
    
    # separate the junctions and IR coords columns into a long tibble
    long_tibble0 <- tibble_gene_names %>%
      split_delimited_columns_in_table(input_table = ., target_colname = c(colnames(tibble_gene_names)[grepl(x = colnames(tibble_gene_names), pattern = "psi", ignore.case = FALSE) | grepl(x = colnames(tibble_gene_names), pattern = "probability", ignore.case = FALSE) ], "de_novo_junctions", "junctions_coords"), split = "\\;")
      
    long_tibble1 <- dplyr::bind_rows(
      long_tibble0[!is.na(long_tibble0$`ir_coords`), ] %>% dplyr::select(-`junctions_coords`) %>% dplyr::mutate("junc_or_IR" = "IR") %>% dplyr::rename("junc_IR_coords" = "ir_coords"),
      long_tibble0[!is.na(long_tibble0$`ir_coords`), ] %>% dplyr::select(-`ir_coords`) %>% dplyr::mutate("junc_or_IR" = "junc") %>% dplyr::rename("junc_IR_coords" = "junctions_coords")
    )
    
    # only the PSI values attributed to "junctions" actually describe IR.
    # therefore we group up every chr/junc_ir_coords and if there is mixed IR and junction event, it must be an IR event.
    # in those cases, we will rename junction coord as IR.
    long_tibble_split_by_chr_coords <- purrr::map(
      .x = long_tibble1 %>% dplyr::group_split(`LSV ID`, `chr`, `junc_IR_coords`),
      .f = function(a1) {
        
        # DEBUG ###
        # a1 <- long_tibble1 %>% dplyr::group_split(`LSV ID`, `chr`, `junc_IR_coords`) %>% .[[2]]
        ###########
        
        # test %>% purrr::map(~any(.x$junc_or_IR == "IR")) %>% unlist %>% which
        
        if (any(a1$junc_or_IR == "IR")) {
          return(a1[a1$junc_or_IR == "junc", ] %>% .[1, ] %>% dplyr::mutate("junc_or_IR" = "IR"))
        } else {
          return(a1)
        }
        
      } )
    
    long_tibble <- long_tibble_split_by_chr_coords %>% 
      data.table::rbindlist() %>% 
      tibble::as_tibble() %>% 
      unique %>% 
      dplyr::distinct(`LSV ID`, `junc_IR_coords`, `chr`, `junc_or_IR`, .keep_all = TRUE) %>%
      readr::type_convert() %>% 
      dplyr::mutate("junc_IR_coords_start" = gsub(x = `junc_IR_coords`, pattern = "([^\\-]+)\\-([^\\-]+)", replacement = "\\1") %>% type.convert, "junc_IR_coords_end" = gsub(x = `junc_IR_coords`, pattern = "([^\\-]+)\\-([^\\-]+)", replacement = "\\2") %>% type.convert)
    
    return(long_tibble)
    
  }, .progress = TRUE )

```

## make long and wide tables

### long

```{r}

long_tibble_dpsi <- list_tibbles_dpsi %>%
  data.table::rbindlist(use.names = TRUE, fill = TRUE) %>% 
  as_tibble %>%
  dplyr::left_join(., wide_tibble_psi[, c("chr", "strand", "junc_IR_coords", "VSR_coords")] %>% unique)

data.table::fwrite(x = long_tibble_dpsi, file = paste(R_processing_results_dir, vector_experiment_metadata_initial %>% paste(collapse = "_"), "_long_tibble_dpsi.txt", sep = ""), sep = "\t", quote = FALSE, row.names = FALSE, col.names = TRUE)

```

### wide 

```{r}

list_tibbles_dpsi_prepare_for_wide <- purrr::map(
  .x = list_tibbles_dpsi,
  .f = function(a1) {
    
    # DEBUG ###
    # a1 <- list_majiq_psi_filtered_by_read_counts[[1]]
    ###########
    
    comparison_name <- a1$comparison_name %>% unique
    
    colnames(a1)[grepl(x = colnames(a1), pattern = "probability") | grepl(x = colnames(a1), pattern = "psi") | grepl(x = colnames(a1), pattern = "de\\_novo\\_junctions")] <- paste(colnames(a1)[grepl(x = colnames(a1), pattern = "probability") | grepl(x = colnames(a1), pattern = "psi") | grepl(x = colnames(a1), pattern = "de\\_novo\\_junctions")], "_", comparison_name, sep = "")
    
    a1 <- a1 %>% dplyr::select(-comparison_name, -comparison_1, -comparison_2)
    
    return(a1)
    
  } )

# full_join all tables
wide_tibble_dpsi0 <- list_tibbles_dpsi_prepare_for_wide %>% 
  purrr::reduce(dplyr::full_join)

# remove junctions with zero read counts - dw we decided to keep them because each junction reflects a different isoform of origin
# wide_tibble_dpsi <- wide_tibble_dpsi[!wide_tibble_dpsi %>% dplyr::arrange(gene_name) %>% dplyr::select(contains("read_counts")) %>% rowMeans(na.rm = TRUE) %>% is.na, ]

colnames(wide_tibble_dpsi0) <- gsub(x = colnames(wide_tibble_dpsi0), pattern = "24h", replacement = "1d")
colnames(wide_tibble_dpsi0) <- gsub(x = colnames(wide_tibble_dpsi0), pattern = "ud", replacement = "MSC")

# add VSR info
wide_tibble_dpsi <- wide_tibble_dpsi0 %>%
  dplyr::left_join(., wide_tibble_psi[, c("chr", "strand", "junc_IR_coords", "VSR_coords")] %>% unique)

data.table::fwrite(x = wide_tibble_dpsi, file = paste(R_processing_results_dir, vector_experiment_metadata_initial %>% paste(collapse = "_"), "_wide_tibble_dpsi.txt", sep = ""), sep = "\t", quote = FALSE, row.names = FALSE, col.names = TRUE)

```

## extract differentially spliced LSVs

```{r}

wide_tibble_dpsi <- data.table::fread(file = paste(R_processing_results_dir, vector_experiment_metadata_initial %>% paste(collapse = "_"), "_wide_tibble_dpsi.txt", sep = ""), sep = "\t", stringsAsFactors = FALSE, header = TRUE) %>% as_tibble

```

## plot the pvalue, qvalue and dpsi distributions

### pvalue

```{r}

# plot the pvalue distribution - density - PSI > 0.15
pdf(paste(R_processing_results_dir, vector_experiment_metadata_initial %>% paste(collapse = "_"), "_pvalue_density_distribution_psigt0.15_allsamples_alllsvs.pdf", sep = ""))
  plot(density(wide_tibble_dpsi %>% dplyr::select(contains("probability_changing")) %>% unlist %>% na.omit), main = paste("P-value (P(|dPSI|>=0.15)) density distribution"), xlab = "pvalue", ylab = "frequency density")
dev.off()

# plot the pvalue distribution - CDF - PSI > 0.15
pdf(paste(R_processing_results_dir, vector_experiment_metadata_initial %>% paste(collapse = "_"), "_pvalue_cdf_distribution_psigt0.15_allsamples_alllsvs.pdf", sep = ""))
  plot(ecdf(wide_tibble_dpsi %>% dplyr::select(contains("probability_changing")) %>% unlist %>% na.omit), main = paste("P-value (P(|dPSI|>=0.15)) cdf distribution"), xlab = "pvalue", ylab = "cumulative frequency")
dev.off()

# plot the pvalue distribution - density - PSI < 0.05
pdf(paste(R_processing_results_dir, vector_experiment_metadata_initial %>% paste(collapse = "_"), "_pvalue_density_distribution_psilt0.05_allsamples_alllsvs.pdf", sep = ""))
  plot(density(wide_tibble_dpsi %>% dplyr::select(contains("probability_non_changing")) %>% unlist %>% na.omit), main = paste("P-value (P(|dPSI|<=0.05)) density distribution"), xlab = "pvalue", ylab = "frequency density")
dev.off()

# plot the pvalue distribution - CDF - PSI < 0.05
pdf(paste(R_processing_results_dir, vector_experiment_metadata_initial %>% paste(collapse = "_"), "_pvalue_cdf_distribution_psilt0.05_allsamples_alllsvs.pdf", sep = ""))
  plot(ecdf(wide_tibble_dpsi %>% dplyr::select(contains("probability_non_changing")) %>% unlist %>% na.omit), main = paste("P-value (P(|dPSI|<=0.05)) cdf distribution"), xlab = "pvalue", ylab = "cumulative frequency")
dev.off()

```

### plot dpsi distributions

```{r}

pdf(paste(R_processing_results_dir, vector_experiment_metadata_initial %>% paste(collapse = "_"), "_absolute_dpsi_density_distribution.pdf", sep = ""), width = 5, height = 5)
plot(density((100 * (wide_tibble_dpsi %>% dplyr::select(contains("dpsi")) %>% unlist %>% na.omit %>% abs)), bw = 1), 
     main = "Distribution of absolute magnitude of change in psi, MAJIQ", 
     xlab = "Absolute dPSI in any direction (%)",
     ylab = "Frequency density",
     col = "magenta", 
     xaxt = "n",
     xlim = c(0, 100)) + 
  polygon(density((100 * (wide_tibble_dpsi %>% dplyr::select(contains("dpsi")) %>% unlist %>% na.omit %>% abs)), bw = 1),
          col = alpha("magenta", 0.33),
          border = FALSE,
          xaxt = "n",
          xlim = c(0, 100)) +
  axis(side = 1, at = seq(0, 100, by = 20), labels = seq(0, 100, by = 20))
dev.off()

# plot the dpsi distribution - density
pdf(paste(R_processing_results_dir, vector_experiment_metadata_initial %>% paste(collapse = "_"), "_dpsi_density_distribution.pdf", sep = ""))
  plot(density((100 * (wide_tibble_dpsi %>% dplyr::select(contains("dpsi")) %>% unlist %>% na.omit)), bw = 1), xlim = c(-100, 100), main = paste("MAJIQ dpsi density distribution"), xlab = "dpsi", ylab = "frequency density")
dev.off()

# plot the dpsi distribution - cdf
pdf(paste(R_processing_results_dir, vector_experiment_metadata_initial %>% paste(collapse = "_"), "_dpsi_cdf_distribution.pdf", sep = ""))
  plot(ecdf((100 * (wide_tibble_dpsi %>% dplyr::select(contains("dpsi")) %>% unlist %>% na.omit))), xlim = c(-100, 100), main = paste("MAJIQ dpsi cdf distribution"), xlab = "dpsi", ylab = "cumulative frequency")
  axis(side = 2, at = seq(0, 1, by = 0.1))
dev.off()

```

## filter tables for the specified cutoffs, both with and without NA.

### specify differential and constitutive cutoffs

```{r}

vector_experiment_metadata_main <- vector_experiment_metadata_initial

differential_probability_cutoff <- 0.8

constitutive_probability_cutoff <- 0.8

vector_experiment_metadata_main <- c(vector_experiment_metadata_main, paste("diff", differential_probability_cutoff, sep = ""), paste("cons", constitutive_probability_cutoff, sep = ""))

```

### do the filtering of differential junctions

```{r}

row_indices_wide_tibble_dpsi_differential_entries <- apply(
  X = wide_tibble_dpsi %>% dplyr::select(contains("probability_changing")),
  MARGIN = 1,
  FUN = function(X) {
    return(any(X %>% na.omit %>% type.convert() >= differential_probability_cutoff))
  } ) %>% which %>% 
  suppressMessages() %>% suppressWarnings() 

row_indices_wide_tibble_dpsi_constitutive_entries <- apply(
  X = wide_tibble_dpsi %>% dplyr::select(contains("probability_non_changing")),
  MARGIN = 1,
  FUN = function(X) {
    return(all(X %>% na.omit %>% type.convert() >= constitutive_probability_cutoff))
  } ) %>% which %>% 
  suppressMessages() %>% suppressWarnings() 

row_indices_wide_tibble_dpsi_non_na_entries <- apply(
  X = wide_tibble_dpsi %>% dplyr::select(contains("probability_non_changing")),
  MARGIN = 1,
  FUN = function(X) {
    return(all(X %>% is.na == FALSE))
  } ) %>% which %>% 
  suppressMessages() %>% suppressWarnings() 

wide_tibble_dpsi_differential <- wide_tibble_dpsi[row_indices_wide_tibble_dpsi_differential_entries, ]

wide_tibble_dpsi_constitutive <- wide_tibble_dpsi[intersect(row_indices_wide_tibble_dpsi_constitutive_entries, row_indices_wide_tibble_dpsi_non_na_entries), ]

write.table(x = wide_tibble_dpsi_differential, file = paste(R_processing_results_dir, vector_experiment_metadata_main %>% paste(collapse = "_"), "_wide_tibble_dpsi_differential.txt", sep = ""), sep = "\t", row.names = FALSE, quote = FALSE)

write.table(x = wide_tibble_dpsi_constitutive, file = paste(R_processing_results_dir, vector_experiment_metadata_main %>% paste(collapse = "_"), "_wide_tibble_dpsi_constitutive.txt", sep = ""), sep = "\t", row.names = FALSE, quote = FALSE)

```

### plot graph of the cumulative changes

#### create tibble of cumulative differential changes, excluding each timepoint successively

```{r eval=FALSE, include=FALSE}

tibble_cumulative_diff_changes <- tibble("timepoint" = vector_OBseries_timepoints_edited, 
                                         "cumulative_diff_changes" = 
                                           c(0, 
                                             wide_tibble_dpsi_differential %>% dplyr::select(contains("probability_changing")) %>% dplyr::select(-matches("probability_changing.*12d"), -matches("probability_changing.*9d"), -matches("probability_changing.*6d"), -matches("probability_changing.*3d"), -matches("probability_changing.*1d"), -matches("probability_changing.*12h")) %>% dplyr::select(contains("probability_changing")) %>% .[apply(X = ., MARGIN = 1, FUN = function(X) {return(any(X %>% na.omit %>% type.convert() >= differential_probability_cutoff))} ) %>% which(), ] %>% nrow,
                                             wide_tibble_dpsi_differential %>% dplyr::select(contains("probability_changing")) %>% dplyr::select(-matches("probability_changing.*12d"), -matches("probability_changing.*9d"), -matches("probability_changing.*6d"), -matches("probability_changing.*3d"), -matches("probability_changing.*1d")) %>% dplyr::select(contains("probability_changing")) %>% .[apply(X = ., MARGIN = 1, FUN = function(X) {return(any(X %>% na.omit %>% type.convert() >= differential_probability_cutoff))} ) %>% which(), ] %>% nrow,
                                             wide_tibble_dpsi_differential %>% dplyr::select(contains("probability_changing")) %>% dplyr::select(-matches("probability_changing.*12d"), -matches("probability_changing.*9d"), -matches("probability_changing.*6d"), -matches("probability_changing.*3d")) %>% dplyr::select(contains("probability_changing")) %>% .[apply(X = ., MARGIN = 1, FUN = function(X) {return(any(X %>% na.omit %>% type.convert() >= differential_probability_cutoff))} ) %>% which(), ] %>% nrow,
                                             wide_tibble_dpsi_differential %>% dplyr::select(contains("probability_changing")) %>% dplyr::select(-matches("probability_changing.*12d"), -matches("probability_changing.*9d"), -matches("probability_changing.*6d")) %>% dplyr::select(contains("probability_changing")) %>% .[apply(X = ., MARGIN = 1, FUN = function(X) {return(any(X %>% na.omit %>% type.convert() >= differential_probability_cutoff))} ) %>% which(), ] %>% nrow,
                                             wide_tibble_dpsi_differential %>% dplyr::select(contains("probability_changing")) %>% dplyr::select(-matches("probability_changing.*12d"), -matches("probability_changing.*9d")) %>% dplyr::select(contains("probability_changing")) %>% .[apply(X = ., MARGIN = 1, FUN = function(X) {return(any(X %>% na.omit %>% type.convert() >= differential_probability_cutoff))} ) %>% which(), ] %>% nrow,
                                             wide_tibble_dpsi_differential %>% dplyr::select(contains("probability_changing")) %>% dplyr::select(-matches("probability_changing.*12d"))%>% dplyr::select(contains("probability_changing")) %>% .[apply(X = ., MARGIN = 1, FUN = function(X) {return(any(X %>% na.omit %>% type.convert() >= differential_probability_cutoff))} ) %>% which(), ] %>% nrow,
                                             wide_tibble_dpsi_differential %>% dplyr::select(contains("probability_changing")) %>% nrow
                                           )
                                         ) %>% 
  add_column("cumulative_diff_changes_pct" = .$cumulative_diff_changes * 100 / (.$cumulative_diff_changes %>% max)) %>% 
  suppressMessages() %>% suppressWarnings()

```

#### GGPLOT

```{r}

ggplot_cumulative_diff_changes <- ggplot(tibble_cumulative_diff_changes, aes(y = cumulative_diff_changes_pct, x = timepoint)) +
  geom_path(aes(group = "OB series"), colour = "purple3") +
  ggtitle("Cumulative changes in the hMSC-TERT4 spliceome\nOsteogenesis\nMAJIQ (table entries)") +
  xlab("Timepoint") +
  ylab("Cumulative differential changes (%)") +
  scale_x_discrete(limits = vector_OBseries_timepoints_edited, labels = vector_OBseries_timepoints_edited) +
  theme_bw() +
  theme(text = element_text(family = "Helvetica"))
  
ggplot_cumulative_diff_changes

ggsave(plot = ggplot_cumulative_diff_changes, filename = paste(R_processing_results_dir, vector_experiment_metadata_main %>% paste(collapse = "_"), "_linegraph_cumulative_diff_changes.pdf", sep = ""), device = "pdf", dpi = 600, width = 10, height = 12, units = "cm")

```

# DRAWING SOMS TO ANALYSE TIME SERIES DATA

## scale PSI values

```{r}

wide_tibble_psi <- data.table::fread(file = paste(R_processing_results_dir, vector_experiment_metadata_initial %>% paste(collapse = "_"), "_wide_tibble_psi.txt", sep = ""), sep = "\t", stringsAsFactors = FALSE, header = TRUE) %>% as_tibble %>% type_convert

wide_tibble_psi_differential <- dplyr::semi_join(wide_tibble_psi, wide_tibble_dpsi_differential)

# extract the PSI values only into a matrix tibble
tibble_matrix_psi_differential0 <- wide_tibble_psi_differential %>% dplyr::select(contains("mean_psi"))

# take the average of all replicates
tibble_matrix_psi_differential <- purrr::map(.x = vector_OBseries_timepoints_edited, .f = ~tibble_matrix_psi_differential0 %>% dplyr::select(contains(paste("BM_MSC_to_OB_", .x, sep = ""))) %>% rowMeans(na.rm = TRUE) %>% tibble::as.tibble() %>% setNames(nm = .x)) %>% purrr::set_names(nm = vector_OBseries_timepoints_edited) %>% purrr::reduce(dplyr::bind_cols)

# scale values
tibble_matrix_psi_differential_scaled <- tibble_matrix_psi_differential %>% genescale(m = ., axis = 1, method = "Z") %>% tibble::as_tibble()

# remove na
vector_row_indices_no_na <- tibble_matrix_psi_differential_scaled %>% add_column("id" = rownames(.)) %>% na.omit %>% .$id

# add back in the annotations
tibble_matrix_psi_differential_scaled <- dplyr::bind_cols(wide_tibble_psi_differential %>% dplyr::select(-contains("psi"), -contains("read_counts")), tibble_matrix_psi_differential_scaled)

tibble_matrix_psi_differential_scaled <- tibble_matrix_psi_differential_scaled[vector_row_indices_no_na, ]

# write table
write.table(x = tibble_matrix_psi_differential_scaled, file = paste(R_processing_results_dir, vector_experiment_metadata_main %>% paste(collapse = "_"), "_tibble_matrix_psi_differential_scaled.txt", sep = ""), sep = "\t", row.names = FALSE, quote = FALSE)

```

## construction of a 5x5 SOM

```{r}

som_seed_number <- 8

som_xdim <- 5
som_ydim <- 5

number_of_som_clusters <- som_xdim * som_ydim

set.seed(som_seed_number)

kohonen_som_result_5_by_5 <- som(tibble_matrix_psi_differential_scaled[, vector_OBseries_timepoints_edited] %>% as.matrix, grid = somgrid(xdim = som_xdim, ydim = som_ydim, topo = "rectangular", toroidal = FALSE), rlen = 100, keep.data = TRUE)

wide_tibble_SOM_summary_5_by_5 <- cbind(tibble_matrix_psi_differential_scaled, "som_cluster" = kohonen_som_result_5_by_5[["unit.classif"]]) %>% tibble::as_tibble()

```

### convert the som table to a long form interprable by ggplot

Steps:

0. Melt wide table into long form
1. Subtract 1 from the som_cluster number
2. x-facet is the remainder when mod 5
3. y-facet is the quotient when mod 5
4. in ggplot, the numbers go from 1-5 from top left to top right, then 6-10 on second row left-right... 25 will be bottom right.

```{r}

# OB series #####

# reshaping into long table

long_tibble_SOM_summary_5_by_5 <- reshape2::melt(wide_tibble_SOM_summary_5_by_5, id.vars = colnames(wide_tibble_SOM_summary_5_by_5)[!colnames(wide_tibble_SOM_summary_5_by_5) %in% vector_OBseries_timepoints_edited], variable.name = "timepoint", value.name = "scaled_psi_value") %>% tibble::as_tibble()

# calculating the facet coordinates for 5x5 plot in ggplot

long_tibble_SOM_summary_5_by_5[, "cluster_minus_1"] <- long_tibble_SOM_summary_5_by_5$som_cluster - 1

long_tibble_SOM_summary_5_by_5[, "remainder_facet.x"] <- long_tibble_SOM_summary_5_by_5$cluster_minus_1 %% 5

long_tibble_SOM_summary_5_by_5[, "quotient_facet.y"] <- long_tibble_SOM_summary_5_by_5$cluster_minus_1 %/% 5

# also create a tibble for the average line for each som_cluster
long_tibble_SOM_summary_5_by_5_average.line <- long_tibble_SOM_summary_5_by_5 %>% dplyr::group_by(som_cluster, timepoint, cluster_minus_1, remainder_facet.x, quotient_facet.y) %>% 
  dplyr::summarise("avg_psi_value" = mean(scaled_psi_value))

```

### THE GGPLOT

all the genes

```{r}

# OB series

ggplot_initial_som_plot <- ggplot() +
  geom_line(data = long_tibble_SOM_summary_5_by_5, aes(x = timepoint, y = scaled_psi_value, group = paste(`lsv_id`, "_", `junc_or_IR`, "_", `chr`, "_", `junc_IR_coords`, sep = "")), alpha = 0.33) +
  geom_line(data = long_tibble_SOM_summary_5_by_5_average.line, aes(x = timepoint, y = avg_psi_value, group = som_cluster), colour = "white", size = 1) +
  scale_colour_manual(values = c("black")) +
  facet_grid(quotient_facet.y ~ remainder_facet.x) +
  ggtitle(paste(som_xdim, "x", som_ydim, "SOM of", nrow(wide_tibble_SOM_summary_5_by_5), "LSV entries p({dPSI| >= 0.15) >=", differential_probability_cutoff)) +
  scale_x_discrete(limits = vector_OBseries_timepoints_edited, labels = vector_OBseries_timepoints_edited) +
  xlab("Time-point") +
  ylab("Scaled PSI Level") +
  # guides(colour = FALSE) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.background = element_rect(size = 0.5, linetype = "solid", colour = "black"), text = element_text(family="Helvetica"))

ggsave(plot = ggplot_initial_som_plot, filename = paste(R_processing_results_dir, vector_experiment_metadata_main %>% paste(collapse = "_"), "_", som_xdim, "x", som_ydim, "_initial_som.pdf", sep = ""), device = "pdf", dpi = 600, width = 33, height = 20, units = "cm")

write.table(x = wide_tibble_SOM_summary_5_by_5, file = paste(R_processing_results_dir, vector_experiment_metadata_main %>% paste(collapse = "_"), "_wide_tibble_", som_xdim, "x", som_ydim, "_initial_som.txt", sep = ""), sep = "\t", row.names = FALSE, quote = FALSE)

write.table(x = long_tibble_SOM_summary_5_by_5, file = paste(R_processing_results_dir, vector_experiment_metadata_main %>% paste(collapse = "_"), "_long_tibble_", som_xdim, "x", som_ydim, "_initial_som.txt", sep = ""), sep = "\t", row.names = FALSE, quote = FALSE)

```

# GENE ONTOLOGY

## load catdb

This gene background shall contain all ensembl protein coding, long noncoding and transcribed genes.

```{r}

# ensembl_mart = ensembl_mart = useMart(biomart = "ensembl", dataset = "hsapiens_gene_ensembl", version = 98)

# # GOTERM
# polyA_RNAseq_GO_background <- getBM(filters = "biotype", values = c("protein_coding", "long_noncoding", "transcribed_processed_gene", "transcribed_unitary_gene", "transcribed_unprocessed_gene", "translated_processed_gene"), attributes = c("external_gene_name", "go_id", "namespace_1003"), mart = ensembl_mart) %>% .[.$namespace_1003 != "",]
# 
# polyA_RNAseq_GO_background[, "namespace_1003"] <- as.character(polyA_RNAseq_GO_background[, "namespace_1003"])
# 
# write.table(x = polyA_RNAseq_GO_background, file = paste(R_processing_results_dir, "polyA_RNAseq_GO_background_GOTERM.txt", sep = ""), quote = FALSE, row.names = FALSE, col.names = FALSE, sep = "\t")

## Create catDB instance (takes a while but needs to be done only once)
# note: you had to save the GO annotation file to disk in the previous steps above
# catdb <- makeCATdb(myfile = paste(R_processing_results_dir, "polyA_RNAseq_GO_background_GOTERM.txt", sep = ""), lib = NULL, org = "", colno = c(2, 1, 3), idconv = NULL)

load(paste(reference_data_dir, "polyA_RNAseq_GO_background_GOTERM.catdb", sep = ""))

```

### hypergeometric test for GO terms

```{r}

plan(multicore)
options(mc.cores = 3)

list_tibbles_hypergo_result <- purrr::map(.x = c("BP", "CC", "MF"), .f = ~systemPipeR::GOHyperGAll(catdb = catdb, gocat = .x, sample = wide_tibble_SOM_summary_5_by_5$gene_name, Nannot = 2) %>% GOHyperGAll_benjamini_correction %>% tibble::as_tibble() %>% readr::type_convert(), .progress = TRUE) %>% set_names(nm = c("BP", "CC", "MF"))

tibble_hypergo_result_all_differential <- list_tibbles_hypergo_result %>% rbindlist %>%  as_tibble

```

#### bar graph of GO terms

```{r}

# OB series

# ggplot(tibble_hypergo_result, aes(x = reorder(Term, -Phyper), y = -log10(Phyper))) +
#   geom_col(aes(fill = SampleMatch)) +
#   scale_fill_distiller(name = "Number of genes enriched", type = "seq", palette = "Purples", direction = 1,   aesthetics = "fill", na.value = "yellow") +
#   geom_hline(yintercept = -log10(0.05), lty = 2) +
#   coord_flip() +
#   facet_wrap(Ont ~ ., ncol = 3, scales = "free_y") +
#   ggtitle(paste("Top 10 significantly over-represented GO terms for OB series for dPSI cutoff of", dPSI_cutoff, "and any sig", p_or_q_value, qpvalue_cutoff, "encompassing", numberofgenes_anysig, "genes")) +
#   xlab("GO term") +
#   ylab(expression(log["10"](P["b-hoch"]))) +
#   # coord_cartesian(ylim = c(0, 50)) +
#   theme_bw() +
#   theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.title.align = 0.5, legend.background = element_rect(size = 0.5, linetype = "solid", colour = "black"), text = element_text(family = "Helvetica")) +
#   ggsave(filename = paste(R_processing_results_dir, "Top 10 significantly over-represented GO terms for OB series dPSI_", dPSI_cutoff,  "_any", p_or_q_value, qpvalue_cutoff, "_", numberofgenes_anysig, "_genes_anysig_with_na.pdf", sep = ""), device = "pdf", dpi = 600, width = 50, height = 200, units = "cm", limitsize = FALSE) +
#   ggsave(filename = paste(R_processing_results_dir, "Top 10 significantly over-represented GO terms for OB series dPSI_", dPSI_cutoff,  "_any", p_or_q_value, qpvalue_cutoff, "_", numberofgenes_anysig, "_genes_anysig_with_na.svg", sep = ""), device = "svg", dpi = 600, width = 50, height = 200, units = "cm", limitsize = FALSE) 

# write the top everything enrichment table
write.table(x = tibble_hypergo_result_all_differential, file = paste(R_processing_results_dir, vector_experiment_metadata_main %>% paste(collapse = "_"), "_tibble_hypergo_result_all_differential.txt", sep = ""), sep = "\t", row.names = FALSE, quote = FALSE)

```

### Gene ontology of each SOM som_cluster

```{r}

plan(list(tweak(multicore, workers = 8),
          tweak(multicore, workers = 4)))

tibble_hypergo_result_differential_per_som_cluster <- furrr::future_map2(
  .x = wide_tibble_SOM_summary_5_by_5 %>% dplyr::group_split(som_cluster) %>% purrr::set_names(x = ., nm = purrr::map(.x = ., .f = ~.x$som_cluster %>% unique) %>% unlist),
  .y = wide_tibble_SOM_summary_5_by_5 %>% dplyr::group_split(som_cluster) %>% purrr::set_names(x = ., nm = purrr::map(.x = ., .f = ~.x$som_cluster %>% unique) %>% unlist) %>% names,
  .f = function(a1, a2) {
    
    furrr::future_map(
      .x = c("BP", "CC", "MF"),
      .f = function(b1) {
        
        systemPipeR::GOHyperGAll(catdb = catdb, gocat = b1, sample = a1$gene_name %>% unique, Nannot = 2) %>% 
          GOHyperGAll_benjamini_correction %>% 
          tibble::as_tibble() %>% 
          readr::type_convert() %>% 
          return
        
      } ) %>% rbindlist %>% as_tibble %>% 
      tibble::add_column("som_cluster" = a2) %>%
      return
    
  }, .progress = TRUE ) %>% rbindlist %>% as_tibble 

# purrr::map2(.x = list_of_som_hyperGOresult_allGO_clusterwise_tables_topten_2, .y = names(list_of_som_hyperGOresult_allGO_clusterwise_tables_topten_2), .f = ~ggplot(.x, aes(x = reorder(Term, -SampleMatch), y = SampleMatch)) +
#               geom_col(aes(fill = log10(Padj))) +
#               scale_fill_distiller(name = expression(log["10"](P)), type = "seq", palette = "Purples", direction = -1,   aesthetics = "fill", na.value = "yellow") +
#               facet_wrap(~som_cluster, scales = "free") +
#               ggtitle(paste("Top 10 significantly over-represented", .y, "GO terms for each som_cluster in OB series")) +
#               scale_x_discrete(labels = function(x) str_wrap(x, width = 35)) +
#               xlab("GO term") +
#               ylab("Number of genes in GO term") +
#               # coord_cartesian(ylim = c(0, 20)) +
#               theme_bw() +
#               theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 5, lineheight = 0.75, colour = "black"), legend.title.align = 0.5, legend.background = element_rect(size=0.5, linetype="solid", colour ="black"), strip.background = element_blank(), strip.text.x = element_blank(), axis.title.y = element_text(margin = margin(r = 20)), text = element_text(family="Helvetica")) +
#               ggsave(filename = paste(R_processing_results_dir, som_xdim, "x", som_ydim, "_SOM_", length(long_tibble_SOM_summary_5_by_5$AS_event_ID %>% unique), "_junctions_PSI_OB_diff_any_", p_or_q_value, qpvalue_cutoff, "_any_deltaPSI_greaterthan_", dPSI_cutoff, "_", .y, "_GO.pdf", sep = ""), device = "pdf", dpi = 600, width = 50, height = 30, units = "cm") +
#               ggsave(filename = paste(R_processing_results_dir, som_xdim, "x", som_ydim, "_SOM_", length(long_tibble_SOM_summary_5_by_5$AS_event_ID %>% unique), "_junctions_PSI_OB_diff_any_", p_or_q_value, qpvalue_cutoff, "_any_deltaPSI_greaterthan_", dPSI_cutoff, "_", .y, "_GO.svg", sep = ""), device = "svg", dpi = 600, width = 50, height = 30, units = "cm"))

# write table
write.table(x = tibble_hypergo_result_differential_per_som_cluster, file = paste(R_processing_results_dir, vector_experiment_metadata_main %>% paste(collapse = "_"), "_tibble_hypergo_result_differential_per_som_cluster.txt", sep = ""), sep = "\t", row.names = FALSE, quote = FALSE)

```

# JUNCTION ONTOLOGY

## retrieve whole biomart domain annotations from server and save

```{r}

# create a list of attributes to retrieve from biomart. we will loop thru this.
list_of_attributes_to_retrieve <- list("interpro" = c("ensembl_peptide_id", "interpro", "interpro_start", "interpro_end"),
                                       "ncoils" = c("ensembl_peptide_id", "ncoils_start", "ncoils_end"),
                                       "seg" = c("ensembl_peptide_id", "seg_start", "seg_end"),
                                       "signalp" = c("ensembl_peptide_id", "signalp_start", "signalp_end"),
                                       "tmhmm" = c("ensembl_peptide_id", "tmhmm_start", "tmhmm_end"),
                                       "sifts" = c("ensembl_peptide_id", "sifts_import", "sifts_import_start", "sifts_import_end"),
                                       "mobidblite" = c("ensembl_peptide_id", "mobidblite", "mobidblite_start", "mobidblite_end"))

```

```{r eval=FALSE, include=FALSE}

# query biomart
# list_of_tibbles_biomart_domain_annotation <- future_map(.x = list_of_attributes_to_retrieve, .f = ~getBM(attributes = .x, mart = ensembl_mart) %>% as_tibble %>% na.omit, .progress = TRUE, .options = future_options(globals = c("getBM", "ensembl_mart")))

# write tables
# future_map2(.x = list_of_tibbles_biomart_domain_annotation, .y = names(list_of_tibbles_biomart_domain_annotation), .f = ~write.table(.x, file = paste(shared_dir, "table_biomart_ENSP_to_", .y, ".txt", sep = ""), row.names = FALSE, col.names = TRUE, quote = FALSE, sep = "\t"), .progress = TRUE, .options = future_options(globals = FALSE))

```

```{r}

options(mc.cores = 10)

# read tables
list_of_tibbles_biomart_domain_annotation <- future_map(.x = names(list_of_attributes_to_retrieve), .f = ~read.delim(paste(reference_data_dir, "table_biomart_ENSP_to_", .x, "_38.98.txt", sep = ""), row.names = NULL, header = TRUE, sep = "\t", stringsAsFactors = FALSE) %>% as_tibble, .progress = TRUE, .options = future_options(globals = c("as_tibble", "shared_dir"))) %>% 
  set_names(names(list_of_attributes_to_retrieve))

# rename columns of each nested tibble to be consistent
list_of_tibbles_biomart_domain_annotation <- list_of_tibbles_biomart_domain_annotation %>% purrr::map(.f = function(.x) {
  
  output_tibble <- .x
  
  colnames(output_tibble) <- gsub(x = colnames(output_tibble), pattern = ".*start$", replacement = "start")
  colnames(output_tibble) <- gsub(x = colnames(output_tibble), pattern = ".*end$", replacement = "end")
  
  return(output_tibble)
  
} )

```

## retrieve whole biomart ENSP to uniprotkb entry ID mapping

```{r}

# tibble_ENSP_to_uniprotkb <- biomaRt::getBM(attributes = c("ensembl_peptide_id", "uniprotsptrembl"), mart = ensembl_mart) %>% setNames(c("ensembl_peptide_id", "uniprotkb_entry")) %>% 
# type_convert %>% 
# as_tibble %>%
# na.omit

# write table
# write.table(tibble_ENSP_to_uniprotkb, file = paste(shared_dir, "tibble_ENSP_to_uniprotkb_38.98.txt", sep = ""), row.names = FALSE, col.names = TRUE, quote = FALSE, sep = "\t")
# read table
# tibble_ENSP_to_uniprotkb <- read.delim(paste(shared_dir, "tibble_ENSP_to_uniprotkb_38.98.txt", sep = ""), row.names = NULL, header = TRUE, sep = "\t", stringsAsFactors = FALSE) %>% as_tibble

tibble_ENSP_to_uniprotkb <- read.delim(file = paste(reference_data_dir, "table_ENSP_to_uniprot_entry_mapping_38.98.txt", sep = ""), sep = "\t", stringsAsFactors = FALSE, header = TRUE, row.names = NULL) %>% as_tibble

```

## import GTF and process it into a nice table containing only character and numeric types

```{r eval=FALSE, include=FALSE}

# IMPORT GTF ANNOTATION OF TRANSCRIPT/EXON/PROTEIN CODING REGIONS ETC...

library(rtracklayer)

tibble_ref_gtf_original <- rtracklayer::import("/mnt/LTS/projects/2019_hmsc_spliceome/Kassem_OB/analysis_NMD_classifier/results/Homo_sapiens.GRCh38.98_NMD_PTC_E4.gtf") %>% as_tibble

# tibble_ref_gtf_original <- rtracklayer::import(paste(reference_data_dir, "hg38_ensembl_reference/gtf/Homo_sapiens.GRCh38.98_NMD_PTC_E4.gtf", sep = "")) %>% as_tibble
# tibble_ref_gtf_original <- rtracklayer::import("Z:/hg38_ensembl_reference/gtf/Homo_sapiens.GRCh38.98.gtf") %>% as_tibble

tibble_ref_gtf_original <- tibble_ref_gtf_original %>% dplyr::select(-source, -score, -gene_version, -gene_source, -transcript_version, -transcript_source, -tag, -transcript_support_level, -exon_version, -protein_version, -ccds_id) %>% unique

tibble_ref_gtf_original <- tibble_ref_gtf_original %>% mutate_if(is.factor, as.character)

# import dbPTM info
# Z:/dbPTM_download/extract/allPTM_human.txt
tibble_dbPTM_allhuman_annotations <- read.delim(paste(reference_data_dir, "dbPTM/extract/allPTM_human_filtered.txt", sep = ""), check.names = FALSE, na = c("NA", ""), sep = "\t", stringsAsFactors = FALSE) %>% as_tibble
# tibble_dbPTM_allhuman_annotations <- read.delim("Z:/dbPTM_download/extract/allPTM_human.txt", col.names = c("uniprotkb_entryname", "uniprotkb_entry", "modified_residue_position", "PTM_type", "pubmed_accessions", "context_sequence"), na = c("NA", ""), sep = "\t", stringsAsFactors = FALSE) %>% as_tibble

# import PhosphoSitePlus info
# Z:/phosphositeplus_phosphosites_human.tab
# tibble_phosphositeplus_allhuman_phosphosites <- read.delim("/mnt/Tertiary/sharedfolder/phosphositeplus_phosphosites_human.tab", col.names = c("gene_name", "protein_name", "uniprotkb_entry", "chr_locus", "modified_residue_position", "SITE_GRP_ID", "organism", "MW.kD", "domain", "site_7AA_either.side", "LT_LIT", "MS_LIT", "MS_CST", "CST_CAT"), na = c("NA", ""), sep = "\t", stringsAsFactors = FALSE) %>% as_tibble
# tibble_phosphositeplus_allhuman_phosphosites <- read.delim("Z:/phosphositeplus_phosphosites_human.tab", col.names = c("gene_name", "protein_name", "uniprotkb_entry", "chr_locus", "modified_residue_position", "SITE_GRP_ID", "organism", "MW.kD", "domain", "site_7AA_either.side", "LT_LIT", "MS_LIT", "MS_CST", "CST_CAT"), na = c("NA", ""), sep = "\t", stringsAsFactors = FALSE) %>% as_tibble

# change the residue position column
# tibble_phosphositeplus_allhuman_phosphosites[, "modified_residue_position"] <- gsub(x = tibble_phosphositeplus_allhuman_phosphosites$modified_residue_position, pattern = "^([A-Z])([0-9]{1,5})(.*)", replacement = "\\2")

# remove rows where phosphosite is NA
# row.indices_phosphosite.is.na <- which(is.na(tibble_phosphositeplus_allhuman_phosphosites$modified_residue_position))

# tibble_phosphositeplus_allhuman_phosphosites <- tibble_phosphositeplus_allhuman_phosphosites[-row.indices_phosphosite.is.na, ]

# RBIND THE PTM TABLES
# tibble_PTM_combined <- dplyr::bind_rows(tibble_dbPTM_allhuman_annotations, tibble_phosphositeplus_allhuman_phosphosites)
tibble_PTM_combined <- tibble_dbPTM_allhuman_annotations

```

## Import all the non-homolog and non-superfamily entries from Interpro

```{r}

tibble_non_family_interpro_entries <- c("interpro_active.site_entries.tsv", "interpro_binding.site_entries.tsv", "interpro_conserved.site_entries.tsv", "interpro_domain_entries.tsv", "interpro_PTM_entries.tsv", "interpro_repeat_entries.tsv") %>% 
  purrr::map(.f = ~read.delim(paste(reference_data_dir, .x, sep = ""), sep = "\t", row.names = NULL, header = TRUE, stringsAsFactors = FALSE, check.names = FALSE) %>% as_tibble) %>% rbindlist %>% as_tibble

```

## transcript and domain analyses! :)

NEW METHOD - USING CONSTITUENT JUNCTIONS

```{r message=FALSE, warning=FALSE}

wide_tibble_psi <- data.table::fread(file = paste(R_processing_results_dir, vector_experiment_metadata_initial %>% paste(collapse = "_"), "_wide_tibble_psi.txt", sep = ""), sep = "\t", stringsAsFactors = FALSE, header = TRUE) %>% as_tibble

# convert LSVs to VSRs
## construct an addition/subtraction flag table: starts are +1 and ends are -1

plan(multicore)
options(mc.cores = 16)

list_lsv_to_vsr_pos_strand <- furrr::future_map(
  .x = wide_tibble_psi[wide_tibble_psi$strand == "+", ] %>% dplyr::group_split(chr, gene_name),
  .f = function(a1) {
    
    # DEBUG ###
    # a1 <- wide_tibble_psi %>% dplyr::group_split(gene_id) %>% .[[1]]
    ###########
    
    tibble_lsv_to_vsr_flag_table <- dplyr::bind_rows(
      tibble("coord" = purrr::map2(.x = a1$junc_IR_coords %>% gsub(pattern = "([^\\-]+)\\-([^\\-]+)", replacement = "\\1"), .y = a1$junc_IR_coords %>% gsub(pattern = "([^\\-]+)\\-([^\\-]+)", replacement = "\\2"), .f = ~min(c(.x, .y) %>% type.convert)) %>% unlist, "flag" = 1),
      tibble("coord" = purrr::map2(.x = a1$junc_IR_coords %>% gsub(pattern = "([^\\-]+)\\-([^\\-]+)", replacement = "\\1"), .y = a1$junc_IR_coords %>% gsub(pattern = "([^\\-]+)\\-([^\\-]+)", replacement = "\\2"), .f = ~max(c(.x, .y) %>% type.convert)) %>% unlist, "flag" = -1)
    ) %>% dplyr::arrange(`coord`)
    
    vec_cumulative_sum <- tibble_lsv_to_vsr_flag_table$flag %>% purrr::accumulate(sum, .dir = "forward")
    
    purrr::map2(
      # starts
      .x = tibble_lsv_to_vsr_flag_table[which(vec_cumulative_sum == 1 & c(0, vec_cumulative_sum[1:(length(vec_cumulative_sum) - 1)]) == 0), ] %>% .$coord,
      # ends
      .y = tibble_lsv_to_vsr_flag_table[which(vec_cumulative_sum == 0 & c(0, vec_cumulative_sum[1:(length(vec_cumulative_sum) - 1)]) == 1), ] %>% .$coord,
      .f = ~tibble("chr" = a1$chr %>% unique, "start" = .x, "end" = .y, "strand" = a1$strand %>% unique)
    ) %>% rbindlist(fill = TRUE, use.names = TRUE) %>% as_tibble %>%
      return
    
  }, .progress = TRUE )

list_lsv_to_vsr_neg_strand <- furrr::future_map(
  .x = wide_tibble_psi[wide_tibble_psi$strand == "-", ] %>% dplyr::group_split(chr, gene_name),
  .f = function(a1) {
    
    # DEBUG ###
    # a1 <- wide_tibble_psi %>% dplyr::group_split(gene_id) %>% .[[1]]
    ###########
    
    tibble_lsv_to_vsr_flag_table <- dplyr::bind_rows(
      tibble("coord" = purrr::map2(.x = a1$junc_IR_coords %>% gsub(pattern = "([^\\-]+)\\-([^\\-]+)", replacement = "\\1"), .y = a1$junc_IR_coords %>% gsub(pattern = "([^\\-]+)\\-([^\\-]+)", replacement = "\\2"), .f = ~min(c(.x, .y) %>% type.convert)) %>% unlist, "flag" = 1),
      tibble("coord" = purrr::map2(.x = a1$junc_IR_coords %>% gsub(pattern = "([^\\-]+)\\-([^\\-]+)", replacement = "\\1"), .y = a1$junc_IR_coords %>% gsub(pattern = "([^\\-]+)\\-([^\\-]+)", replacement = "\\2"), .f = ~max(c(.x, .y) %>% type.convert)) %>% unlist, "flag" = -1)
    ) %>% dplyr::arrange(`coord`)
    
    vec_cumulative_sum <- tibble_lsv_to_vsr_flag_table$flag %>% purrr::accumulate(sum, .dir = "forward")
    
    purrr::map2(
      # starts
      .x = tibble_lsv_to_vsr_flag_table[which(vec_cumulative_sum == 1 & c(0, vec_cumulative_sum[1:(length(vec_cumulative_sum) - 1)]) == 0), ] %>% .$coord,
      # ends
      .y = tibble_lsv_to_vsr_flag_table[which(vec_cumulative_sum == 0 & c(0, vec_cumulative_sum[1:(length(vec_cumulative_sum) - 1)]) == 1), ] %>% .$coord,
      .f = ~tibble("chr" = a1$chr %>% unique, "start" = .x, "end" = .y, "strand" = a1$strand %>% unique)
    ) %>% rbindlist(fill = TRUE, use.names = TRUE) %>% as_tibble %>%
      return
    
  }, .progress = TRUE )

tibble_lsv_to_vsr_pos_strand <- list_lsv_to_vsr_pos_strand %>% rbindlist(fill = TRUE, use.names = TRUE) %>% as_tibble %>% dplyr::mutate_if(is.factor, as.character)
tibble_lsv_to_vsr_neg_strand <- list_lsv_to_vsr_neg_strand %>% rbindlist(fill = TRUE, use.names = TRUE) %>% as_tibble %>% dplyr::mutate_if(is.factor, as.character)

# group VSRs with their constituent junctions
tibble_VSRs_to_constituent_junctions <- dplyr::bind_rows(
  regioneR::overlapRegions(
    type = "any", 
    A = tibble_lsv_to_vsr_pos_strand %>% as.data.frame %>% regioneR::toGRanges(),
    B = tibble(
      "chr" = wide_tibble_psi[wide_tibble_psi$strand == "-", ] %>% .$chr,
      "start" = purrr::map2(.x = wide_tibble_psi[wide_tibble_psi$strand == "-", ] %>% .$junc_IR_coords %>% gsub(pattern = "([^\\-]+)\\-([^\\-]+)", replacement = "\\1"), .y = wide_tibble_psi[wide_tibble_psi$strand == "-", ] %>% .$junc_IR_coords %>% gsub(pattern = "([^\\-]+)\\-([^\\-]+)", replacement = "\\2"), .f = ~min(c(.x, .y) %>% type.convert)) %>% unlist,
      "end" = purrr::map2(.x = wide_tibble_psi[wide_tibble_psi$strand == "-", ] %>% .$junc_IR_coords %>% gsub(pattern = "([^\\-]+)\\-([^\\-]+)", replacement = "\\1"), .y = wide_tibble_psi[wide_tibble_psi$strand == "-", ] %>% .$junc_IR_coords %>% gsub(pattern = "([^\\-]+)\\-([^\\-]+)", replacement = "\\2"), .f = ~max(c(.x, .y) %>% type.convert)) %>% unlist,
      "strand" = wide_tibble_psi[wide_tibble_psi$strand == "-", ] %>% .$strand
    ) %>% as.data.frame %>%
      regioneR::toGRanges()
  ) %>% dplyr::mutate("strand" = "-"),
  regioneR::overlapRegions(
    type = "any", 
    A = tibble_lsv_to_vsr_neg_strand %>% as.data.frame %>% regioneR::toGRanges(),
    B = tibble(
      "chr" = wide_tibble_psi[wide_tibble_psi$strand == "+", ] %>% .$chr,
      "start" = purrr::map2(.x = wide_tibble_psi[wide_tibble_psi$strand == "+", ] %>% .$junc_IR_coords %>% gsub(pattern = "([^\\-]+)\\-([^\\-]+)", replacement = "\\1"), .y = wide_tibble_psi[wide_tibble_psi$strand == "+", ] %>% .$junc_IR_coords %>% gsub(pattern = "([^\\-]+)\\-([^\\-]+)", replacement = "\\2"), .f = ~min(c(.x, .y) %>% type.convert)) %>% unlist,
      "end" = purrr::map2(.x = wide_tibble_psi[wide_tibble_psi$strand == "+", ] %>% .$junc_IR_coords %>% gsub(pattern = "([^\\-]+)\\-([^\\-]+)", replacement = "\\1"), .y = wide_tibble_psi[wide_tibble_psi$strand == "+", ] %>% .$junc_IR_coords %>% gsub(pattern = "([^\\-]+)\\-([^\\-]+)", replacement = "\\2"), .f = ~max(c(.x, .y) %>% type.convert)) %>% unlist,
      "strand" = wide_tibble_psi[wide_tibble_psi$strand == "+", ] %>% .$strand
    ) %>% as.data.frame %>%
      regioneR::toGRanges()
  ) %>% dplyr::mutate("strand" = "+")
) %>% as_tibble %>% 
  dplyr::select(-type) %>%
  dplyr::distinct(.keep_all = TRUE) %>%
  dplyr::rename("VSR_start" = "startA", "VSR_end" = "endA", "junc_start" = "startB", "junc_end" = "endB") %>%
  dplyr::left_join(., 
                   tibble("junc_start" = purrr::map2(.x = wide_tibble_psi$junc_IR_coords %>% gsub(pattern = "([^\\-]+)\\-([^\\-]+)", replacement = "\\1"), .y = wide_tibble_psi$junc_IR_coords %>% gsub(pattern = "([^\\-]+)\\-([^\\-]+)", replacement = "\\2"), .f = ~min(c(.x, .y) %>% type.convert)) %>% unlist,
                          
                          "junc_end" = purrr::map2(.x = wide_tibble_psi$junc_IR_coords %>% gsub(pattern = "([^\\-]+)\\-([^\\-]+)", replacement = "\\1"), .y = wide_tibble_psi$junc_IR_coords %>% gsub(pattern = "([^\\-]+)\\-([^\\-]+)", replacement = "\\2"), .f = ~max(c(.x, .y) %>% type.convert)) %>% unlist,
                          "lsv_id" = wide_tibble_psi$lsv_id,
                          "gene_name" = wide_tibble_psi$gene_name,
                          "gene_id" = wide_tibble_psi$gene_id,
                          "A5SS" = wide_tibble_psi$A5SS,
                          "A3SS" = wide_tibble_psi$A3SS,
                          "ES" = wide_tibble_psi$ES,
                          "junc_or_IR" = wide_tibble_psi$junc_or_IR
                          )
  ) %>%
  dplyr::mutate("VSR_coords" = paste(`chr`, ":", `VSR_start`, "-", `VSR_end`, ":", `strand`, sep = ""))

# group_split by VSR coords
list_VSRs_to_constituent_junctions_split_by_VSR <- tibble_VSRs_to_constituent_junctions %>% 
  dplyr::group_split(chr, VSR_start, VSR_end) %>%
  purrr::map(~list(
    "gene_id" = .x$gene_id %>% unique %>% paste(collapse = ";"),
    "gene_name" = .x$gene_name %>% unique %>% paste(collapse = ";"),
    "lsv_id" = .x$lsv_id %>% unique %>% paste(collapse = ";"),
    "VSR_coords" = .x$VSR_coords %>% unique %>% paste(collapse = ";"),
    "has_A5SS" = .x$A5SS %>% any,
    "has_A3SS" = .x$A3SS %>% any,
    "has_ES" = .x$ES %>% any,
    "has_IR" = any(.x$junc_or_IR == "IR"),
    "contributing_junctions" = .x[, c("chr", "junc_start", "junc_end", "strand")] %>% dplyr::rename("start" = "junc_start", "end" = "junc_end") %>% purrr::array_tree() %>% purrr::set_names(nm = 1:length(.))
  ))

## match contributing junctions to reference annotation
## NOTE: there will be contributing junctions which do not have any flanking exons. In those cases, they will be excluded from analysis and the total sample space should comprise of matched junctions only.

plan(multicore)
options(mc.cores = 32)

# match to reference GTF. these wil be the important exon pairs.
list_ref_entries_matched_to_constituent_junctions <- furrr::future_imap(
  .x = list_VSRs_to_constituent_junctions_split_by_VSR, 
  .f = function(a1, a2) {
    
    # cat("now processing: ", a2)
    
    # DEBUG ###
    # a1 <- list_VSRs_to_constituent_junctions_split_by_VSR[[1]]
    ###########
    
    purrr::splice(
      a1,
      
      "ref_matched_CDS_pairs" = list(a1$contributing_junctions %>% (function(x) {
        
        temp0 <- purrr::map(.x = x, .f = ~.x %>% extract_junction.flanking.CDS_JUM(spliceregion_list = ., tibble_ref_gtf_original, match_consecutive = FALSE))
        
        temp1 <- purrr::discard(.x = temp0, .p = ~length(.x) == 0)
        
      } ) ),
      
      "ref_matched_exon_pairs" = list(a1$contributing_junctions %>% (function(x) {
        
        temp0 <- purrr::map(.x = x, .f = ~.x %>% extract_junction.flanking.exons_JUM(spliceregion_list = ., tibble_ref_gtf_original, match_consecutive = FALSE))
        
        temp1 <- purrr::discard(.x = temp0, .p = ~length(.x) == 0)
        
      } ) )
      
    ) %>% return
  }, .progress = TRUE) %>% 
  purrr::discard(.x = ., .p = ~length(.x$ref_matched_CDS_pairs) <= 1 & length(.x$ref_matched_exon_pairs) <= 1)

# CRYPTIC FUNCTION TO EXTRACT ALL DIFFERENTIAL COORDS FROM A LIST OF MATCHED TRANSCRIPTS ENTRY PAIRS FROM VSR JUNCTIONS
extract_diff_coord_from_entry_pairs <- function(list_of_junctions_of_transcripts_entry_pairs) {
  
  # DEBUG ###
  # list_of_junctions_of_transcripts_entry_pairs <- list_ref_entries_matched_to_constituent_junctions[[1]] %>% .$ref_matched_CDS_pairs
  ###########
  
  # for each contributing junction, take only UNIQUE exon pairs
  # label entries as left and right exons (this should be easy since the exon pair entries were pre-sorted by exon number)
  list_collapsed_tibbles_per_junction <- list_of_junctions_of_transcripts_entry_pairs %>% purrr::map_depth(.depth = 2, .f = ~add_column(.x, "left_or_right_exon" = c("left_exon", "right_exon"))) %>% purrr::map(~.x[[1]])
  # rbind and collapse
  collapsed_tibble <- list_collapsed_tibbles_per_junction %>% rbindlist %>% as_tibble
  
  # get current strand
  current_strand <- collapsed_tibble$strand %>% unique
  
  # find LRELE (leftmost right end of left exons) and RLERE (rightmost left end of right exons)
  # these are the boundary of the VSR and will be used to tackle the issue of constitutive end exons.
  if (current_strand == "+") {
    LRELE <- collapsed_tibble[collapsed_tibble$left_or_right_exon == "left_exon", ] %>% .$end %>% min
    RLERE <- collapsed_tibble[collapsed_tibble$left_or_right_exon == "right_exon", ] %>% .$start %>% max
  } else if (current_strand == "-") {
    LRELE <- collapsed_tibble[collapsed_tibble$left_or_right_exon == "left_exon", ] %>% .$start %>% max
    RLERE <- collapsed_tibble[collapsed_tibble$left_or_right_exon == "right_exon", ] %>% .$end %>% min
  }
  
  # find left overlapping exons (these have a left end that extends upstream of LRELE)
  # also find right overlapping exons (these have a right end that extends downstream of RLERE)
  # middle exons are neither right nor left overlapping exons.
  if (current_strand == "+") {
    tibble_left_overlapping_exons <- collapsed_tibble[which(collapsed_tibble$start <= LRELE), ]
    tibble_right_overlapping_exons <- collapsed_tibble[which(collapsed_tibble$end >= RLERE), ]
    tibble_middle_exons <- collapsed_tibble[which(!(collapsed_tibble$start <= LRELE | collapsed_tibble$end >= RLERE)), ]
  } else if (current_strand == "-") {
    tibble_left_overlapping_exons <- collapsed_tibble[which(collapsed_tibble$end >= LRELE), ]
    tibble_right_overlapping_exons <- collapsed_tibble[which(collapsed_tibble$start <= RLERE), ]
    tibble_middle_exons <- collapsed_tibble[which(!(collapsed_tibble$end >= LRELE | collapsed_tibble$start <= RLERE)), ]
  }
   
  # calculate sigma(pairs) (total number of unique matched pairs), 
  # sigma(repeats) (total number of duplicate MIDDLE exons removed)
  # hence calculate C (the constitutive threshold number for left and right-end exons)
  # nucleotide positions in the end exons with a frequency tally of C are constitutive.
  # nucleotides with a tally of less than C are differential.
  # this must be done because all forms of alternative exon skipping generate more than one junction
  # when we generated matched pairs, we would have then double-counted the middle alternative exons.
  # this technique is therefore sensitive to all archetypal alternatively skipped exons and alternative constitutive exons.
  # this would fail if there are short alternative transcripts which are completely smack-bang in the middle (exceedingly rare, I don't think that JUM can even detect this, as it's not technically an LSV which shares a divergent node. It's actually a date hub.)
  Sp <- (collapsed_tibble %>% nrow) / 2
  Sr <- (tibble_middle_exons %>% nrow) - (tibble_middle_exons %>% dplyr::distinct(start, end) %>% nrow)
  C_number <- Sp - Sr
  
  # tally nucleotide positions for the left and right exons and filter for C
  ## get each genomic coord or position of the overlapping left and right exons
  list_genomic_coords_of_all_left_exon_positions <- purrr::map2(.x = tibble_left_overlapping_exons$start, 
                                                                .y = tibble_left_overlapping_exons$end,
                                                                .f = ~.x:.y)
  
  list_genomic_coords_of_all_right_exon_positions <- purrr::map2(.x = tibble_right_overlapping_exons$start, 
                                                                .y = tibble_right_overlapping_exons$end,
                                                                .f = ~.x:.y)
  
  ## create tally, keep only the positions which have a tally less than C
  vector_genomic_coords_of_all_differential_left_exon_positions <- list_genomic_coords_of_all_left_exon_positions %>% 
    unlist %>% 
    tibble::enframe(name = NULL, value = "genome_coord") %>%
    dplyr::group_by(genome_coord) %>% 
    dplyr::summarise("tally" = dplyr::n()) %>%
    dplyr::filter(tally == 1 | tally < C_number, .preserve = TRUE) %>% 
    .$genome_coord
  ## create tally, keep only the positions which have a tally less than C
  vector_genomic_coords_of_all_differential_right_exon_positions <- list_genomic_coords_of_all_right_exon_positions %>% 
    unlist %>% 
    tibble::enframe(name = NULL, value = "genome_coord") %>%
    dplyr::group_by(genome_coord) %>% 
    dplyr::summarise("tally" = dplyr::n()) %>%
    dplyr::filter(tally == 1 | tally < C_number, .preserve = TRUE) %>% 
    .$genome_coord
  
  # fetch all the nucleotide positions of the middle exons.
  # Since they are in a VSR, by definition they are ALL differential.
  vector_genomic_coords_of_all_middle_exon_positions <- purrr::map2(.x = tibble_middle_exons$start, 
                                                                    .y = tibble_middle_exons$end,
                                                                    .f = ~.x:.y) %>% unlist
  
  # mix, unique-ify, sort and return
  vector_differential_coords <- c(vector_genomic_coords_of_all_differential_left_exon_positions,
                                  vector_genomic_coords_of_all_differential_right_exon_positions,
                                  vector_genomic_coords_of_all_middle_exon_positions) %>% unique %>% sort
  
  return(vector_differential_coords)
  
}

# GENERATE GENOME-RELATIVE COORDS FOR EVERY DIFFERENTIAL POSITION.
## remove any overlapping regions on the left and right ends of the AS structure.
## we do this because analysing each junction separately will result in constitutive flanking exons to be falsely called as differential (e.g. in the case of cassette exons)

# differential CDS positions for domain/PTM analyses, differential exon positions for transcript feature analysis.
list_genome_relative_differential_coords <- future_imap(
  .x = list_ref_entries_matched_to_constituent_junctions, 
  .f = function(a1, a2) {
    
    # DEBUG ###
    # a1 <- list_ref_entries_matched_to_constituent_junctions[[8]]
    ###########
    
    # cat("\nnow processing: ", a2)
    
    input_list <- a1
    
    output_list <- purrr::splice(
      
      input_list,
      
      "vector_genomic_coords_of_all_differential_exon_positions" = if (input_list$ref_matched_exon_pairs %>% length != 0) {extract_diff_coord_from_entry_pairs(input_list$ref_matched_exon_pairs)} else {list()},
      
      "vector_genomic_coords_of_all_differential_CDS_positions" = if (input_list$ref_matched_CDS_pairs %>% length != 0) {extract_diff_coord_from_entry_pairs(input_list$ref_matched_CDS_pairs)} else {list()} ,
      
      "genomic_coords_of_all_CDS_positions_per_protein_id" = list(input_list$ref_matched_CDS_pairs %>% (function(x) {
        
        # DEBUG ###
        # x <- input_list$ref_matched_CDS_pairs
        ###########
        
        collapsed_tibble <- x %>% flatten %>% rbindlist %>% as_tibble
        
        # generate all the genome-relative coords of the parent CDS positions
        list_genome_relative_coords_of_CDS_positions_per_protein_id <- collapsed_tibble$protein_id %>% na.omit %>% unique %>% 
          purrr::map(.x = ., .f = ~tibble_ref_gtf_original[which(tibble_ref_gtf_original$protein_id == .x & tibble_ref_gtf_original$type == "CDS"), ]) %>% 
          # .[apply(X = ., MARGIN = 1, FUN = function(X) {all(is.na(X)) == FALSE}), ]) %>% 
          purrr::map(~purrr::map2(.x = .x$start, .y = .x$end, .f = ~.x:.y) %>% unlist %>% unique %>% sort(decreasing = FALSE))
        
        names(list_genome_relative_coords_of_CDS_positions_per_protein_id) <- collapsed_tibble$protein_id %>% na.omit %>% unique
        
        return(list_genome_relative_coords_of_CDS_positions_per_protein_id)
        
      } ) ),
      
      "vector_matched_transcript_ids" = list(input_list$ref_matched_exon_pairs %>% (function(.x) {
        
        # DEBUG ###
        # .x <- input_list$ref_matched_exon_pairs
        ###########
        
        collapsed_tibble <- .x %>% flatten %>% rbindlist %>% as_tibble
        
        vector_matched_transcript_ids <- collapsed_tibble$transcript_id %>% na.omit %>% unique
        
        return(vector_matched_transcript_ids)
        
      } ) )
      
    )
    
    return(output_list)
    
  }, .progress = TRUE ) %>%
  
  # drop AS junction structures that don't have any differential regions.
  purrr::discard(.x = ., .p = ~length(.x$vector_genomic_coords_of_all_differential_exon_positions) == 0 & length(.x$vector_genomic_coords_of_all_differential_CDS_positions) == 0)

# MATCH DIFFERENTIAL GENOME-RELATIVE COORDS TO EACH CDS REGION CORRESPONDING TO PROTEIN ID
# THEN EXTRACT THE PROTEIN-RELATIVE COORDS
list_transcript_and_protein_relative_differential_coords <- future_imap(
  .x = list_genome_relative_differential_coords, 
  .f = function(a1, a2) {
    
    # cat("now processing junction number: ", a2, "\n")
    
    # DEBUG ###
    # a1 <- list_genome_relative_differential_coords[[6]]
    ###########
    
    # get current strand - this is necessary for getting CDS-relative coords.
    if (a1$ref_matched_CDS_pairs %>% length != 0) {
      current_strand <- a1$ref_matched_CDS_pairs %>% .[[1]] %>% .[[1]] %>% .$strand %>% unique
    }
    
    input_list <- a1
    
    output_list <- purrr::splice(
      
      input_list,
      
      "CDS_relative_differential_coords" = list(purrr::map(.x = input_list$genomic_coords_of_all_CDS_positions_per_protein_id, 
                                                           .f = function(b1) {
                                                             
                                                             if (current_strand == "+") {
                                                               which((b1 %>% type.convert) %in% (input_list$vector_genomic_coords_of_all_differential_CDS_positions %>% type.convert)) %>% sort(decreasing = FALSE) %>% return 
                                                             } else if (current_strand == "-") {
                                                               which((b1 %>% rev %>% type.convert) %in% (input_list$vector_genomic_coords_of_all_differential_CDS_positions %>% type.convert)) %>% sort(decreasing = FALSE) %>% return 
                                                             }
                                                             
                                                           } ) %>% 
                                                  purrr::discard(.p = ~length(.x) == 0)
      )
    ) %>%
      
      # protein-relative coords are simply the ceiling of a third of the transcript-relative coords
      purrr::splice(
        
        "protein_relative_differential_coords" = list(.$CDS_relative_differential_coords %>% 
                                                        purrr::map(~ceiling(.x / 3) %>% unlist %>% unique))
        
      )
    
  }, .progress = TRUE)

# MATCH THE DIFFERENTIAL TRANSCRIPT-RELATIVE COORDS TO THE ENSEMBL GTF
# MATCH THE DIFFERENTIAL PROTEIN-RELATIVE COORDS TO THE FETCHED BIOMART LIST AS WELL AS THE PTMS
suppressMessages(
  list_matched_annotation <- furrr::future_imap(
    .x = list_transcript_and_protein_relative_differential_coords, 
    .f = function(a1, a2) {
    
    # WARNING!! FIX THIS WHEN NAMING THE FUNCTION!
    # list_of_tibbles_biomart_domain_annotation <<- list_of_tibbles_biomart_domain_annotation
    
    # tibble_ENSP_to_uniprotkb <<- tibble_ENSP_to_uniprotkb
    # tibble_PTM_combined <<- tibble_PTM_combined
    # tibble_ref_gtf_original <<- tibble_ref_gtf_original
    ############################################
    
    # DEBUG ###
    # a1 <- list_transcript_and_protein_relative_differential_coords[[1]]
    ###########
    
    # cat("\nnow processing: ", a2)
    
    input_list <- a1
    
    output_list <- purrr::splice(
      
      input_list,
      
      "transcript_features" = purrr::map(.x = input_list$vector_matched_transcript_ids, .f = function(.x) {
        
        # DEBUG ###
        # .x <- input_list$vector_matched_transcript_ids %>% .[[1]]
        ###########
        
        # subset the reference GTF by transcript_id
        tibble_ref_gtf_subset_by_transcript_id <- tibble_ref_gtf_original[which(tibble_ref_gtf_original$transcript_id == .x), ]
        
        # test for which differential positions lie between a feature
        row.indices_of_overlaps_with_differential_positions <- which(purrr::map2(.x = tibble_ref_gtf_subset_by_transcript_id$start, 
                                                                                 .y = tibble_ref_gtf_subset_by_transcript_id$end, 
                                                                                 .f = ~any(.x <= input_list$vector_genomic_coords_of_all_differential_exon_positions &
                                                                                             .y >= input_list$vector_genomic_coords_of_all_differential_exon_positions)) %>% unlist)
        
        # extract matched GTF entries
        matched_GTF_entries <- tibble_ref_gtf_subset_by_transcript_id[row.indices_of_overlaps_with_differential_positions, ]
        
        return(matched_GTF_entries)
        
      } ) %>% 
        # rbind and spit out unique transcript feature types.
        rbindlist(fill = TRUE, use.names = TRUE) %>% .[, c("type", "transcript_biotype")] %>% unlist %>% unique,
      
      "biomart_annotations" = list(purrr::map2(.x = input_list$CDS_relative_differential_coords, .y = names(input_list$CDS_relative_differential_coords), .f = function(.x, .y) {
        
        # DEBUG ###
        # .x <- input_list$CDS_relative_differential_coords %>% .[[3]]
        # .y <- names(input_list$CDS_relative_differential_coords) %>% .[3]
        ###########
        
        CDS.relative.coords <- .x
        protein.id <- .y
        
        # find domains which overlapped with the differential positions.
        list_matched_biomart_annotations <- purrr::map2(.x = list_of_tibbles_biomart_domain_annotation, 
                                                        .y = names(list_of_tibbles_biomart_domain_annotation),
                                                        .f = function(.x, .y) {
                                                          
                                                          # DEBUG ###
                                                          # .x <- list_of_tibbles_biomart_domain_annotation[[1]]
                                                          # .y <- list_of_tibbles_biomart_domain_annotation[1] %>% names
                                                          ###########
                                                          
                                                          tibble_domain_subset <- .x[.x$ensembl_peptide_id == protein.id, ]
                                                          
                                                          if (nrow(tibble_domain_subset) != 0) {
                                                            
                                                            # test matched_domain_entriesfor which differential positions lie between a domain
                                                            row.indices_of_overlaps_with_differential_positions <- which(purrr::map2(
                                                              .x = tibble_domain_subset$start, 
                                                              .y = tibble_domain_subset$end, 
                                                              .f = ~any(.x < CDS.relative.coords &
                                                                          .y > CDS.relative.coords)) %>% unlist)
                                                            
                                                            # extract matched GTF entries
                                                            tibble_matched_domain_entries <- tibble_domain_subset[row.indices_of_overlaps_with_differential_positions, ]
                                                            
                                                          } else if (nrow(tibble_domain_subset) == 0) {
                                                            
                                                            tibble_matched_domain_entries <- tibble_domain_subset
                                                            
                                                          }
                                                          
                                                          # calculate the degree of overlap
                                                          tibble_matched_domain_entries <- tibble_matched_domain_entries %>% dplyr::mutate("percentage_overlap" = purrr::map2(.x = tibble_matched_domain_entries$start, .y = tibble_matched_domain_entries$end, .f = function(a1, a2) {(intersect(a1:a2, CDS.relative.coords) %>% length)/((a1:a2) %>% length)} ) %>% unlist)
                                                          
                                                          # rename the columns back to being domain-type specific
                                                          colnames(tibble_matched_domain_entries) <- gsub(x = colnames(tibble_matched_domain_entries), pattern = "start", replacement = paste(.y, "_", "start", sep = ""))
                                                          colnames(tibble_matched_domain_entries) <- gsub(x = colnames(tibble_matched_domain_entries), pattern = "end", replacement = paste(.y, "_", "end", sep = ""))
                                                          colnames(tibble_matched_domain_entries) <- gsub(x = colnames(tibble_matched_domain_entries), pattern = "percentage_overlap", replacement = paste(.y, "_", "percentage_overlap", sep = ""))
                                                          
                                                          return(tibble_matched_domain_entries)
                                                          
                                                        } )
        
        # reduce into tibble by full join
        tibble_matched_biomart_annotations <- list_matched_biomart_annotations %>% purrr::reduce(dplyr::full_join)
        
        return(tibble_matched_biomart_annotations)
        
      } ) %>% rbindlist(fill = TRUE, use.names = TRUE) %>% as_tibble ),
      
      "PTMs" =  list(
        
        purrr::map2(.x = input_list$CDS_relative_differential_coords, .y = names(input_list$CDS_relative_differential_coords), .f = function(.x, .y) {
          
          # DEBUG ###
          # .x <- input_list$CDS_relative_differential_coords %>% .[[1]]
          # .y <- names(input_list$CDS_relative_differential_coords) %>% .[1]
          ###########
          
          tibble_uniprotkb_entries_from_ENSP <- tibble_ENSP_to_uniprotkb[which(tibble_ENSP_to_uniprotkb$ensembl_peptide_id == .y), ]
          
          tibble_combined_PTM_matching_entries <- tibble_uniprotkb_entries_from_ENSP %>% dplyr::left_join(., tibble_PTM_combined, by = "uniprotkb_entry") %>%
            
            .[.$modified_residue_position %in% .x, ]
          
          return(tibble_combined_PTM_matching_entries)
          
        } ) %>% rbindlist(fill = TRUE, use.names = TRUE) %>% as_tibble
        
      )
      
    )
    
  }, .progress = TRUE)
)

# TIDY AND WRAP UP ALL THE ANNOTATIONS.
# prepare for export
list_tidied_annotation <- list_matched_annotation %>% 
  future_map(.f = ~
               # collapse all the matched exon pair annotations into a single tibble
               modify_at(.x, .at = "ref_matched_CDS_pairs", .f = ~map2(.x = .x, .y = names(.x), .f = ~.x %>% rbindlist %>% add_column("junction_ID" = .y)) %>% rbindlist %>% as_tibble) %>% 
               modify_at(.x, .at = "ref_matched_exon_pairs", .f = ~map2(.x = .x, .y = names(.x), .f = ~.x %>% rbindlist %>% add_column("junction_ID" = .y)) %>% rbindlist %>% as_tibble) %>%
               # concatenate all bare vectors 
               modify_at(.x, .at = "vector_genomic_coords_of_all_differential_exon_positions", .f = ~.x %>% paste(collapse = ",")) %>%
               modify_at(.x, .at = "vector_genomic_coords_of_all_differential_CDS_positions", .f = ~.x %>% paste(collapse = ",")) %>%
               modify_at(.x, .at = "vector_matched_transcript_ids", .f = ~.x %>% paste(collapse = ",")) %>%
               modify_at(.x, .at = "transcript_features", .f = ~.x %>% paste(collapse = ",")), .progress = TRUE)

# extract the transcript features and tibblise 
tibble_final_transcript_feature_annotation <- list_tidied_annotation %>% purrr::map(~.x[c("gene_name", "gene_id", "lsv_id", "VSR_coords", "has_A5SS", "has_A3SS", "has_ES", "has_IR", "vector_matched_transcript_ids", "transcript_features")] %>% as_tibble) %>%
  rbindlist(use.names = TRUE, fill = TRUE) %>% 
  as_tibble %>%
  # setNames(c("transcript_ids_with_annotation", "transcript_features")) %>% 
  ## add in gene symbols
  # dplyr::right_join(wide_tibble_psi[, c("lsv_id", "gene_id", "gene_name")] %>% unique %>% na.omit, ., by = c("AS_event_ID", "splicemode")) %>% 
  as_tibble
# write table
write.table(x = tibble_final_transcript_feature_annotation, file = paste(R_processing_results_dir, vector_experiment_metadata_main %>% paste(collapse = "_"), "_table_junction_ontology_matched_transcript_features.txt", sep = ""), sep = "\t", row.names = FALSE, quote = FALSE)

# extract the biomart results and tibblise 
tibble_final_biomart_annotation <- list_tidied_annotation %>% purrr::map(~.x[c("gene_name", "gene_id", "lsv_id", "VSR_coords", "has_A5SS", "has_A3SS", "has_ES", "has_IR", "biomart_annotations")]) %>%
  purrr::discard(.p = ~.x$biomart_annotations %>% nrow == 0) %>%
  purrr::map(~purrr::modify_at(.x = .x, .at = "biomart_annotations", .f = ~array_tree(.x, margin = 2)) %>% flatten %>% as_tibble) %>%
  rbindlist(fill = TRUE, use.names = TRUE) %>% 
  as_tibble
# write table
write.table(x = tibble_final_biomart_annotation, file = paste(R_processing_results_dir, vector_experiment_metadata_main %>% paste(collapse = "_"), "_table_junction_ontology_matched_biomart_domains.txt", sep = ""), sep = "\t", row.names = FALSE, quote = FALSE)

# extract the PTM results and tibblise 
tibble_final_PTM_annotation <- list_tidied_annotation %>% purrr::map(~.x[c("gene_name", "gene_id", "lsv_id", "VSR_coords", "has_A5SS", "has_A3SS", "has_ES", "has_IR", "PTMs")]) %>%
  purrr::discard(.p = ~.x$PTMs %>% nrow == 0) %>%
  purrr::map(~purrr::modify_at(.x = .x, .at = "PTMs", .f = ~array_tree(.x, margin = 2)) %>% flatten %>% as_tibble) %>%
  rbindlist(fill = TRUE, use.names = TRUE) %>% 
  as_tibble
# write table
write.table(x = tibble_final_PTM_annotation, file = paste(R_processing_results_dir, vector_experiment_metadata_main %>% paste(collapse = "_"), "_table_junction_ontology_matched_ptms.txt", sep = ""), sep = "\t", row.names = FALSE, quote = FALSE)

# extract the other supporting information and tibblise
tibble_final_annotation_supp <- list_tidied_annotation %>% 
  purrr::map(~.x[c("gene_name", "gene_id", "lsv_id", "VSR_coords", "has_A5SS", "has_A3SS", "has_ES", "has_IR", "vector_genomic_coords_of_all_differential_exon_positions", "vector_genomic_coords_of_all_differential_CDS_positions", "vector_matched_transcript_ids", "protein_relative_differential_coords")] %>% 
               purrr::splice("contributing_junctions" = names(.x$contributing_junctions) %>% paste(collapse = ","),
                             "contributing_identifiers" = .x$contributing_junctions %>% purrr::map(~paste(.x$chr, ":", .x$start, "-", .x$end, ":", .x$strand, sep = "")) %>% unlist %>% paste(collapse = ","))) %>%
  purrr::map_if(.p = ~.x$protein_relative_differential_coords %>% length != 0, .f = ~purrr::modify_at(.x = .x, .at = "protein_relative_differential_coords", .f = ~.x %>% purrr::map(~paste(.x, collapse = ",")) %>% as_tibble %>% t %>% as_tibble(rownames = "ensembl_peptide_id") %>% setNames(c("ensembl_peptide_id", "protein_relative_differential_coords")))) %>%
  purrr::map_if(.p = ~.x$protein_relative_differential_coords %>% length == 0, .f = ~purrr::modify_at(.x = .x, .at = "protein_relative_differential_coords", .f = function(.x) {return("NA")} ) %>% splice("ensembl_peptide_id" = "NA")) %>%
  purrr::map(~.x %>% flatten %>% as_tibble) %>%
  purrr::discard(.p = ~.x %>% nrow == 0) %>% rbindlist(use.names = TRUE, fill = TRUE) %>% as_tibble %>% 
  as_tibble
# write table
write.table(x = tibble_final_annotation_supp, file = paste(R_processing_results_dir, vector_experiment_metadata_main %>% paste(collapse = "_"), "_table_junction_ontology_supporting_info.txt", sep = ""), sep = "\t", row.names = FALSE, quote = FALSE)

```

## stats summary of junction ontology

```{r}

# transcript-level
message("total number of unique differential LSVs with any sort of transcript-level annotation: ", tibble_final_transcript_feature_annotation$VSR_coords %>% unique %>% length)

message("percent of differential regions matched to protein coding transcript: ", 100 * grep(x = tibble_final_transcript_feature_annotation %>% dplyr::distinct(VSR_coords, .keep_all = TRUE) %>% .$transcript_features, pattern = "protein_coding") %>% length/(tibble_final_transcript_feature_annotation$VSR_coords %>% unique %>% length))
message("percent of differential regions matched to an lncRNA transcript: ", 100 * grep(x = tibble_final_transcript_feature_annotation %>% dplyr::distinct(VSR_coords, .keep_all = TRUE) %>% .$transcript_features, pattern = "lncRNA") %>% length/(tibble_final_transcript_feature_annotation$VSR_coords %>% unique %>% length))
message("percent of differential regions matched to a miRNA transcript: ", 100 * grep(x = tibble_final_transcript_feature_annotation %>% dplyr::distinct(VSR_coords, .keep_all = TRUE) %>% .$transcript_features, pattern = "miRNA") %>% length/(tibble_final_transcript_feature_annotation$VSR_coords %>% unique %>% length))

message("percent of differential regions overlapping a start codon: ", 100 * grep(x = tibble_final_transcript_feature_annotation %>% dplyr::distinct(VSR_coords, .keep_all = TRUE) %>% .$transcript_features, pattern = "start_codon") %>% length/(tibble_final_transcript_feature_annotation$VSR_coords %>% unique %>% length))
message("percent of differential regions overlapping a stop codon: ", 100 * grep(x = tibble_final_transcript_feature_annotation %>% dplyr::distinct(VSR_coords, .keep_all = TRUE) %>% .$transcript_features, pattern = "stop_codon") %>% length/(tibble_final_transcript_feature_annotation$VSR_coords %>% unique %>% length))
message("percent of differential regions matched to a 3' UTR region: ", 100 * grep(x = tibble_final_transcript_feature_annotation %>% dplyr::distinct(VSR_coords, .keep_all = TRUE) %>% .$transcript_features, pattern = "three_prime_utr") %>% length/(tibble_final_transcript_feature_annotation$VSR_coords %>% unique %>% length))
message("percent of differential regions matched to a 5' UTR region: ", 100 * grep(x = tibble_final_transcript_feature_annotation %>% dplyr::distinct(VSR_coords, .keep_all = TRUE) %>% .$transcript_features, pattern = "five_prime_utr") %>% length/(tibble_final_transcript_feature_annotation$VSR_coords %>% unique %>% length))
message("percent of differential regions matched to a CDS region: ", 100 * grep(x = tibble_final_transcript_feature_annotation %>% dplyr::distinct(VSR_coords, .keep_all = TRUE) %>% .$transcript_features, pattern = "CDS") %>% length/(tibble_final_transcript_feature_annotation$VSR_coords %>% unique %>% length))

# PROTEIN-LEVEL
# vector_unique_interpro_ids <- tibble_final_biomart_annotation$interpro %>% na.omit %>% unique

tibble_protein_level_summary_count <- tibble_final_biomart_annotation %>% dplyr::group_by(VSR_coords) %>% 
  dplyr::summarise("overlaps_interpro_domain" = all(is.na(interpro)) == FALSE & intersect(interpro, tibble_non_family_interpro_entries$Accession) %>% length != 0,
                   "unique_interpro_ids" = interpro %>% na.omit %>% unique %>% paste(collapse = ";"),
                   "overlaps_LCR" = all(is.na(seg_start)) == FALSE,
                   "overlaps_disordered_region" = all(is.na(mobidblite)) == FALSE,
                   "overlaps_ncoils" = all(is.na(ncoils_start)) == FALSE,
                   "overlaps_signalp" = all(is.na(signalp_start)) == FALSE,
                   "overlaps_tmhmm" = all(is.na(tmhmm_start)) == FALSE)

vector_unique_interpro_ids <- dplyr::semi_join(tibble_protein_level_summary_count$unique_interpro_ids %>% strsplit(split = ";") %>% unlist %>% sort %>% tibble::enframe(name = NULL, value = "vec"), tibble_non_family_interpro_entries$Accession %>% tibble::enframe(name = NULL, value = "vec"), by = "vec") %>% unlist

# create tally of each unique instance of interpro ID per AS_event_ID
tibble_interpro_id_tally_per_vsr <- tibble::enframe(vector_unique_interpro_ids, name = NULL, value = "interpro_id") %>% dplyr::group_by(interpro_id) %>% dplyr::summarise("tally" = n()) %>% .[order(.$tally), ] %>% dplyr::arrange(desc(tally))

# create interpro to matched gene mapping
tibble_interpro_ID_to_matched_gene_mapping <- tibble_final_biomart_annotation %>% dplyr::group_by(interpro) %>% dplyr::summarise("genes" = paste(gene_name %>% unique %>% mixedsort, collapse = ",")) %>% setNames(c("interpro_id", "genes"))
# create interpro to matched vsr mapping
tibble_interpro_ID_to_matched_vsr_mapping <- tibble_final_biomart_annotation %>% dplyr::group_by(interpro) %>% 
  dplyr::summarise("AS_event_IDs" = paste(VSR_coords %>% unique %>% mixedsort, collapse = ",")) %>% setNames(c("interpro_id", "VSRs"))

# fetch descriptions of interpro ID
tibble_interpro_ID_to_description_mapping <- tibble_non_family_interpro_entries[, c("Accession", "Name")] %>% setNames(c("interpro_id", "interpro_description")) %>% as_tibble
# add column for plotting
tibble_interpro_ID_to_description_mapping <- tibble_interpro_ID_to_description_mapping %>% add_column("interpro_identifier" = paste(tibble_interpro_ID_to_description_mapping$interpro_description, " (", tibble_interpro_ID_to_description_mapping$interpro_id, ")", sep = ""))
# tibble joins
tibble_interpro_id_tally_per_vsr <- dplyr::right_join(tibble_interpro_ID_to_description_mapping, tibble_interpro_id_tally_per_vsr, by = "interpro_id")
tibble_interpro_id_tally_per_vsr <- dplyr::right_join(tibble_interpro_ID_to_matched_gene_mapping, tibble_interpro_id_tally_per_vsr, by = "interpro_id")
# plot
ggplot_interpro_id_tally_per_vsr  <- ggplot(tibble_interpro_id_tally_per_vsr %>% dplyr::arrange(desc(tally)) %>% head(16), aes(x = reorder(interpro_identifier, -tally), y = tally)) +
  geom_col(fill = "orange") +
  ggtitle(paste("# VSRs altering protein domains")) +
  xlab("Interpro identifier") +
  scale_x_discrete(labels = function(x) {str_wrap(x, width = 50)}) +
  ylab("Number of hits") +
  # coord_cartesian(ylim = c(0, 50)) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8), axis.text.y = element_text(size = 20), axis.title.y = element_text(margin = margin(r = 90)), legend.title.align = 0.5, legend.background = element_rect(size = 0.5, linetype = "solid", colour = "black"), text = element_text(family = "Helvetica"))

ggplot_interpro_id_tally_per_vsr

ggsave(plot = ggplot_interpro_id_tally_per_vsr, filename = paste(R_processing_results_dir, vector_experiment_metadata_main %>% paste(collapse = "_"), "_ggplot_interpro_id_tally_per_vsr.pdf", sep = ""), device = "pdf", dpi = 600, width = 80, height = 10, units = "cm")

write.table(x = tibble_interpro_id_tally_per_vsr %>% dplyr::arrange(desc(tally)), file = paste(R_processing_results_dir, vector_experiment_metadata_main %>% paste(collapse = "_"), "_tibble_interpro_id_tally_per_vsr.txt", sep = ""), sep = "\t", row.names = FALSE, quote = FALSE)

message("total number of unique LSVs with any sort of protein-level annotation: ", tibble_final_biomart_annotation$VSR_coords %>% unique %>% length, " (", tibble_final_biomart_annotation$VSR_coords %>% unique %>% length *100/tibble_final_transcript_feature_annotation$VSR_coords %>% unique %>% length, "% of those which have any transcript annotation)")

message("total percent of unique LSVs overlapping an interpro domain: ", length(which(tibble_protein_level_summary_count$overlaps_interpro_domain == TRUE))/nrow(tibble_protein_level_summary_count) * 100)

message("total percent of unique LSVs overlapping a low complexity region: ", length(which(tibble_protein_level_summary_count$overlaps_LCR == TRUE))/nrow(tibble_protein_level_summary_count) * 100)
message("total number of unique LSVs overlapping a disordered region: ", length(which(tibble_protein_level_summary_count$overlaps_disordered_region == TRUE))/nrow(tibble_protein_level_summary_count) * 100)
message("total number of unique LSVs overlapping a coiled-coiled domain: ", length(which(tibble_protein_level_summary_count$overlaps_ncoils == TRUE))/nrow(tibble_protein_level_summary_count) * 100)
message("total number of unique LSVs overlapping a signalp domain: ", length(which(tibble_protein_level_summary_count$overlaps_signalp == TRUE))/nrow(tibble_protein_level_summary_count) * 100)
message("total number of unique LSVs overlapping a tmhmm domain: ", length(which(tibble_protein_level_summary_count$overlaps_tmhmm == TRUE))/nrow(tibble_protein_level_summary_count) * 100)

```

### count PTM overlap numbers

```{r}

tibble_PTM_tally <- tibble_final_PTM_annotation %>% dplyr::distinct(VSR_coords, modified_residue_position, PTM_type) %>% dplyr::group_by(PTM_type) %>% dplyr::summarise("tally" = n())

# plot
ggplot_PTM_tally <- ggplot(tibble_PTM_tally, aes(x = reorder(PTM_type, -tally), y = tally)) +
  geom_col(fill = "purple3") +
  geom_text(stat = "identity", nudge_y = 1, aes(label = tally), angle = 90, hjust = 0) +
  ggtitle(paste("Tally of PTMs inside differentially spliced regions\nJUM")) +
  xlab("PTM type") +
  scale_x_discrete(labels = function(x) {str_wrap(x, width = 50)}) +
  ylab("Frequency") +
  ylim(c(0, max(tibble_PTM_tally$tally) + 5)) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), axis.title.y = element_text(margin = margin(r = 10)), legend.title.align = 0.5, legend.background = element_rect(size = 0.5, linetype = "solid", colour = "black"), text = element_text(family = "Helvetica"))

ggsave(plot = ggplot_PTM_tally, filename = paste(R_processing_results_dir, vector_experiment_metadata_main %>% paste(collapse = "_"), "_ggplot_PTM_tally.pdf", sep = ""), device = "pdf", dpi = 600, width = 4, height = 8, units = "cm")

write.table(x = tibble_PTM_tally, file = paste(R_processing_results_dir, vector_experiment_metadata_main %>% paste(collapse = "_"), "_tibble_PTM_tally.txt", sep = ""), sep = "\t", row.names = FALSE, quote = FALSE)

```

## try calculating frameshift by just naively looking at whether the differential region is a multiple of 3

```{r}

tibble_final_annotation_supp_with_frameshift_test <- tibble_final_annotation_supp %>% 
  add_column("total_differential_region_size" = purrr::map(.x = tibble_final_annotation_supp$vector_genomic_coords_of_all_differential_exon_positions, .f = ~.x %>% strsplit(split = ",") %>% unlist %>% length) %>% unlist, .after = "vector_genomic_coords_of_all_differential_exon_positions") %>%
  add_column("remainder_by_3" = .$total_differential_region_size %% 3, .after = "total_differential_region_size")
# write table
write.table(x = tibble_final_annotation_supp_with_frameshift_test, file = paste(R_processing_results_dir, vector_experiment_metadata_main %>% paste(collapse = "_"), "_table_junction_ontology_supporting_info_frameshift_test.txt", sep = ""), sep = "\t", row.names = FALSE, quote = FALSE)

subset_tibble_final_annotation_supp_with_frameshift_test <- tibble_final_annotation_supp_with_frameshift_test %>% dplyr::distinct(VSR_coords, has_A5SS, has_A3SS, has_ES, has_IR, remainder_by_3) %>% reshape2::melt(id.vars = c("VSR_coords", "remainder_by_3"), value.name = "flag", variable.name = "splicemode") %>% tibble::as_tibble()

ggplot_junction_ontology_supporting_info_frameshift_test <- ggplot() +
  geom_bar(data = subset_tibble_final_annotation_supp_with_frameshift_test, stat = "count", mapping = aes(y = ..count.., x = flag)) +
  geom_label(data = subset_tibble_final_annotation_supp_with_frameshift_test, stat = "count", mapping = aes(label = ..count.., x = flag)) +
  facet_wrap(splicemode ~ remainder_by_3, ncol = 3, scales = "free", labeller = labeller(sample = c("0" = "No Frameshift", "1" = "Frameshift by 1", "2" = "Frameshift by 2"))) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.background = element_rect(size = 0.5, linetype = "solid", colour = "black"), text = element_text(family = "Helvetica")) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, colour = "black"), text = element_text(family = "Helvetica"))

ggsave(plot = ggplot_junction_ontology_supporting_info_frameshift_test, filename = paste(R_processing_results_dir, vector_experiment_metadata_main %>% paste(collapse = "_"), "_table_junction_ontology_supporting_info_frameshift_test.pdf", sep = ""), device = "pdf", dpi = 600, width = 20, height = 15, units = "cm")

```

# ENRICHMENT OF SPLICING FACTORS

## Generate table of all the mRNA sequences of all annotated transcripts

- mRNA sequences: UNSPLICED, for,
- Genes: ANYSIG

```{r eval=FALSE, include=FALSE}

anysig_all_mrna_seqs <- getBM(filters = "external_gene_name", values = wide_table_of_all_splicemodes_with_na_filtered_qvalue_0.05_AS_plausible$Gene, attributes = c("external_gene_name", "ensembl_transcript_id", "transcript_exon_intron"), mart = ensembl_mart) %>% as_tibble

```

## generate lists of target genes containing motifs of splicing factors

use regex lmao

```{r eval=FALSE, include=FALSE}

RBM41_binding_motif_containing_genes <- anysig_all_mrna_seqs[which(grepl(x = anysig_all_mrna_seqs$transcript_exon_intron, pattern = "(A|T)TAC(A|T)TT")), "external_gene_name"] %>% unique

print(nrow(RBM41_binding_motif_containing_genes))

SRSF2_binding_motif_containing_genes <- anysig_all_mrna_seqs[which(grepl(x = anysig_all_mrna_seqs$transcript_exon_intron, pattern = "AGGAG(A|T)(G|A|T)")), "external_gene_name"] %>% unique

print(nrow(SRSF2_binding_motif_containing_genes))

tibble_SOM_summary_5_by_5_AS_plausible$Gene %>% unique %>% length %>% print

print("rip")

```

## import MBNL (HiTS-CLiP) and SRSF (FLASH-Seq) data and match with GTF information

### set directories

```{r}

clipseq_dir <- "/mnt/Tertiary/sharedfolder/isoform_usage_project/CLIPseq_files/"

FLASHseq_dir <- "/mnt/4tb_ironwolf/2019_FLASHseq/results/R_processing_results/"

```

### import the bed files from file - ON HOLD

```{r eval=FALSE, include=FALSE}

list_of_RBP_target_gene_categories_raw <- list(
  "SRSF2 HiTS_CLiP HeLa_WT GSE111900 0.01FDR" = read.delim(paste(clipseq_dir, "SRSF2_hits.clip_GSE111900/bedfile_srsf2_clip_GSE111900_WT.txt", sep = ""), sep = "\t", header = TRUE, row.names = NULL, stringsAsFactors = FALSE) %>% as_tibble,
  
  # "SRSF1 FLASH_seq HEK293 GSE118265 PEP0.01" = read.delim(paste(FLASHseq_dir, "pureclip_peaks_SR1-SRSF1.bed_geneset_PEP0.01.txt", sep = ""), header = FALSE, stringsAsFactors = FALSE) %>% unique %>% as.vector,
  "SRSF2 FLASH_seq HEK293 GSE118265 PEP0.01" = read.delim(paste(FLASHseq_dir, "pureclip_peaks_SR5-SRSF2.bed_annotated_PEP0.01.txt", sep = ""), sep = "\t", header = TRUE, row.names = NULL, stringsAsFactors = FALSE) %>% as_tibble,
  "SRSF3 FLASH_seq HEK293 GSE118265 PEP0.01" = read.delim(paste(FLASHseq_dir, "pureclip_peaks_SR8-SRSF3.bed_annotated_PEP0.01.txt", sep = ""), sep = "\t", header = TRUE, row.names = NULL, stringsAsFactors = FALSE) %>% as_tibble,
  # "SRSF4 FLASH_seq HEK293 GSE118265 PEP0.01" = read.delim(paste(FLASHseq_dir, "pureclip_peaks_SR9-SRSF4.bed_geneset_PEP0.01.txt", sep = ""), header = FALSE, stringsAsFactors = FALSE) %>% unique %>% as.vector,
  # "SRSF5 FLASH_seq HEK293 GSE118265 PEP0.01" = read.delim(paste(FLASHseq_dir, "pureclip_peaks_SR10-SRSF5.bed_geneset_PEP0.01.txt", sep = ""), header = FALSE, stringsAsFactors = FALSE) %>% unique %>% as.vector,
  "SRSF6 FLASH_seq HEK293 GSE118265 PEP0.01" = read.delim(paste(FLASHseq_dir, "pureclip_peaks_SR11-SRSF6.bed_annotated_PEP0.01.txt", sep = ""), sep = "\t", header = TRUE, row.names = NULL, stringsAsFactors = FALSE) %>% as_tibble,
  # "SRSF7 FLASH_seq HEK293 GSE118265 PEP0.01" = read.delim(paste(FLASHseq_dir, "pureclip_peaks_SR12-SRSF7.bed_geneset_PEP0.01.txt", sep = ""), header = FALSE, stringsAsFactors = FALSE) %>% unique %>% as.vector,
  # "SRSF9 FLASH_seq HEK293 GSE118265 PEP0.01" = read.delim(paste(FLASHseq_dir, "pureclip_peaks_SR13-SRSF9.bed_geneset_PEP0.01.txt", sep = ""), header = FALSE, stringsAsFactors = FALSE) %>% unique %>% as.vector,
  "SRSF11 FLASH_seq HEK293 GSE118265 PEP0.01" = read.delim(paste(FLASHseq_dir, "pureclip_peaks_SR14-SRSF11.bed_annotated_PEP0.01.txt", sep = ""), sep = "\t", header = TRUE, row.names = NULL, stringsAsFactors = FALSE) %>% as_tibble,
  
  "MBNL2 HiTS_CLiP MEF GSE60487 pvalue0.01" = read.delim(paste(clipseq_dir, "MBNL1.2.3_hits.clip_GSE60487/bedfile_mbnl2_hits.clip_MEF_GSE60487_pvalue0.01.txt", sep = ""), sep = "\t", header = TRUE, row.names = NULL, stringsAsFactors = FALSE) %>% as_tibble,
  "MBNL1 HiTS_CLiP MEF GSE60487 pvalue0.01" = read.delim(paste(clipseq_dir, "MBNL1.2.3_hits.clip_GSE60487/bedfile_mbnl1_hits.clip_MEF_GSE60487_pvalue0.01.txt", sep = ""), sep = "\t", header = TRUE, row.names = NULL, stringsAsFactors = FALSE) %>% as_tibble,
  "MBNL3 HiTS_CLiP MEF GSE60487 pvalue0.01" = read.delim(paste(clipseq_dir, "MBNL1.2.3_hits.clip_GSE60487/bedfile_mbnl3_hits.clip_MEF_GSE60487_pvalue0.01.txt", sep = ""), sep = "\t", header = TRUE, row.names = NULL, stringsAsFactors = FALSE) %>% as_tibble
)

```


```{r}

list_of_RBP_target_gene_categories_raw <- list(
  "SRSF2 HiTS_CLiP HeLa_WT GSE111900 0.01FDR" = read.delim(paste(clipseq_dir, "SRSF2_hits.clip_GSE111900/geneset_srsf2_clip_GSE111900_WT_0.01FDR.txt", sep = ""), header = FALSE, stringsAsFactors = FALSE) %>% unique %>% as.vector,
  
  # "SRSF1 FLASH_seq HEK293 GSE118265 PEP0.01" = read.delim(paste(FLASHseq_dir, "pureclip_peaks_SR1-SRSF1.bed_geneset_PEP0.01.txt", sep = ""), header = FALSE, stringsAsFactors = FALSE) %>% unique %>% as.vector,
  "SRSF2 FLASH_seq HEK293 GSE118265 PEP0.01" = read.delim(paste(FLASHseq_dir, "pureclip_peaks_SR5-SRSF2.bed_geneset_PEP0.01.txt", sep = ""), header = FALSE, stringsAsFactors = FALSE) %>% unique %>% as.vector,
  "SRSF3 FLASH_seq HEK293 GSE118265 PEP0.01" = read.delim(paste(FLASHseq_dir, "pureclip_peaks_SR8-SRSF3.bed_geneset_PEP0.01.txt", sep = ""), header = FALSE, stringsAsFactors = FALSE) %>% unique %>% as.vector,
  # "SRSF4 FLASH_seq HEK293 GSE118265 PEP0.01" = read.delim(paste(FLASHseq_dir, "pureclip_peaks_SR9-SRSF4.bed_geneset_PEP0.01.txt", sep = ""), header = FALSE, stringsAsFactors = FALSE) %>% unique %>% as.vector,
  # "SRSF5 FLASH_seq HEK293 GSE118265 PEP0.01" = read.delim(paste(FLASHseq_dir, "pureclip_peaks_SR10-SRSF5.bed_geneset_PEP0.01.txt", sep = ""), header = FALSE, stringsAsFactors = FALSE) %>% unique %>% as.vector,
  "SRSF6 FLASH_seq HEK293 GSE118265 PEP0.01" = read.delim(paste(FLASHseq_dir, "pureclip_peaks_SR11-SRSF6.bed_geneset_PEP0.01.txt", sep = ""), header = FALSE, stringsAsFactors = FALSE) %>% unique %>% as.vector,
  # "SRSF7 FLASH_seq HEK293 GSE118265 PEP0.01" = read.delim(paste(FLASHseq_dir, "pureclip_peaks_SR12-SRSF7.bed_geneset_PEP0.01.txt", sep = ""), header = FALSE, stringsAsFactors = FALSE) %>% unique %>% as.vector,
  # "SRSF9 FLASH_seq HEK293 GSE118265 PEP0.01" = read.delim(paste(FLASHseq_dir, "pureclip_peaks_SR13-SRSF9.bed_geneset_PEP0.01.txt", sep = ""), header = FALSE, stringsAsFactors = FALSE) %>% unique %>% as.vector,
  "SRSF11 FLASH_seq HEK293 GSE118265 PEP0.01" = read.delim(paste(FLASHseq_dir, "pureclip_peaks_SR14-SRSF11.bed_geneset_PEP0.01.txt", sep = ""), header = FALSE, stringsAsFactors = FALSE) %>% unique %>% as.vector,
  
  "MBNL2 HiTS_CLiP MEF GSE60487 pvalue0.01" = read.delim(paste(clipseq_dir, "MBNL1.2.3_hits.clip_GSE60487/geneset_mbnl2_hits.clip_MEF_GSE60487_pvalue0.01.txt", sep = ""), header = FALSE, stringsAsFactors = FALSE) %>% unique %>% as.vector %>% lapply(toupper),
  "MBNL1 HiTS_CLiP MEF GSE60487 pvalue0.01" = read.delim(paste(clipseq_dir, "MBNL1.2.3_hits.clip_GSE60487/geneset_mbnl1_hits.clip_MEF_GSE60487_pvalue0.01.txt", sep = ""), header = FALSE, stringsAsFactors = FALSE) %>% unique %>% as.vector %>% lapply(toupper),
  "MBNL3 HiTS_CLiP MEF GSE60487 pvalue0.01" = read.delim(paste(clipseq_dir, "MBNL1.2.3_hits.clip_GSE60487/geneset_mbnl3_hits.clip_MEF_GSE60487_pvalue0.01.txt", sep = ""), header = FALSE, stringsAsFactors = FALSE) %>% unique %>% as.vector %>% lapply(toupper)
)

list_of_RBP_target_gene_categories <- list_of_RBP_target_gene_categories_raw %>% flatten

names(list_of_RBP_target_gene_categories) <- names(list_of_RBP_target_gene_categories_raw)

```

## enrichment of upstream RBPs - clusterwise

```{r}

## gene enrichment in each som_cluster

list_of_RBP_target_enrichment_by_SOM_cluster_AS_plausible <- purrr::map(.x = list_of_gene_tables_by_SOM_cluster_flattened_AS_plausible, .f = ~enrichment(genes = ., reference = reference_geneset, genesets = list_of_RBP_target_gene_categories, adj = "BH", verbose = FALSE) %>% bc3net_benjamini_correction %>% cbind(., genes_contained = filtering_genehits_from_background_catalogue(list_of_RBP_target_gene_categories[.$TermID %>% as.character], .x) %>% lapply(toString) %>% paste(sep = ", ") %>% unlist) %>% type_convert %>% as_tibble)

names(list_of_RBP_target_enrichment_by_SOM_cluster_AS_plausible) <- 1:number_of_som_clusters

list_of_RBP_target_enrichment_by_SOM_cluster_topten_AS_plausible <- purrr::map2(.x = list_of_RBP_target_enrichment_by_SOM_cluster_AS_plausible, .y = 1:number_of_som_clusters, .f = ~.x[order(.x$padj, decreasing = FALSE), ] %>% head(n = 10) %>% cbind(., som_cluster = .y) %>% as_tibble)

# bind rows and calculate ggplot facet x and y coordinates
wide_table_of_RBP_target_enrichment_by_SOM_cluster_topten_AS_plausible <- purrr::reduce(.x = list_of_RBP_target_enrichment_by_SOM_cluster_topten_AS_plausible, .f = bind_rows) %>% type_convert %>% cbind(., cluster_minus_1 = .$som_cluster - 1) %>% cbind(., remainder_facet.x = .$cluster_minus_1 %% 5) %>% cbind(., quotient_facet.y = .$cluster_minus_1 %/% 5)

## GGPLOT

ggplot(wide_table_of_RBP_target_enrichment_by_SOM_cluster_topten_AS_plausible, aes(x = reorder(TermID, -genes), y = genes)) +
  geom_col(aes(fill = log10(pval))) +
  scale_fill_distiller(name = expression(log["10"](P)), type = "seq", palette = "Purples", direction = -1,   aesthetics = "fill", na.value = "yellow") +
  facet_wrap(~som_cluster, scales = "free") +
  ggtitle("Top 10 significantly over-represented UPSTREAM RBP CANDIDATES for each PLAUSIBLE som_cluster in OB series") +
  scale_x_discrete(labels = function(x) str_wrap(x, width = 15)) +
  xlab("Upstream RBP with literature reference") +
  ylab("Number of genes enriched amongst RBP target genes") +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5, size = 5, lineheight = 0.75, colour = "black"), legend.title.align = 0.5, legend.background = element_rect(size=0.5, linetype="solid", colour ="black"), strip.background = element_blank(), strip.text.x = element_blank(), axis.title.y = element_text(margin = margin(r = 60)), text = element_text(family = "Helvetica")) +
  ggsave(filename = paste(R_processing_results_dir, som_xdim, "x", som_ydim, "_SOM_", length(long_table_of_final_SOM_summary_5_by_5_AS_plausible$AS_event_ID %>% unique), "_junctions_PSI_OB_diff_any_", p_or_q_value, qpvalue_cutoff, "_any_deltaPSI_greaterthan_", dPSI_cutoff, "_upstreamRBP_plausibleASlength.pdf", sep = ""), device = "pdf", dpi = 600, width = 45, height = 25, units = "cm") +
  ggsave(filename = paste(R_processing_results_dir, som_xdim, "x", som_ydim, "_SOM_", length(long_table_of_final_SOM_summary_5_by_5_AS_plausible$AS_event_ID %>% unique), "_junctions_PSI_OB_diff_any_", p_or_q_value, qpvalue_cutoff, "_any_deltaPSI_greaterthan_", dPSI_cutoff, "_upstreamRBP_plausibleASlength.svg", sep = ""), device = "svg", dpi = 600, width = 45, height = 25, units = "cm")

write.table(x = wide_table_of_RBP_target_enrichment_by_SOM_cluster_topten_AS_plausible, file = paste(R_processing_results_dir, som_xdim, "x", som_ydim, "_SOM_", length(long_table_of_final_SOM_summary_5_by_5_AS_plausible$AS_event_ID %>% unique), "_junctions_PSI_OB_diff_any_", p_or_q_value, qpvalue_cutoff, "_any_deltaPSI_greaterthan_", dPSI_cutoff, "_upstreamRBP_plausibleASlength.txt", sep = ""), sep = "\t", row.names = FALSE, quote = FALSE)


```

## enrichment of upstream RBPs - timepointwise

```{r}

### highest PSI 

list_of_highest_PSI_per_timepoint_RBPenrichment_AS_plausible <- purrr::map(.x = list_of_highest_PSI_isoforms_per_timepoint_filtered_AS_plausible, .f = ~enrichment(genes = .x, reference = reference_geneset, genesets = list_of_RBP_target_gene_categories, adj = "BH", verbose = FALSE) %>% bc3net_benjamini_correction %>% cbind(., genes_contained = filtering_genehits_from_background_catalogue(list_of_RBP_target_gene_categories[.$TermID %>% as.character], .x) %>% lapply(toString) %>% paste(sep = ", ") %>% unlist) %>% type_convert)

list_of_highest_PSI_per_timepoint_RBPenrichment_topten_AS_plausible <- purrr::map2(.x = list_of_highest_PSI_per_timepoint_RBPenrichment_AS_plausible, .y = as.list(names(list_of_highest_PSI_isoforms_per_timepoint_filtered_AS_plausible)), .f = ~.x[order(.x$padj, decreasing = FALSE), ] %>% head(n = 10) %>% cbind(., timepoint = .y))

# un-nest by binding rows
wide_table_of_timepointwise_highestPSI_upstreamRBP_AS_plausible <- purrr::reduce(.x = list_of_highest_PSI_per_timepoint_RBPenrichment_topten_AS_plausible, .f = bind_rows)

wide_table_of_timepointwise_highestPSI_upstreamRBP_AS_plausible <- type_convert(wide_table_of_timepointwise_highestPSI_upstreamRBP_AS_plausible)

wide_table_of_timepointwise_highestPSI_upstreamRBP_AS_plausible <- arrange(transform(wide_table_of_timepointwise_highestPSI_upstreamRBP_AS_plausible, timepoint = factor(timepoint, levels = unique(wide_table_of_timepointwise_highestPSI_upstreamRBP_AS_plausible$timepoint))), timepoint)

### lowest PSI

list_of_lowest_PSI_per_timepoint_RBPenrichment_AS_plausible <- purrr::map(.x = list_of_lowest_PSI_isoforms_per_timepoint_filtered_AS_plausible, .f = ~enrichment(genes = .x, reference = reference_geneset, genesets = list_of_RBP_target_gene_categories, adj = "BH", verbose = FALSE) %>% bc3net_benjamini_correction %>% cbind(., genes_contained = filtering_genehits_from_background_catalogue(list_of_RBP_target_gene_categories[.$TermID %>% as.character], .x) %>% lapply(toString) %>% paste(sep = ", ") %>% unlist) %>% type_convert)

list_of_lowest_PSI_per_timepoint_RBPenrichment_topten_AS_plausible <- purrr::map2(.x = list_of_lowest_PSI_per_timepoint_RBPenrichment_AS_plausible, .y = as.list(names(list_of_lowest_PSI_isoforms_per_timepoint_filtered_AS_plausible)), .f = ~.x[order(.x$padj, decreasing = FALSE), ] %>% head(n = 10) %>% cbind(., timepoint = .y))

# un-nest by binding rows
wide_table_of_timepointwise_lowestPSI_upstreamRBP_AS_plausible <- purrr::reduce(.x = list_of_lowest_PSI_per_timepoint_RBPenrichment_topten_AS_plausible, .f = bind_rows)

wide_table_of_timepointwise_lowestPSI_upstreamRBP_AS_plausible <- type_convert(wide_table_of_timepointwise_lowestPSI_upstreamRBP_AS_plausible)

wide_table_of_timepointwise_lowestPSI_upstreamRBP_AS_plausible <- arrange(transform(wide_table_of_timepointwise_lowestPSI_upstreamRBP_AS_plausible, timepoint = factor(timepoint, levels = unique(wide_table_of_timepointwise_lowestPSI_upstreamRBP_AS_plausible$timepoint))), timepoint)

## GGPLOT

# highest PSI

ggplot(wide_table_of_timepointwise_highestPSI_upstreamRBP_AS_plausible, aes(x = reorder(TermID, padj), y = genes)) +
  geom_col(aes(fill = log10(padj))) +
  scale_fill_distiller(name = expression(log["10"](P["b-hoch"])), type = "seq", palette = "Purples", direction = -1,   aesthetics = "fill", na.value = "yellow") +
  facet_wrap(~timepoint, scales = "free") +
  ggtitle(paste("Top 10 significantly over-represented upstream RBPs for the", high_scaledPSIcutoff * 100, "% highest PSI PLAUSIBLE isoforms in each OB timepoint")) +
  scale_x_discrete(labels = function(x) str_wrap(x, width = 3)) +
  xlab("Upstream RBP") +
  ylab("Number of gene targets in som_cluster") +
  # coord_cartesian(ylim = c(0, 20)) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5, size = 5, lineheight = 0.75, colour = "black"), legend.title.align = 0.5, legend.background = element_rect(size=0.5, linetype="solid", colour ="black"), axis.title.y = element_text(margin = margin(r = 20)), text = element_text(family="Helvetica")) +
  ggsave(filename = paste(R_processing_results_dir, "UpstreamRBPs_top10_", high_scaledPSIcutoff * 100, "_percent_highestPSI_eachtimepoint_OB_diff_any_", p_or_q_value, qpvalue_cutoff, "_any_deltaPSI_greaterthan_", dPSI_cutoff, "_plausibleASlength.pdf", sep = ""), device = "pdf", dpi = 600, width = 25, height = 15, units = "cm") +
  ggsave(filename = paste(R_processing_results_dir, "UpstreamRBPs_top10_", high_scaledPSIcutoff * 100, "_percent_highestPSI_eachtimepoint_OB_diff_any_", p_or_q_value, qpvalue_cutoff, "_any_deltaPSI_greaterthan_", dPSI_cutoff, "_plausibleASlength.svg", sep = ""), device = "svg", dpi = 600, width = 25, height = 15, units = "cm")

write.table(x = wide_table_of_timepointwise_highestPSI_upstreamRBP_AS_plausible, file = paste(R_processing_results_dir, "UpstreamRBPs_top10_", high_scaledPSIcutoff * 100, "_percent_highestPSI_eachtimepoint_OB_diff_any_", p_or_q_value, qpvalue_cutoff, "_any_deltaPSI_greaterthan_", dPSI_cutoff, "_plausibleASlength.txt", sep = ""), sep = "\t", row.names = FALSE, quote = FALSE)

# lowest PSI

ggplot(wide_table_of_timepointwise_lowestPSI_upstreamRBP_AS_plausible, aes(x = reorder(TermID, padj), y = genes)) +
  geom_col(aes(fill = log10(padj))) +
  scale_fill_distiller(name = expression(log["10"](P["b-hoch"])), type = "seq", palette = "Purples", direction = -1,   aesthetics = "fill", na.value = "yellow") +
  facet_wrap(~timepoint, scales = "free") +
  ggtitle(paste("Top 10 significantly over-represented upstream RBPs for the", high_scaledPSIcutoff * 100, "% lowest PSI PLAUSIBLE isoforms in each OB timepoint")) +
  scale_x_discrete(labels = function(x) str_wrap(x, width = 3)) +
  xlab("Upstream RBP") +
  ylab("Number of gene targets in som_cluster") +
  # coord_cartesian(ylim = c(0, 20)) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5, size = 5, lineheight = 0.75, colour = "black"), legend.title.align = 0.5, legend.background = element_rect(size=0.5, linetype="solid", colour ="black"), axis.title.y = element_text(margin = margin(r = 20)), text = element_text(family="Helvetica")) +
  ggsave(filename = paste(R_processing_results_dir, "UpstreamRBPs_top10_", low_scaledPSIcutoff * 100, "_percent_lowestPSI_eachtimepoint_OB_diff_any_", p_or_q_value, qpvalue_cutoff, "_any_deltaPSI_greaterthan_", dPSI_cutoff, "_plausibleASlength.pdf", sep = ""), device = "pdf", dpi = 600, width = 25, height = 15, units = "cm") +
  ggsave(filename = paste(R_processing_results_dir, "UpstreamRBPs_top10_", low_scaledPSIcutoff * 100, "_percent_lowestPSI_eachtimepoint_OB_diff_any_", p_or_q_value, qpvalue_cutoff, "_any_deltaPSI_greaterthan_", dPSI_cutoff, "_plausibleASlength.svg", sep = ""), device = "svg", dpi = 600, width = 25, height = 15, units = "cm")

write.table(x = wide_table_of_timepointwise_lowestPSI_upstreamRBP_AS_plausible, file = paste(R_processing_results_dir, "UpstreamRBPs_top10_", low_scaledPSIcutoff * 100, "_percent_lowestPSI_eachtimepoint_OB_diff_any_", p_or_q_value, qpvalue_cutoff, "_any_deltaPSI_greaterthan_", dPSI_cutoff, "_plausibleASlength.txt", sep = ""), sep = "\t", row.names = FALSE, quote = FALSE)


```

# QUALITY CHECK

## create quality check results directory

```{r}

qualitycheck_results_dir <-  paste(R_processing_results_dir, "qualitycheck/", sep = "")

if(! dir.exists(qualitycheck_results_dir) ) {
  dir.create(qualitycheck_results_dir, recursive = TRUE)}

JUM_diff_dir <- "Y:/PGNEXUS/analysis_JUM/run_1_PGNEXUS_pvalue1/results/JUM_diff/"

```

## check for stringency of timepointwise top/bottom cutoff

```{r}

for (OBtimepoint in vector_OBseries_timepoints_edited) {
  
  ggplot(list_of_highest_PSI_isoforms_per_timepoint[[OBtimepoint]] %>% as.data.frame %>% mutate_if(is.factor, as.character) %>% type_convert, aes(x = .x)) + 
    geom_density() +
    ggtitle(paste("density_distribution_of_scaled_PSI_for_", OBtimepoint, "_timepoint_any_", p_or_q_value, qpvalue_cutoff, "_deltaPSI_greaterthan_", dPSI_cutoff, sep = "")) +
    xlab("scaled PSI") +
    ylab("proportion of isoforms") +
    theme_bw() +
    theme(text = element_text(family = "Helvetica")) +
    ggsave(filename = paste(qualitycheck_results_dir, "density_distribution_of_scaled_PSI_for_", OBtimepoint, "_timepoint_any_", p_or_q_value, qpvalue_cutoff, "_deltaPSI_greaterthan_", dPSI_cutoff, ".pdf", sep = ""), device = "pdf", dpi = 600, width = 45, height = 25, units = "cm") +
    ggsave(filename = paste(qualitycheck_results_dir, "density_distribution_of_scaled_PSI_for_", OBtimepoint, "_timepoint_any_", p_or_q_value, qpvalue_cutoff, "_deltaPSI_greaterthan_", dPSI_cutoff, ".svg", sep = ""), device = "svg", dpi = 600, width = 45, height = 25, units = "cm") 
  
  ggplot(list_of_highest_PSI_isoforms_per_timepoint[[OBtimepoint]] %>% as.data.frame %>% mutate_if(is.factor, as.character) %>% type_convert, aes(x = .x)) + 
    stat_ecdf(geom = "smooth", colour = "black") +
    geom_hline(aes(yintercept = 0.1), color = "red", linetype = "dashed", size = 1) +
    ggtitle(paste("CDF_distribution_of_scaled_PSI_for_", OBtimepoint, "_timepoint_any_", p_or_q_value, qpvalue_cutoff, "_deltaPSI_greaterthan_", dPSI_cutoff, sep = "")) +
    xlab("scaled PSI") +
    ylab("proportion of isoforms") +
    scale_y_continuous(breaks = c(0.0, 0.1, 0.2, 0.4, 0.6, 0.8, 1.0)) +
    theme_bw() +
    theme(text = element_text(family = "Helvetica")) +
    ggsave(filename = paste(qualitycheck_results_dir, "CDF_distribution_of_scaled_PSI_for_", OBtimepoint, "_timepoint_any_", p_or_q_value, qpvalue_cutoff, "_deltaPSI_greaterthan_", dPSI_cutoff, ".pdf", sep = ""), device = "pdf", dpi = 600, width = 45, height = 25, units = "cm") +
    ggsave(filename = paste(qualitycheck_results_dir, "CDF_distribution_of_scaled_PSI_for_", OBtimepoint, "_timepoint_any_", p_or_q_value, qpvalue_cutoff, "_deltaPSI_greaterthan_", dPSI_cutoff, ".svg", sep = ""), device = "svg", dpi = 600, width = 45, height = 25, units = "cm")
  
}

```

## check for whether there is any dependence of number of junctions detected vs. coverage

```{r}

number_of_junctions_detected_per_sample <- read.delim(paste(qualitycheck_results_dir, "number_of_junctions_detected_per_sample.txt", sep = ""), stringsAsFactors = FALSE, sep = "\t", header = TRUE) %>% as_tibble

coveragedata <- read.delim(paste(qualitycheck_results_dir, "coveragedata.txt", sep = ""), stringsAsFactors = FALSE, sep = "\t", header = TRUE, row.names = NULL) %>% as_tibble

num_junctions_vs_coverage <- dplyr::inner_join(number_of_junctions_detected_per_sample, coveragedata, by = "timepoint_name")

num_junctions_vs_coverage_pearson <- cor(num_junctions_vs_coverage[, 2], num_junctions_vs_coverage[, 3], method = "pearson") %>% signif(4)

num_junctions_vs_coverage_gradient <- lm(formula = junction_counts ~ read_count, num_junctions_vs_coverage) %>% .[[1]] %>% .[2] %>% signif(digits = 4)

num_junctions_vs_coverage_intercept <- lm(formula = junction_counts ~ read_count, num_junctions_vs_coverage) %>% .[[1]] %>% .[1] %>% signif(4)

ggplot(num_junctions_vs_coverage, aes(y = junction_counts, x = read_count)) +
  geom_point() +
  geom_smooth(method = "lm", formula = y~x, colour = "blue") +
  annotate(geom = "text", label = bquote("R"^2 ~ "=" ~ .(num_junctions_vs_coverage_pearson)), x = 3.75e7, y = 244000, color = "blue") +
  annotate(geom = "text", label = bquote("y =" ~ .(num_junctions_vs_coverage_gradient) ~ "x +" ~ .(num_junctions_vs_coverage_intercept)), x = 3.75e7, y = 240000, color = "blue") +
  ggtitle(paste("plot_of_number_of_junctions_per_sample_vs_coverage", sep = "")) +
  xlab("Sequencing Depth") +
  ylab("Number of splice junctions detected") +
  theme_bw() +
  theme(text = element_text(family = "Helvetica")) +
  ggsave(filename = paste(qualitycheck_results_dir, "plot_of_number_of_junctions_per_sample_vs_coverage", ".pdf", sep = ""), device = "pdf", dpi = 600, width = 15, height = 15, units = "cm") +
  ggsave(filename = paste(qualitycheck_results_dir, "plot_of_number_of_junctions_per_sample_vs_coverage", ".svg", sep = ""), device = "svg", dpi = 600, width = 15, height = 15, units = "cm")


```


## frequency distribution of no. junctions structures detected/gene

### all junctions

```{r}

avg_junctions_per_gene_all <- (wide_tibble_dpsi_differential$AS_event_ID %>% unique %>% length)/(wide_tibble_dpsi_differential$Gene %>% unique %>% length)

print(paste("There are", avg_junctions_per_gene_all, "unique junction structures overall without considering plausible AS length"))

junctions_per_gene_all_freq <- wide_tibble_dpsi_differential %>% dplyr::distinct(., AS_event_ID, .keep_all = TRUE) %>% group_by(Gene) %>% summarise(no_junctions = n())

junctions_per_gene_all_freq_2 <- junctions_per_gene_all_freq %>% group_by(no_junctions) %>% summarise(numberofgeneswithjunctionnumber = n())

# ggplot

ggplot(junctions_per_gene_all_freq_2) + 
  geom_col(aes(y = numberofgeneswithjunctionnumber, x = no_junctions)) +
  geom_text(data = junctions_per_gene_all_freq_2, aes(label = numberofgeneswithjunctionnumber, y = numberofgeneswithjunctionnumber + 20, x = no_junctions), position = position_nudge(y = 400), angle = 90) +
  ggtitle(paste("frequency distribution of ALL junctions per gene\n1:2 ratio = ", junctions_per_gene_all_freq_2[1, 2]/junctions_per_gene_all_freq_2[2, 2], "\nThere are", avg_junctions_per_gene_all, "unique junction structures overall without considering plausible AS length", sep = "")) +
  # scale_x_continuous(trans = "log2") +
  scale_x_continuous(limits = c(0, 10), breaks = 1:10) +
  ylim(c(0, max(junctions_per_gene_all_freq_2$numberofgeneswithjunctionnumber) + 700)) +
  xlab("number of junctions/gene") +
  ylab("number of genes") +
  theme_bw() +
  theme(text = element_text(family = "Helvetica")) +
  ggsave(filename = paste(qualitycheck_results_dir, "frequency_distribution_of_all_junctions_per_gene_", p_or_q_value, qpvalue_cutoff, "_deltaPSI_greaterthan_", dPSI_cutoff, "_all.pdf", sep = ""), device = "pdf", dpi = 600, width = 8, height = 8, units = "cm") +
  ggsave(filename = paste(qualitycheck_results_dir, "frequency_distribution_of_all_junctions_per_gene_", p_or_q_value, qpvalue_cutoff, "_deltaPSI_greaterthan_", dPSI_cutoff, "_all.svg", sep = ""), device = "svg", dpi = 600, width = 8, height = 8, units = "cm") 

# print(paste("Ratio of number of 1 isoform genes : 2 isoform genes =", junctions_per_gene_all_freq_2[1, 2]/junctions_per_gene_all_freq_2[2, 2]))

```

### all constitutive junctions

```{r}

avg_junctions_per_gene_all <- (PSI_levels_timeseries_constitutive_OB_wide_with_na$AS_event_ID %>% unique %>% length)/(PSI_levels_timeseries_constitutive_OB_wide_with_na$Gene %>% unique %>% length)

print(paste("There are", avg_junctions_per_gene_all, "unique constitutive junction structures detected without considering plausible AS length"))

junctions_per_gene_all_freq <- PSI_levels_timeseries_constitutive_OB_wide_with_na %>% dplyr::distinct(., AS_event_ID, .keep_all = TRUE) %>% group_by(Gene) %>% summarise(no_junctions = n())

junctions_per_gene_all_freq_2 <- junctions_per_gene_all_freq %>% group_by(no_junctions) %>% summarise(numberofgeneswithjunctionnumber = n())

# ggplot

ggplot(junctions_per_gene_all_freq_2) + 
  geom_col(aes(y = numberofgeneswithjunctionnumber, x = no_junctions)) +
  geom_text(data = junctions_per_gene_all_freq_2, aes(label = numberofgeneswithjunctionnumber, y = numberofgeneswithjunctionnumber + 20, x = no_junctions), position = position_nudge(y = 300), angle = 90) +
  ggtitle(paste("frequency distribution of constitutive junctions per gene\n1:2 ratio = ", junctions_per_gene_all_freq_2[1, 2]/junctions_per_gene_all_freq_2[2, 2], "\nThere are", avg_junctions_per_gene_all, "unique constitutive junction structures detected without considering plausible AS length", sep = "")) +
  # scale_x_continuous(trans = "log2") +
  scale_x_continuous(limits = c(0, 10), breaks = 1:10) +
  ylim(c(0, max(junctions_per_gene_all_freq_2$numberofgeneswithjunctionnumber) + 500)) +
  xlab("number of junctions/gene") +
  ylab("number of genes") +
  theme_bw() +
  theme(text = element_text(family = "Helvetica")) +
  ggsave(filename = paste(qualitycheck_results_dir, "frequency_distribution_of_constitutive_junctions_per_gene_", p_or_q_value, qpvalue_cutoff, "_deltaPSI_greaterthan_", dPSI_cutoff, "_all.pdf", sep = ""), device = "pdf", dpi = 600, width = 8, height = 8, units = "cm") +
  ggsave(filename = paste(qualitycheck_results_dir, "frequency_distribution_of_constitutive_junctions_per_gene_", p_or_q_value, qpvalue_cutoff, "_deltaPSI_greaterthan_", dPSI_cutoff, "_all.svg", sep = ""), device = "svg", dpi = 600, width = 8, height = 8, units = "cm") 

# print(paste("Ratio of number of 1 isoform genes : 2 isoform genes =", junctions_per_gene_all_freq_2[1, 2]/junctions_per_gene_all_freq_2[2, 2]))

```

### all differential junctions

```{r}

avg_junctions_per_gene_all <- (PSI_levels_timeseries_OB_wide_with_na$AS_event_ID %>% unique %>% length)/(PSI_levels_timeseries_OB_wide_with_na$Gene %>% unique %>% length)

print(paste("There are", avg_junctions_per_gene_all, "unique differentially spliced junction structures detected without considering plausible AS length"))

junctions_per_gene_all_freq <- PSI_levels_timeseries_OB_wide_with_na %>% dplyr::distinct(., AS_event_ID, .keep_all = TRUE) %>% group_by(Gene) %>% summarise(no_junctions = n())

junctions_per_gene_all_freq_2 <- junctions_per_gene_all_freq %>% group_by(no_junctions) %>% summarise(numberofgeneswithjunctionnumber = n())

# ggplot

ggplot(junctions_per_gene_all_freq_2) + 
  geom_col(aes(y = numberofgeneswithjunctionnumber, x = no_junctions)) +
  geom_text(data = junctions_per_gene_all_freq_2, aes(label = numberofgeneswithjunctionnumber, y = numberofgeneswithjunctionnumber + 20, x = no_junctions), position = position_nudge(y = 100), angle = 90) +
  ggtitle(paste("frequency distribution of differential junctions per gene\n1:2 ratio = ", junctions_per_gene_all_freq_2[1, 2]/junctions_per_gene_all_freq_2[2, 2], "\nThere are", avg_junctions_per_gene_all, "unique differentially spliced junction structures detected without considering plausible AS length", sep = "")) +
  scale_x_continuous(limits = c(0, 10), breaks = 1:10) +
  ylim(c(0, max(junctions_per_gene_all_freq_2$numberofgeneswithjunctionnumber) + 200)) +
  xlab("number of junctions/gene") +
  ylab("number of genes") +
  theme_bw() +
  theme(text = element_text(family = "Helvetica")) +
  ggsave(filename = paste(qualitycheck_results_dir, "frequency_distribution_of_junctions_per_gene_", p_or_q_value, qpvalue_cutoff, "_deltaPSI_greaterthan_", dPSI_cutoff, "_all.pdf", sep = ""), device = "pdf", dpi = 600, width = 8, height = 8, units = "cm") +
  ggsave(filename = paste(qualitycheck_results_dir, "frequency_distribution_of_junctions_per_gene_", p_or_q_value, qpvalue_cutoff, "_deltaPSI_greaterthan_", dPSI_cutoff, "_all.svg", sep = ""), device = "svg", dpi = 600, width = 8, height = 8, units = "cm") 

# print(paste("Ratio of number of 1 isoform genes : 2 isoform genes =", junctions_per_gene_all_freq_2[1, 2]/junctions_per_gene_all_freq_2[2, 2]))

```

## frequency distribution of no. events detected per category

```{r}

junctions_per_category_all_freq <- PSI_levels_timeseries_OB_wide_with_na %>% dplyr::distinct(., AS_event_ID, .keep_all = TRUE) %>% group_by(splicemode) %>% summarise(no_junctions_all = n()) %>% dplyr::arrange(desc(no_junctions_all))
# 
# junctions_per_category_summary <- dplyr::full_join(junctions_per_category_all_freq, junctions_per_category_AS_plausible_freq, by = "splicemode")
# 
# junctions_per_category_summary_2 <- add_column(junctions_per_category_summary, "percentage_change_after_AS_plausible_filtering" = paste(signif((junctions_per_category_summary$no_junctions_AS_plausible - junctions_per_category_summary$no_junctions_all) * 100 / junctions_per_category_summary$no_junctions_all, 2), "%"))
# 
# long_junctions_per_category_summary_2 <- reshape2::melt(junctions_per_category_summary_2, id.vars = "splicemode")
# 
# long_junctions_per_category_summary_3 <- add_column(long_junctions_per_category_summary_2, "value_numeric" = gsub(x = long_junctions_per_category_summary_2$value, pattern = " %", replacement = "") %>% as.numeric)

# ggplot

ggplot(junctions_per_category_all_freq) + 
  geom_col(aes(y = no_junctions_all, x = splicemode)) +
  # facet_wrap(~variable, scales = "free", labeller = labeller("no_junctions_all" = "All AS structures", "no_junctions_AS_plausible" = "")) +
  geom_text(data = junctions_per_category_all_freq, aes(label = no_junctions_all, y = no_junctions_all, x = splicemode), angle = 90, position = position_nudge(x = 0, y = 60)) +
  ggtitle(paste("frequency distribution of differentially spliced junctions per category 
              ", p_or_q_value, qpvalue_cutoff, "_deltaPSI_greaterthan_", dPSI_cutoff, sep = "")) +
  scale_x_discrete(limits = junctions_per_category_all_freq$splicemode, breaks = junctions_per_category_all_freq$splicemode, labels = junctions_per_category_all_freq$splicemode %>% gsub(pattern = "_", replacement = " ")) +
  ylim(c(0, (junctions_per_category_all_freq$no_junctions_all %>% max) + 90)) +
  xlab("AS category") +
  ylab("Number of differential junctions") +
  theme_bw() +
  theme(text = element_text(family = "Helvetica")) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, colour = "black"), text = element_text(family = "Helvetica")) +
  ggsave(filename = paste(qualitycheck_results_dir, "frequency_distribution_of_junctions_per_category_", p_or_q_value, qpvalue_cutoff, "_deltaPSI_greaterthan_", dPSI_cutoff, ".pdf", sep = ""), device = "pdf", dpi = 600, width = 6, height = 8, units = "cm") +
  ggsave(filename = paste(qualitycheck_results_dir, "frequency_distribution_of_junctions_per_category_", p_or_q_value, qpvalue_cutoff, "_deltaPSI_greaterthan_", dPSI_cutoff, ".svg", sep = ""), device = "svg", dpi = 600, width = 6, height = 8, units = "cm") 

```

## frequency distribution of no. junctions detected with NMD/first exon/last exon

incl. NMD, first/last junction.

```{r}

# band-aids: add columns for reference first/last exon.
wide_tibble_dpsi_differential_2 <- wide_tibble_dpsi_differential %>% 
  add_column("first_exon_reference" = grepl(x = wide_tibble_dpsi_differential$first_or_last_exon_reference, pattern = "first_exon"),
             "last_exon_reference" = grepl(x = wide_tibble_dpsi_differential$first_or_last_exon_reference, pattern = "last_exon"))

PSI_levels_timeseries_constitutive_OB_wide_2 <- PSI_levels_timeseries_constitutive_OB_wide %>% 
  add_column("first_exon_reference" = grepl(x = PSI_levels_timeseries_constitutive_OB_wide$first_or_last_exon_reference, pattern = "first_exon"),
             "last_exon_reference" = grepl(x = PSI_levels_timeseries_constitutive_OB_wide$first_or_last_exon_reference, pattern = "last_exon"))

PSI_levels_timeseries_OB_wide_with_na_2 <- PSI_levels_timeseries_OB_wide_with_na %>% 
  add_column("first_exon_reference" = grepl(x = PSI_levels_timeseries_OB_wide_with_na$first_or_last_exon_reference, pattern = "first_exon"),
             "last_exon_reference" = grepl(x = PSI_levels_timeseries_OB_wide_with_na$first_or_last_exon_reference, pattern = "last_exon"))

# ALL JUNCTIONS
# category means splicemode + NMD status + first/last junction
# also clean up the splicemode column
tibble_junctions_per_category_all <- wide_tibble_dpsi_differential_2 %>% dplyr::distinct(., AS_event_ID, .keep_all = TRUE) %>% group_by(splicemode, NMD_flagged_recon, poison_exon_candidate_recon, first_exon_reference, last_exon_reference) %>% summarise(no_junctions_all = n())

tibble_junctions_per_category_all[is.na(tibble_junctions_per_category_all)] <- FALSE

tibble_junctions_per_category_all <- tibble_junctions_per_category_all %>% group_by(splicemode, NMD_flagged_recon, poison_exon_candidate_recon, first_exon_reference, last_exon_reference) %>% summarise(no_junctions_all = sum(no_junctions_all))

all_junctions_count <- tibble_junctions_per_category_all$no_junctions_all %>% sum(na.rm = TRUE)
number_NMD_all_junctions <- tibble_junctions_per_category_all[tibble_junctions_per_category_all$NMD_flagged_recon == TRUE, ] %>% .$no_junctions_all %>% sum(na.rm = TRUE)
number_poison_exon_all_junctions <- tibble_junctions_per_category_all[tibble_junctions_per_category_all$poison_exon_candidate_recon == TRUE, ] %>% .$no_junctions_all %>% sum(na.rm = TRUE)
number_first_junction_all_junctions <- tibble_junctions_per_category_all[tibble_junctions_per_category_all$first_exon_reference == TRUE, ] %>% .$no_junctions_all %>% sum(na.rm = TRUE)
number_last_junction_all_junctions <- tibble_junctions_per_category_all[tibble_junctions_per_category_all$last_exon_reference == TRUE, ] %>% .$no_junctions_all %>% sum(na.rm = TRUE)

message("There are ", number_NMD_all_junctions*100/all_junctions_count, "% NMD junctions overall.")
message("There are ", number_poison_exon_all_junctions*100/all_junctions_count, "% junctions touching at least one poison exon candidate.")
message("There are ", number_first_junction_all_junctions*100/all_junctions_count, "% first junctions overall.")
message("There are ", number_last_junction_all_junctions*100/all_junctions_count, "% last junctions overall.")

# CONSTITUTIVE JUNCTIONS
tibble_junctions_per_category_constitutive <- PSI_levels_timeseries_constitutive_OB_wide_2 %>% dplyr::distinct(., AS_event_ID, .keep_all = TRUE) %>% group_by(splicemode, NMD_flagged_recon, poison_exon_candidate_recon, first_exon_reference, last_exon_reference) %>% summarise(no_junctions_constitutive = n())

tibble_junctions_per_category_constitutive[is.na(tibble_junctions_per_category_constitutive)] <- FALSE

tibble_junctions_per_category_constitutive <- tibble_junctions_per_category_constitutive %>% group_by(splicemode, NMD_flagged_recon, poison_exon_candidate_recon, first_exon_reference, last_exon_reference) %>% summarise(no_junctions_constitutive = sum(no_junctions_constitutive))

constitutive_junctions_count <- tibble_junctions_per_category_constitutive$no_junctions_constitutive %>% sum(na.rm = TRUE)
number_NMD_constitutive_junctions <- tibble_junctions_per_category_constitutive[tibble_junctions_per_category_constitutive$NMD_flagged_recon == TRUE, ] %>% .$no_junctions_constitutive %>% sum(na.rm = TRUE)
number_poison_exon_constitutive_junctions <- tibble_junctions_per_category_constitutive[tibble_junctions_per_category_constitutive$poison_exon_candidate_recon == TRUE, ] %>% .$no_junctions_all %>% sum(na.rm = TRUE)
number_first_junction_constitutive_junctions <- tibble_junctions_per_category_constitutive[tibble_junctions_per_category_constitutive$first_exon_reference == TRUE, ] %>% .$no_junctions_constitutive %>% sum(na.rm = TRUE)
number_last_junction_constitutive_junctions <- tibble_junctions_per_category_constitutive[tibble_junctions_per_category_constitutive$last_exon_reference == TRUE, ] %>% .$no_junctions_constitutive %>% sum(na.rm = TRUE)

message("There are ", number_NMD_constitutive_junctions*100/constitutive_junctions_count, "% NMD junctions constitutive.")
message("There are ", number_poison_exon_constitutive_junctions*100/constitutive_junctions_count, "% junctions touching at least one poison exon candidate.")
message("There are ", number_first_junction_constitutive_junctions*100/constitutive_junctions_count, "% first junctions constitutive.")
message("There are ", number_last_junction_constitutive_junctions*100/constitutive_junctions_count, "% last junctions constitutive.")

# DIFFERENTIAL JUNCTIONS
tibble_junctions_per_category_differential <- PSI_levels_timeseries_OB_wide_with_na_2 %>% dplyr::distinct(., AS_event_ID, .keep_all = TRUE) %>% group_by(splicemode, NMD_flagged_recon, poison_exon_candidate_recon, first_exon_reference, last_exon_reference) %>% summarise(no_junctions_differential = n())

tibble_junctions_per_category_differential[is.na(tibble_junctions_per_category_differential)] <- FALSE

tibble_junctions_per_category_differential <- tibble_junctions_per_category_differential %>% group_by(splicemode, NMD_flagged_recon, poison_exon_candidate_recon, first_exon_reference, last_exon_reference) %>% summarise(no_junctions_differential = sum(no_junctions_differential))

differential_junctions_count <- tibble_junctions_per_category_differential$no_junctions_differential %>% sum(na.rm = TRUE)
number_NMD_differential_junctions <- tibble_junctions_per_category_differential[tibble_junctions_per_category_differential$NMD_flagged_recon == TRUE, ] %>% .$no_junctions_differential %>% sum(na.rm = TRUE)
number_poison_exon_differential_junctions <- tibble_junctions_per_category_differential[tibble_junctions_per_category_differential$poison_exon_candidate_recon == TRUE, ] %>% .$no_junctions_all %>% sum(na.rm = TRUE)
number_first_exon_differential_junctions <- tibble_junctions_per_category_differential[tibble_junctions_per_category_differential$first_exon_reference == TRUE, ] %>% .$no_junctions_differential %>% sum(na.rm = TRUE)
number_last_exon_differential_junctions <- tibble_junctions_per_category_differential[tibble_junctions_per_category_differential$last_exon_reference == TRUE, ] %>% .$no_junctions_differential %>% sum(na.rm = TRUE)

message("There are ", number_NMD_differential_junctions*100/differential_junctions_count, "% NMD junctions differential.")
message("There are ", number_poison_exon_differential_junctions*100/differential_junctions_count, "% junctions touching at least one poison exon candidate.")
message("There are ", number_first_exon_differential_junctions*100/differential_junctions_count, "% first junctions differential.")
message("There are ", number_last_exon_differential_junctions*100/differential_junctions_count, "% last junctions differential.")

# COMBINE ALL THE TABLES FOR PLOTTING
tibble_junctions_per_category_summary <- list(tibble_junctions_per_category_all, tibble_junctions_per_category_constitutive, tibble_junctions_per_category_differential) %>% purrr::reduce(dplyr::full_join)

# melt the sample
long_tibble_junctions_per_category_summary <- reshape2::melt(tibble_junctions_per_category_summary, id.vars = c("splicemode", "NMD_flagged_recon", "poison_exon_candidate_recon", "first_exon_reference", "last_exon_reference"), variable.name = "sample", value.name = "number_of_junctions_per_category") %>% as_tibble %>% 
  # add the overall counts for each splicemode
  dplyr::group_by(splicemode, sample) %>% dplyr::mutate("number_of_junctions_per_splicemode" = sum(number_of_junctions_per_category %>% na.omit))

# melt the category (splicemode + NMD+ first + last exon)
long_tibble_junctions_per_category_summary_2 <- reshape2::melt(long_tibble_junctions_per_category_summary, id.vars = c("splicemode", "sample", "number_of_junctions_per_category", "number_of_junctions_per_splicemode"), variable.name = "NMD_first_last_exon", value.name = "NMD_first_last_exon_value") %>% as_tibble %>% 
  # add the overall counts for each unique category
  dplyr::group_by(splicemode, sample, NMD_first_last_exon, NMD_first_last_exon_value) %>% dplyr::mutate("number_of_junctions_per_category" = sum(number_of_junctions_per_category %>% na.omit)) %>% unique %>%
  # add the percentage for each category/splicemode
  dplyr::mutate("percentage_junctions_per_category" = number_of_junctions_per_category*100/number_of_junctions_per_splicemode)

max_number_of_junctions_per_splicemode <- max(long_tibble_junctions_per_category_summary_2$number_of_junctions_per_splicemode)
max_percentage_junctions_per_category <- max(long_tibble_junctions_per_category_summary_2[long_tibble_junctions_per_category_summary_2$NMD_first_last_exon_value == TRUE, ] %>% .$percentage_junctions_per_category %>% na.omit)
max_number_of_junctions_per_splicemode_for_plot <- max_number_of_junctions_per_splicemode + 500

# ggplot
ggplot() + 
  geom_col(data = long_tibble_junctions_per_category_summary_2[, c("splicemode", "sample", "number_of_junctions_per_splicemode")]  %>% dplyr::distinct(splicemode, sample, .keep_all = TRUE), aes(y = number_of_junctions_per_splicemode, x = splicemode)) +
  facet_wrap(~sample, scales = "free", labeller = labeller(sample = c(no_junctions_all = "All junctions", no_junctions_constitutive = "Constitutive", no_junctions_differential = "Differential", no_junctions_differential_plausible = "Differential (plausible)"))) +
  geom_text(data = long_tibble_junctions_per_category_summary_2[, c("splicemode", "sample", "number_of_junctions_per_splicemode")]  %>% dplyr::distinct(splicemode, sample, .keep_all = TRUE), aes(label = number_of_junctions_per_splicemode, y = number_of_junctions_per_splicemode, x = splicemode), angle = 90, position = position_nudge(x = 0, y = 500)) +
  geom_point(data = long_tibble_junctions_per_category_summary_2[long_tibble_junctions_per_category_summary_2$NMD_first_last_exon_value == TRUE, ], aes(x = splicemode, y = percentage_junctions_per_category * max_number_of_junctions_per_splicemode_for_plot / max_percentage_junctions_per_category, shape = NMD_first_last_exon), width = 0.1, height = 0) +
  ggtitle(paste("Frequency distribution of VSRs per category 
                ", p_or_q_value, qpvalue_cutoff, "_dpsi", dPSI_cutoff, sep = "")) +
  xlab("Splicemode") +
  scale_y_continuous(name = "Number of VSRs", limits = c(0, max_number_of_junctions_per_splicemode_for_plot), sec.axis = sec_axis(trans = ~. * max_percentage_junctions_per_category/max_number_of_junctions_per_splicemode_for_plot, name = "Percentage NMD/first/last exon per splicemode", breaks = seq(0, 100, 20))) +
  scale_shape_manual(name = "Category", limits = c("first_exon_reference", "last_exon_reference"), labels = c("First exon", "Last exon", "NMD", "poison_exon_candidate"), values = c(1, 4, 19, 11)) + 
  # , "NMD_flagged_recon", "poison_exon_candidate_recon"
  theme_bw() +
  theme(text = element_text(family = "Helvetica")) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, colour = "black"), text = element_text(family = "Helvetica")) +
  ggsave(filename = paste(R_processing_results_dir, "frequency_distribution_of_VSRs_per_NMD.first.last.exon_", p_or_q_value, qpvalue_cutoff, "_dpsi", dPSI_cutoff, ".pdf", sep = ""), device = "pdf", dpi = 600, width = 20, height = 10, units = "cm") +
  ggsave(filename = paste(R_processing_results_dir, "frequency_distribution_of_VSRs_per_NMD.first.last.exon_", p_or_q_value, qpvalue_cutoff, "_dpsi", dPSI_cutoff, ".svg", sep = ""), device = "svg", dpi = 600, width = 20, height = 10, units = "cm") 

# upset plot
message("all junctions")
df <- wide_tibble_dpsi_differential_2 %>% dplyr::distinct(., AS_event_ID, .keep_all = TRUE) %>% .[, c("AS_event_ID", "splicemode", "NMD_flagged_recon", "poison_exon_candidate_recon", "first_exon_reference", "last_exon_reference")] %>% add_column("dummy" = TRUE) %>% reshape2::dcast(formula = AS_event_ID + NMD_flagged_recon + poison_exon_candidate_recon + first_exon_reference + last_exon_reference ~ splicemode, value.var = "dummy") %>% as_tibble 

df[is.na(df)] = FALSE

upset_combs <- data.frame(df %>% dplyr::select(., -AS_event_ID), row.names = df$AS_event_ID) %>% make_comb_mat(mode = "distinct")

print(set_size(upset_combs))

pdf(file = paste(R_processing_results_dir, "upset_plot_of_intersections_junctions_per_NMD.first.last.exon_per_splicemode_", p_or_q_value, qpvalue_cutoff, "_dpsi", dPSI_cutoff, "_alljunctions.pdf", sep = ""), height = 4, width = 10)

ht <- draw(ComplexHeatmap::UpSet(upset_combs, 
                                 comb_order = order(-comb_size(upset_combs)), 
                                 left_annotation = rowAnnotation("Set Type" = c("any_NMD" = "Junction ontology",
                                                                                "first_exon_reference" = "Junction ontology",
                                                                                "last_exon_reference" = "Junction ontology",
                                                                                "A3SS_events" = "Splicemode",
                                                                                "A5SS_events" = "Splicemode",
                                                                                "cassette_exon_events" = "Splicemode",
                                                                                "composite_events" = "Splicemode",
                                                                                "intron_retention" = "Splicemode")[set_name(upset_combs)], show_annotation_name = FALSE, 
                                                                 col = list("Set Type" = c("Junction ontology" = "tomato1", "Splicemode" = "blue2"))
                                 )))
od <- column_order(ht)
cs <- comb_size(upset_combs)

decorate_annotation("Intersection\nsize", {
  grid.text(cs[od], x = seq_along(cs), y = unit(cs[od], "native") + unit(2, "pt"), 
            default.units = "native", just = c("left", "centre"), gp = gpar(fontsize = 8), rot = 90)
})

dev.off()

message("all constitutive")
df <- PSI_levels_timeseries_constitutive_OB_wide_2 %>% dplyr::distinct(., AS_event_ID, .keep_all = TRUE) %>% .[, c("AS_event_ID", "splicemode", "NMD_flagged_recon", "poison_exon_candidate_recon", "first_exon_reference", "last_exon_reference")] %>% add_column("dummy" = TRUE) %>% reshape2::dcast(formula = AS_event_ID + NMD_flagged_recon + poison_exon_candidate_recon + first_exon_reference + last_exon_reference ~ splicemode, value.var = "dummy") %>% as_tibble 

df[is.na(df)] = FALSE

upset_combs <- data.frame(df %>% dplyr::select(., -AS_event_ID), row.names = df$AS_event_ID) %>% make_comb_mat(mode = "distinct")

print(set_size(upset_combs))

pdf(file = paste(R_processing_results_dir, "upset_plot_of_intersections_junctions_per_NMD.first.last.exon_per_splicemode_", p_or_q_value, qpvalue_cutoff, "_dpsi", dPSI_cutoff, "_constitutive.pdf", sep = ""), height = 4, width = 10)

ht <- draw(ComplexHeatmap::UpSet(upset_combs, 
                                 comb_order = order(-comb_size(upset_combs)), 
                                 left_annotation = rowAnnotation("Set Type" = c("any_NMD" = "Junction ontology",
                                                                                "first_exon_reference" = "Junction ontology",
                                                                                "last_exon_reference" = "Junction ontology",
                                                                                "A3SS_events" = "Splicemode",
                                                                                "A5SS_events" = "Splicemode",
                                                                                "cassette_exon_events" = "Splicemode",
                                                                                "composite_events" = "Splicemode",
                                                                                "intron_retention" = "Splicemode")[set_name(upset_combs)], show_annotation_name = FALSE, 
                                                                 col = list("Set Type" = c("Junction ontology" = "tomato1", "Splicemode" = "blue2"))
                                 )))
od <- column_order(ht)
cs <- comb_size(upset_combs)

decorate_annotation("Intersection\nsize", {
  grid.text(cs[od], x = seq_along(cs), y = unit(cs[od], "native") + unit(2, "pt"), 
            default.units = "native", just = c("left", "centre"), gp = gpar(fontsize = 8), rot = 90)
})

dev.off()

message("all differential")
df <- PSI_levels_timeseries_OB_wide_with_na_2 %>% dplyr::distinct(., AS_event_ID, .keep_all = TRUE) %>% .[, c("AS_event_ID", "splicemode", "NMD_flagged_recon", "poison_exon_candidate_recon", "first_exon_reference", "last_exon_reference")] %>% add_column("dummy" = TRUE) %>% reshape2::dcast(formula = AS_event_ID + NMD_flagged_recon + poison_exon_candidate_recon + first_exon_reference + last_exon_reference ~ splicemode, value.var = "dummy") %>% as_tibble 

df[is.na(df)] = FALSE

upset_combs <- data.frame(df %>% dplyr::select(., -AS_event_ID), row.names = df$AS_event_ID) %>% make_comb_mat(mode = "distinct")

print(set_size(upset_combs))

pdf(file = paste(R_processing_results_dir, "upset_plot_of_intersections_junctions_per_NMD.first.last.exon_per_splicemode_", p_or_q_value, qpvalue_cutoff, "_dpsi", dPSI_cutoff, "_differential.pdf", sep = ""), height = 4, width = 10)

ht <- draw(ComplexHeatmap::UpSet(upset_combs, 
                                 comb_order = order(-comb_size(upset_combs)), 
                                 left_annotation = rowAnnotation("Set Type" = c("any_NMD" = "Junction ontology",
                                                                                "first_exon_reference" = "Junction ontology",
                                                                                "last_exon_reference" = "Junction ontology",
                                                                                "A3SS_events" = "Splicemode",
                                                                                "A5SS_events" = "Splicemode",
                                                                                "cassette_exon_events" = "Splicemode",
                                                                                "composite_events" = "Splicemode",
                                                                                "intron_retention" = "Splicemode")[set_name(upset_combs)], show_annotation_name = FALSE, 
                                                                 col = list("Set Type" = c("Junction ontology" = "tomato1", "Splicemode" = "blue2"))
                                 )))
od <- column_order(ht)
cs <- comb_size(upset_combs)

decorate_annotation("Intersection\nsize", {
  grid.text(cs[od], x = seq_along(cs), y = unit(cs[od], "native") + unit(2, "pt"), 
            default.units = "native", just = c("left", "centre"), gp = gpar(fontsize = 8), rot = 90)
})

dev.off()

```

## check the concordance between the ref and recon gtf first/last exon and NMD

```{r}

# get row indices of first/last exon and NMD annotations.
## first exon
row.indices_first_exon_ref <- grep(x = wide_tibble_dpsi_differential$first_or_last_exon_reference, pattern = "first_exon")
row.indices_first_exon_recon <- grep(x = wide_tibble_dpsi_differential$first_or_last_exon_recon, pattern = "first_exon")

row.indices_first_exon_ref.recon.intersection <- intersect(row.indices_first_exon_ref, row.indices_first_exon_recon)
row.indices_first_exon_ref.recon.union <- union(row.indices_first_exon_ref, row.indices_first_exon_recon)

message("number of first exons in the reference: ", row.indices_first_exon_ref %>% length)
message("number of first exons in the recon: ", row.indices_first_exon_recon %>% length)
message("number of first exons in BOTH recon and reference: ", row.indices_first_exon_ref.recon.intersection %>% length)
message("first exons jaccard similarity: ", (row.indices_first_exon_ref.recon.intersection %>% length)/(row.indices_first_exon_ref.recon.union %>% length))

## last exon
row.indices_last_exon_ref <- grep(x = wide_tibble_dpsi_differential$first_or_last_exon_reference, pattern = "last_exon")
row.indices_last_exon_recon <- grep(x = wide_tibble_dpsi_differential$first_or_last_exon_recon, pattern = "last_exon")

row.indices_last_exon_ref.recon.intersection <- intersect(row.indices_last_exon_ref, row.indices_last_exon_recon)
row.indices_last_exon_ref.recon.union <- union(row.indices_last_exon_ref, row.indices_last_exon_recon)

message("number of last exons in the reference: ", row.indices_last_exon_ref %>% length)
message("number of last exons in the recon: ", row.indices_last_exon_recon %>% length)
message("number of last exons in BOTH recon and reference: ", row.indices_last_exon_ref.recon.intersection %>% length)
message("last exons jaccard similarity: ", (row.indices_last_exon_ref.recon.intersection %>% length)/(row.indices_last_exon_ref.recon.union %>% length))

## NMD
row.indices_NMD_ref <- grep(x = wide_tibble_dpsi_differential$NMD_flagged_ref, pattern = "TRUE")
row.indices_NMD_recon <- grep(x = wide_tibble_dpsi_differential$NMD_recon, pattern = "TRUE")

row.indices_NMD_ref.recon.intersection <- intersect(row.indices_NMD_ref, row.indices_NMD_recon)
row.indices_NMD_ref.recon.union <- union(row.indices_NMD_ref, row.indices_NMD_recon)

message("number of NMD in the reference: ", row.indices_NMD_ref %>% length)
message("number of NMD in the recon: ", row.indices_NMD_recon %>% length)
message("number of NMD in BOTH recon and reference: ", row.indices_NMD_ref.recon.intersection %>% length)
message("NMD jaccard similarity: ", (row.indices_NMD_ref.recon.intersection %>% length)/(row.indices_NMD_ref.recon.union %>% length))

```


## Recording absolute PSI values for reporting junction switching

### Import the detailed tables into the environment

```{r message=FALSE, warning=FALSE}

list_of_timepoint_comparisons_final <- read.delim(paste(R_processing_results_dir, "list_of_timepoint_comparisons_final.txt", sep = ""), stringsAsFactors = FALSE, sep = "\t", header = FALSE, row.names = NULL) %>% array_tree %>% flatten

list_of_AS_events <- c("A3SS_events", "A5SS_events", "cassette_exon_events", "composite_events", "intron_retention", "MXE_events") %>% array_tree %>% flatten

# read tables into environment

list_of_detailed_tables <- purrr::map(.x = list_of_timepoint_comparisons_final, .f = ~purrr::map2(.x = .x, .y = list_of_AS_events, .f = ~read.delim(file = paste(R_processing_results_dir, "final_JUM_output_", .x, "/", list.files(path = paste(R_processing_results_dir, "final_JUM_output_", .x, "/", sep = ""), pattern = paste("(.)", .y, "(.*)detailed.txt", sep = "")), sep = ""), na.strings = c("NONE", "NA", "INF", "Inf") , sep = "\t", stringsAsFactors = FALSE) %>% as_tibble %>% add_column(., "splicemode" = .y)) %>% set_names(list_of_AS_events)) %>% set_names(list_of_timepoint_comparisons_final)

# bind rows for each comparison

list_of_detailed_tables_2 <- purrr::map(.x = list_of_detailed_tables, .f = ~rbindlist(.x))

# rename the colnames to be not comparison-specific - we will add a comparison column later on

list_of_detailed_tables_3 <- purrr::map2(.x = list_of_detailed_tables_2, .y = list_of_timepoint_comparisons_final, .f = ~setNames(., c("Gene", "AS_event_ID", "AS_structure_ID", "sub_junction_ID", "sub-junction_dispersion_estimate", "LRT_statistic-full_vs_reduced", "LRT_p_value-full_vs_reduced", "BH_adjusted_p-values", "logCPM_1", "logCPM_2", "fitting_parameter_log2fold_change_2_from_1", "chr", "sub_junction_start_coor", "sub_junction_end_coor", "sub_junction_size", "sub_junction_strand", "raw_count.1", "raw_count.2", "raw_count.3", "raw_count.4", "raw_count.5", "raw_count.6", "percentage_usage.1", "percentage_usage.2", "percentage_usage.3", "percentage_usage.4", "percentage_usage.5", "percentage_usage.6", "deltaPSI", "splicemode")) %>% add_column(., "comparison" = .y)) 

wide_tibble_of_all_detailed_tables <- list_of_detailed_tables_3 %>% rbindlist %>% as_tibble

# remove all the rows which have an NA except for in the dpsi because that's cassette exon.
wide_tibble_of_all_detailed_tables <- wide_tibble_of_all_detailed_tables[-which(is.na(wide_tibble_of_all_detailed_tables[, -29])), ]

wide_tibble_of_all_detailed_tables <- wide_tibble_of_all_detailed_tables[wide_tibble_of_all_detailed_tables$Gene != "Gene", ]

```

### extract only the MSC timepoint (ud)

we can take any comparison involving ud. I just happened to take the 12d - ud table.

```{r}

wide_tibble_of_all_detailed_tables_12d.ud.only <- wide_tibble_of_all_detailed_tables[wide_tibble_of_all_detailed_tables$comparison == "BM_MSC_to_OB_12d_vs_BM_MSC_to_OB_ud", ]

colnames(wide_tibble_of_all_detailed_tables_12d.ud.only)[29] <- "12d"

```

### calculate PSI by taking average of all 3 ud replicates

```{r}

wide_tibble_of_all_detailed_tables_12d.ud.only_2 <- wide_tibble_of_all_detailed_tables_12d.ud.only

wide_tibble_of_all_detailed_tables_12d.ud.only_2[, c(23:28)] <- wide_tibble_of_all_detailed_tables_12d.ud.only[, c(23:28)] %>% as.data.frame %>% apply(., 2, FUN = function(X){strsplit(X, split = "\\%") %>% unlist})

wide_tibble_of_all_detailed_tables_12d.ud.only_2 <- wide_tibble_of_all_detailed_tables_12d.ud.only_2[-which(is.na(wide_tibble_of_all_detailed_tables_12d.ud.only_2[, -29])), ]

wide_tibble_of_all_detailed_tables_12d.ud.only_3 <- wide_tibble_of_all_detailed_tables_12d.ud.only_2 %>% 
  add_column("avg_PSI_12d" = apply(X = .[, c("percentage_usage.1", "percentage_usage.2", "percentage_usage.3")], MARGIN = 1, FUN = function(X){mean(X %>% as.numeric)/100})) %>%
  add_column("avg_PSI_ud" = apply(X = .[, c("percentage_usage.4", "percentage_usage.5", "percentage_usage.6")], MARGIN = 1, FUN = function(X){mean(X %>% as.numeric)/100})) %>%
  add_column("dpsi_12d.minus.ud_1" = .$avg_PSI_12d - .$avg_PSI_ud)

```

### apply special averaging treatment for cassette exons

```{r}

list_detailed_cassette.exon_AS.event.IDs <- wide_tibble_of_all_detailed_tables_12d.ud.only_3[wide_tibble_of_all_detailed_tables_12d.ud.only_3$splicemode == "cassette_exon_events", "AS_event_ID"] %>% unique %>% array_tree

# subset 12d.ud table by AS event ID for cassette exons only

list_of_12d.ud_detailed_tibble_subset_by_AS.event.ID <- purrr::map(.x = list_detailed_cassette.exon_AS.event.IDs, .f = ~wide_tibble_of_all_detailed_tables_12d.ud.only_3[wide_tibble_of_all_detailed_tables_12d.ud.only_3$AS_event_ID == (.x %>% paste) & wide_tibble_of_all_detailed_tables_12d.ud.only_3$splicemode == "cassette_exon_events", ])

# append the cassette dpsi as dpsi_12d.minus.ud_2

list_of_12d.ud_detailed_tibble_subset_by_AS.event.ID_2 <- purrr::map(.x = list_of_12d.ud_detailed_tibble_subset_by_AS.event.ID, 
                                                                     .f = ~add_column(.x, "dpsi_12d.minus.ud_2" = .x[c(2, 3), "dpsi_12d.minus.ud_1"] %>% unlist %>% mean) %>%
                                                                       add_column(., "avg.psi_ud_final" = c(.x[c(1, 4), "avg_PSI_ud"] %>% unlist %>% mean,
                                                                                                            .x[c(2, 3), "avg_PSI_ud"] %>% unlist %>% mean,
                                                                                                            .x[c(2, 3), "avg_PSI_ud"] %>% unlist %>% mean,
                                                                                                            .x[c(1, 4), "avg_PSI_ud"] %>% unlist %>% mean)) %>%
                                                                       dplyr::mutate("12d" = c(NA, NA, -(.x[4, "12d"] %>% as.numeric), paste(.x[4, "12d"]))))

wide_tibble_of_all_detailed_tables_12d.ud.only_cassette.exon_subset <- list_of_12d.ud_detailed_tibble_subset_by_AS.event.ID_2 %>% rbindlist %>% type_convert

# # we also need -PSI for 12d
# 
# wide_tibble_of_all_detailed_tables_12d.ud.only_cassette.exon_subset_negative.12d <- wide_tibble_of_all_detailed_tables_12d.ud.only_cassette.exon_subset_positive.12d
# wide_tibble_of_all_detailed_tables_12d.ud.only_cassette.exon_subset_negative.12d[, "12d"] <- -(wide_tibble_of_all_detailed_tables_12d.ud.only_cassette.exon_subset_negative.12d$`12d` %>% as.numeric)
# 
# wide_tibble_of_all_detailed_tables_12d.ud.only_cassette.exon_subset <- dplyr::bind_rows(wide_tibble_of_all_detailed_tables_12d.ud.only_cassette.exon_subset_positive.12d, wide_tibble_of_all_detailed_tables_12d.ud.only_cassette.exon_subset_negative.12d)

```

### append cassette exon averages to the detailed table along with all the other average psi's

```{r}

wide_tibble_of_all_detailed_tables_12d.ud.only_4 <- dplyr::full_join(wide_tibble_of_all_detailed_tables_12d.ud.only_3 %>% type_convert, wide_tibble_of_all_detailed_tables_12d.ud.only_cassette.exon_subset)

wide_tibble_of_all_detailed_tables_12d.ud.only_4 <- wide_tibble_of_all_detailed_tables_12d.ud.only_4[-which(is.na(wide_tibble_of_all_detailed_tables_12d.ud.only_4$logCPM_1)), ]

wide_tibble_of_all_detailed_tables_12d.ud.only_4[wide_tibble_of_all_detailed_tables_12d.ud.only_4$splicemode != "cassette_exon_events", "avg.psi_ud_final"] <- wide_tibble_of_all_detailed_tables_12d.ud.only_4[wide_tibble_of_all_detailed_tables_12d.ud.only_4$splicemode != "cassette_exon_events", "avg_PSI_ud"]

wide_tibble_absolute.ud.PSI <- wide_tibble_of_all_detailed_tables_12d.ud.only_4[, c("AS_event_ID", "splicemode", "12d", "avg.psi_ud_final")]

```

### filtering join of the detailed tables by the timeseries PSI data

```{r}

# append the absolute PSI at timepoint ud
wide_tibble_of_absolute.ud.PSI_matched_to_PSI_table <- dplyr::left_join(PSI_levels_timeseries_OB_wide_with_na %>% type_convert, wide_tibble_absolute.ud.PSI %>% type_convert, by = c("AS_event_ID", "splicemode", "12d")) %>% as_tibble

tibble_absolute_PSI_levels_timeseries <- wide_tibble_of_absolute.ud.PSI_matched_to_PSI_table

# add back the absolute PSI at ud timepoint
tibble_absolute_PSI_levels_timeseries[, vector_OBseries_timepoints_edited] <- tibble_absolute_PSI_levels_timeseries[, vector_OBseries_timepoints_edited] + tibble_absolute_PSI_levels_timeseries$avg.psi_ud_final

# remove the absolute PSI column
tibble_absolute_PSI_levels_timeseries <- tibble_absolute_PSI_levels_timeseries %>% dplyr::select(., -"avg.psi_ud_final")

# reorder the columns to be in chronological order
tibble_absolute_PSI_levels_timeseries <- tibble_absolute_PSI_levels_timeseries[, c("Gene", "AS_event_ID", "splicemode", "isoform_number", vector_OBseries_timepoints_edited)] %>% dplyr::mutate_if(is.factor, as.character)

```

### analysis of junction switching

#### create subset list for every AS_event_ID (every unique junction)

```{r}

list_unique_AS.event.IDs_absolute_PSI_levels_timeseries <- tibble_absolute_PSI_levels_timeseries[, c("AS_event_ID", "splicemode")] %>% unique %>% array_tree

list_of_tibbles_absolute_PSI_levels_timeseries <- purrr::map(.x = list_unique_AS.event.IDs_absolute_PSI_levels_timeseries, .f = ~tibble_absolute_PSI_levels_timeseries[tibble_absolute_PSI_levels_timeseries$AS_event_ID == (.x[[1]] %>% paste) & tibble_absolute_PSI_levels_timeseries$splicemode == (.x[[2]] %>% paste), ])

```

#### calculate the ranks for every AS_event_ID with more than one junction recorded

```{r}

# calculate ranks
list_of_tibbles_absolute_PSI_levels_ranks.per.timepoint <- purrr::map_if(.x = list_of_tibbles_absolute_PSI_levels_timeseries, .p = ~nrow(.x) > 1, .f = ~apply(X = .x[, vector_OBseries_timepoints_edited], MARGIN = 2, FUN = function(X){rank(X %>% as.numeric)}))

remove_consecutive_duplicates_from_data.frame <- function(df) {
  
  # turn dataframe into list
  a <- df %>% array_tree
  # test if each term starting from 2nd element is identical to previous
  b <- purrr::map2(.x = a[1:(length(a) - 1)], .y = a[2:(length(a))], .f = ~identical(.x, .y))
  # get the elements (minus 1) which are not identical to previous
  c <- which(b == FALSE)
  # return filtered list
  d <- a[c(1, c + 1)]
  # re-make into dataframe
  e <- d %>% rbindlist %>% as.data.frame
  row.names(e) <- names(d)
  
  # return filtered dataframe
  return(e %>% t)
  
}

# unique consecutive ranks only
list_of_tibbles_absolute_PSI_levels_ranks.per.timepoint_unique <- purrr::map_if(.x = list_of_tibbles_absolute_PSI_levels_ranks.per.timepoint, .p = ~nrow(.x) > 1, .f = ~.x %>% t %>% remove_consecutive_duplicates_from_data.frame)

```

#### which elements have more than one column?

```{r}

list_of_logical_junction_switched_or_not <- purrr::map_if(.x = list_of_tibbles_absolute_PSI_levels_ranks.per.timepoint_unique, .p = ~nrow(.x) > 1, .f = ~ncol(.x) > 1)

```

#### for those junctions with only one entry, is PSI going back and forth between 0.5?

```{r}

list_of_logical_junction_switched_or_not <- purrr::map_if(.x = list_of_logical_junction_switched_or_not, .p = ~is.logical(.x) == FALSE, 
                                                          .f = ~any(.x[, vector_OBseries_timepoints_edited] > 0.5) & any(.x[, vector_OBseries_timepoints_edited] < 0.5))

```

#### filter the absolute PSI table for junctions switched over the time course

```{r}

list_of_tibbles_absolute_PSI_levels_timeseries_junction.switched <- list_of_tibbles_absolute_PSI_levels_timeseries[which(list_of_logical_junction_switched_or_not %>% unlist == TRUE)]

tibble_absolute_PSI_levels_timeseries_junction.switched <- list_of_tibbles_absolute_PSI_levels_timeseries_junction.switched %>% rbindlist %>% as_tibble

# by definition, junctions that go from NA to not NA are switched
write.table(x = tibble_absolute_PSI_levels_timeseries_junction.switched, file = paste(R_processing_results_dir, "wide_table_of_",  nrow(tibble_absolute_PSI_levels_timeseries_junction.switched), "_switched.junctions_PSI_OB_diff_any_", p_or_q_value, qpvalue_cutoff, "_any_deltaPSI_greaterthan_", dPSI_cutoff, ".txt", sep = ""), sep = "\t", row.names = FALSE, quote = FALSE)

```

## Use the NA values in junction switching to determine average expression of NA

we can use this info to determine if values are missing at random or left-censored.

### fetch row indices which have at least one NA

```{r}

# get row indices of the final junction switching table while have at least one NA

row.indices_junc.switch.table_any.na <- tibble_absolute_PSI_levels_timeseries_junction.switched[, vector_OBseries_timepoints_edited] %>% apply(MARGIN = 1, FUN = function(X) {
  
  return(any(is.na(X)) == TRUE)
  
} )

row.indices_junc.switch.table_any.na <- which(row.indices_junc.switch.table_any.na == TRUE)

```

### extract AS_event_ID of na, join onto the wide tibble of detailed tables

```{r}

tibble_AS_event_ID_which_have_na <- tibble_absolute_PSI_levels_timeseries_junction.switched[row.indices_junc.switch.table_any.na, ] %>% .$AS_event_ID %>% unique %>% tibble::enframe(value = "AS_event_ID")

# join to get all the values with na
wide_tibble_of_all_detailed_tables_with_na <- dplyr::semi_join(wide_tibble_of_all_detailed_tables, tibble_AS_event_ID_which_have_na, by = "AS_event_ID") %>% type_convert

# join to get all the values with no na
wide_tibble_of_all_detailed_tables_with_no_na <- dplyr::anti_join(wide_tibble_of_all_detailed_tables, tibble_AS_event_ID_which_have_na, by = "AS_event_ID") %>% type_convert

```

### plot distributions

```{r}

plot(density(bw = 0.01, c(wide_tibble_of_all_detailed_tables_with_na$logCPM_1 %>% na.omit, wide_tibble_of_all_detailed_tables_with_na[wide_tibble_of_all_detailed_tables_with_na$comparison == "BM_MSC_to_OB_12d_vs_BM_MSC_to_OB_ud", ] %>% .$logCPM_2 %>% na.omit)), main = "junction logCPM counts for junction structures with missing values")

plot(density(bw = 0.01, c(wide_tibble_of_all_detailed_tables_with_no_na$logCPM_1 %>% na.omit, wide_tibble_of_all_detailed_tables_with_no_na[wide_tibble_of_all_detailed_tables_with_no_na$comparison == "BM_MSC_to_OB_12d_vs_BM_MSC_to_OB_ud", ] %>% .$logCPM_2 %>% na.omit)), main = "junction logCPM counts for junction structures with no missing values")

plot(density(bw = 0.01, c(wide_tibble_of_all_detailed_tables %>% type_convert %>% .$logCPM_1 %>% na.omit, wide_tibble_of_all_detailed_tables[wide_tibble_of_all_detailed_tables$comparison == "BM_MSC_to_OB_12d_vs_BM_MSC_to_OB_ud", ] %>% type_convert %>% .$logCPM_2 %>% na.omit)), main = "junction logCPM counts for all junction structures")

```

## checking the junction counts and LRT statistics

### import the detailed tables into the environment

```{r message=FALSE, warning=FALSE}

wide_table_of_all_detailed_tables <- list_of_detailed_tables_3 %>% rbindlist %>% as_tibble

wide_table_of_all_detailed_tables_maxCPM <- wide_table_of_all_detailed_tables %>% dplyr::group_by(Gene) %>% dplyr::summarise(., maxCPM = max(logCPM_1 %>% na.omit, logCPM_2 %>% na.omit))

wide_table_of_all_detailed_tables_maxtranscriptlength <- getBM(filters = "external_gene_name", values = wide_table_of_all_detailed_tables_maxCPM$Gene, attributes = c("external_gene_name", "transcript_length"), mart = ensembl_mart) %>% group_by(external_gene_name) %>% na.omit %>% filter(transcript_length == max(transcript_length	)) %>% 
  setNames(c("Gene", "maxtranscriptlength"))

wide_table_of_all_detailed_tables_maxCPM_maxtranscriptlength <- dplyr::full_join(wide_table_of_all_detailed_tables_maxCPM, 
                                                                                 wide_table_of_all_detailed_tables_maxtranscriptlength, 
                                                                                 by = "Gene")

```

### graph the no. of junctions detected vs. max. junction counts logCPM OR maximum transcript length

```{r}

junctions_per_gene_constitutive_all_freq <- PSI_levels_timeseries_constitutive_OB_wide_with_na %>% dplyr::distinct(., AS_event_ID, .keep_all = TRUE) %>% group_by(Gene) %>% summarise(no_junctions = n())

junctions_per_gene_all_freq <- PSI_levels_timeseries_OB_wide_with_na %>% dplyr::distinct(., AS_event_ID, .keep_all = TRUE) %>% group_by(Gene) %>% summarise(no_junctions = n())

wide_table_numberof_junctions_per_gene_maxCPM_maxtranscriptlength <- dplyr::full_join(wide_table_of_all_detailed_tables_maxCPM_maxtranscriptlength, junctions_per_gene_constitutive_all_freq, by = "Gene") %>% 
  dplyr::full_join(., junctions_per_gene_all_freq, by = "Gene") %>% setNames(., c("Gene", "maxCPM", "maxtranscriptlength", "no_junctions_constitutive", "no_junctions_allsig"))

long_table_numberof_junctions_per_gene_maxCPM_maxtranscriptlength <- reshape2::melt(wide_table_numberof_junctions_per_gene_maxCPM_maxtranscriptlength, 
                                                                                    id = c("Gene", "maxCPM", "maxtranscriptlength"), variable.name = "filteringstep",
                                                                                    value.name = "no_junctions") %>% as_tibble %>% type_convert

# no junctions vs. max junction counts in logCPM

ggplot(long_table_numberof_junctions_per_gene_maxCPM_maxtranscriptlength %>% na.omit %>% type_convert) + 
  geom_point(aes(y = no_junctions, x = maxCPM)) +
  geom_smooth(method = "lm", formula = y~x, colour = "red", aes(y = no_junctions, x = maxCPM)) +
  facet_wrap(~filteringstep, scales = "free") +
  ggtitle(paste("scatterplot of the number of junctions detected per gene against max. junction counts 
              ", p_or_q_value, qpvalue_cutoff, "_deltaPSI_greaterthan_", dPSI_cutoff, sep = "")) +
  xlab("maximum junction count for a gene (logCPM)") +
  ylab("number of (differential) junctions detected") +
  theme_bw() +
  theme(axis.text.x = element_text(hjust = 1, colour = "black"), text = element_text(family = "Helvetica")) +
  ggsave(filename = paste(qualitycheck_results_dir, "scatterplot_no_junctions_vs_max_junctioncounts_", p_or_q_value, qpvalue_cutoff, "_deltaPSI_greaterthan_", dPSI_cutoff, ".pdf", sep = ""), device = "pdf", dpi = 600, width = 14, height = 8, units = "cm") +
  ggsave(filename = paste(qualitycheck_results_dir, "scatterplot_no_junctions_vs_max_junctioncounts_", p_or_q_value, qpvalue_cutoff, "_deltaPSI_greaterthan_", dPSI_cutoff, ".svg", sep = ""), device = "svg", dpi = 600, width = 14, height = 8, units = "cm") 


# no. junctions detected vs. maximum annotated transcript length

ggplot(long_table_numberof_junctions_per_gene_maxCPM_maxtranscriptlength %>% na.omit %>% type_convert) + 
  geom_point(aes(y = no_junctions, x = maxtranscriptlength)) +
  # geom_dotplot(aes(x = no_junctions, y = maxtranscriptlength), binaxis = "x", bins = 2) +
  # coord_flip() +
  # geom_smooth(method = "lm", formula = y~x, colour = "red", aes(y = no_junctions, x = maxtranscriptlength)) +
  facet_wrap(~filteringstep, scales = "free") +
  ggtitle(paste("scatterplot of the number of unique junction structures detected per gene against max. annotated transcipt length 
              ", p_or_q_value, qpvalue_cutoff, "_deltaPSI_greaterthan_", dPSI_cutoff, sep = "")) +
  xlab("maximum annotated transcript length") +
  ylab("number of (differential) junctions detected") +
  theme_bw() +
  theme(axis.text.x = element_text(hjust = 1, colour = "black"), text = element_text(family = "Helvetica")) +
  ggsave(filename = paste(qualitycheck_results_dir, "scatterplot_no_junctions_vs_max_transcriptlength_", p_or_q_value, qpvalue_cutoff, "_deltaPSI_greaterthan_", dPSI_cutoff, ".pdf", sep = ""), device = "pdf", dpi = 600, width = 14, height = 8, units = "cm") +
  ggsave(filename = paste(qualitycheck_results_dir, "scatterplot_no_junctions_vs_max_transcriptlength_", p_or_q_value, qpvalue_cutoff, "_deltaPSI_greaterthan_", dPSI_cutoff, ".svg", sep = ""), device = "svg", dpi = 600, width = 14, height = 8, units = "cm") 

```

## PCA analysis of junction counts per sample (replicate)

read the combined counts in the environment
```{r}

library(Amelia)

list_combined_count_filenames <- list.files(path = paste(JUM_diff_dir, sep = "")) %>% .[grep(x = ., pattern = "(.*)__combined_count.txt")] %>% array_tree
vector_combined_count_filenames <- list_combined_count_filenames %>% unlist
list_of_timepoint_names <- vector_combined_count_filenames %>% gsub(x = ., pattern = "(.*)__combined_count.txt", replacement = "\\1") %>% array_tree
# list_of_assigned_table_names <- vector_combined_count_filenames %>% gsub(x = ., pattern = "(.*)__combined_count.txt", replacement = "\\1_combined_count_table") %>% array_tree


length(list_combined_count_filenames)
length(list_of_timepoint_names)

list_of_combined_count_files <- purrr::map2(.x = list_combined_count_filenames, .y = list_of_timepoint_names, .f = ~read.delim(file = paste(JUM_diff_dir, .x, sep = ""), sep = "\t", header = FALSE, na.strings = c("NONE", "NA", "INF", "Inf")) %>% setNames(c("sub_junction_id", paste(.y, "_count", sep = ""))) %>% as_tibble %>% mutate_if(is.factor, as.character))

wide_table_of_all_combined_count_files <- purrr::reduce(list_of_combined_count_files, dplyr::full_join)

# CHECK FOR MISSING VALUES IN THE COMBINED COUNT TABLE. THERE SHOULD BE NONE.

missmap(wide_table_of_all_combined_count_files, pdfstub = paste(qualitycheck_results_dir, "heatmap_missingness_combinedcount_tables.pdf", sep = ""))

# PCA analysis

PCA_combined_count <- prcomp(wide_table_of_all_combined_count_files[, 2:ncol(wide_table_of_all_combined_count_files)])

# plot standard deviations 

PCA_stdev <- tibble(PC = 1:(PCA_combined_count[["sdev"]] %>% length), stdev = PCA_combined_count[["sdev"]])
PCA_variance <- tibble(PC = PCA_stdev$PC, variance = PCA_stdev$stdev ^ 2)
PCA_variance <- add_column(PCA_variance, variance_explained = PCA_variance$variance/sum(PCA_variance$variance) * 100)

ggplot(PCA_variance) + 
  geom_col(aes(y = variance_explained, x = PC, fill = PC)) +
  scale_fill_gradientn(colours = heat.colors(n = (PCA_combined_count[["sdev"]] %>% length))) +
  ggtitle(paste("PCA variance distribution amongst PCs based on JUM combined count", sep = "")) +
  xlab("PC") +
  ylab("Variance explained (%)") +
  theme_bw() +
  theme(text = element_text(family = "Helvetica")) +
  ggsave(filename = paste(qualitycheck_results_dir, "barplot_PCA_stdevs_based_on_JUM_combined_count.pdf", sep = ""), device = "pdf", dpi = 600, width = 45, height = 25, units = "cm") +
  ggsave(filename = paste(qualitycheck_results_dir, "barplot_PCA_stdevs_based_on_JUM_combined_count.svg", sep = ""), device = "svg", dpi = 600, width = 45, height = 25, units = "cm")

# plot loadings

PCA_loadings <- PCA_combined_count[["rotation"]] %>% as_tibble(rownames = "sample")
PCA_loadings <- add_column(PCA_loadings, timepoint = gsub(x = PCA_loadings$sample, pattern = "(BM_MSC_to_)(.*)_([0-9]{0,2})(d|h|ud)_(r[1-3])(.*)", replacement = "\\3\\4"))
PCA_loadings <- add_column(PCA_loadings, replicatenumber = gsub(x = PCA_loadings$sample, pattern = "(BM_MSC_to_)(.*)_([0-9]{0,2})(d|h|ud)_(r[1-3])(.*)", replacement = "\\5"))

ggplot(PCA_loadings) + 
  geom_point(aes(y = PC2, x = PC1, shape = replicatenumber, color = timepoint, size = 2)) +
  scale_color_brewer(palette = "Spectral") +
  ggtitle(paste("PCA standard deviations based on JUM combined count", sep = "")) +
  xlab(paste("PC1 (", PCA_variance[1, "variance_explained"] %>% signif(3), "%)", sep = "")) +
  ylab(paste("PC2 (", PCA_variance[2, "variance_explained"] %>% signif(3), "%)", sep = "")) +
  theme_bw() +
  theme(text = element_text(family = "Helvetica")) +
  ggsave(filename = paste(qualitycheck_results_dir, "PCA_plot_PC2_vs_PC1_based_on_JUM_combined_count.pdf", sep = ""), device = "pdf", dpi = 600, width = 25, height = 20, units = "cm") +
  ggsave(filename = paste(qualitycheck_results_dir, "PCA_plot_PC2_vs_PC1_based_on_JUM_combined_count.svg", sep = ""), device = "svg", dpi = 600, width = 25, height = 20, units = "cm")

ggplot(PCA_loadings) + 
  geom_point(aes(y = PC3, x = PC2, shape = replicatenumber, color = timepoint, size = 2)) +
  scale_color_brewer(palette = "Spectral") +
  ggtitle(paste("PCA standard deviations based on JUM combined count", sep = "")) +
  xlab(paste("PC2 (", PCA_variance[2, "variance_explained"] %>% signif(3), "%)", sep = "")) +
  ylab(paste("PC3 (", PCA_variance[3, "variance_explained"] %>% signif(3), "%)", sep = "")) +
  theme_bw() +
  theme(text = element_text(family = "Helvetica")) +
  ggsave(filename = paste(qualitycheck_results_dir, "PCA_plot_PC3_vs_PC2_based_on_JUM_combined_count.pdf", sep = ""), device = "pdf", dpi = 600, width = 25, height = 20, units = "cm") +
  ggsave(filename = paste(qualitycheck_results_dir, "PCA_plot_PC3_vs_PC2_based_on_JUM_combined_count.svg", sep = ""), device = "svg", dpi = 600, width = 25, height = 20, units = "cm")

# I wonder if filtering for low junction counts improves the clustering

### FILTERING FOR JUNCTIONS WITH AT LEAST 5 REOBS IN ALL 3 REPLICATES OF EACH TIMEPOINT

# generate column partitioning indices (subset every 3 columns for each timepoint made up of 3 replicates)
a <- seq(from = 2, to = wide_table_of_all_combined_count_files %>% ncol, by = 3)
b <- seq(from = 4, to = wide_table_of_all_combined_count_files %>% ncol, by = 3)
c <- purrr::map2(a, b, ~.x:.y)

# generate logical tests for each partition each row. does each timepoint have at least 5 junction reads in all replicates?
d <- apply(wide_table_of_all_combined_count_files, MARGIN = 1, FUN = function(X) {purrr::map(c, ~all(X[.x] %>% as.numeric >= 5))})

# logical table to show the junction coordinates which have at least one timepoint which has a sufficient number of mapped read counts.
e <- purrr::map(d, ~any(.x == TRUE))

# filter for juunctions backed by sufficient read counts only
wide_table_of_all_combined_count_files_more_than_5_read_in_at_least_3_samples <- wide_table_of_all_combined_count_files[which(e == TRUE), ]

# repeat the PCA plots
# PCA analysis

PCA_combined_count_filtered <- prcomp(wide_table_of_all_combined_count_files_more_than_5_read_in_at_least_3_samples[, 2:ncol(wide_table_of_all_combined_count_files_more_than_5_read_in_at_least_3_samples)])

# plot standard deviations 

PCA_stdev_filtered <- tibble(PC = 1:(PCA_combined_count_filtered[["sdev"]] %>% length), stdev = PCA_combined_count_filtered[["sdev"]])
PCA_variance_filtered <- tibble(PC = PCA_stdev_filtered$PC, variance = PCA_stdev_filtered$stdev ^ 2)
PCA_variance_filtered <- add_column(PCA_variance_filtered, variance_explained = PCA_variance_filtered$variance/sum(PCA_variance_filtered$variance) * 100)

ggplot(PCA_variance_filtered) + 
  geom_col(aes(y = variance_explained, x = PC, fill = PC)) +
  scale_fill_gradientn(colours = heat.colors(n = (PCA_combined_count_filtered[["sdev"]] %>% length))) +
  ggtitle(paste("PCA variance distribution amongst PCs based on JUM combined count filtered (> 5 in all replicates each timepoint)", sep = "")) +
  xlab("PC") +
  ylab("Variance explained (%)") +
  theme_bw() +
  theme(text = element_text(family = "Helvetica")) +
  ggsave(filename = paste(qualitycheck_results_dir, "barplot_PCA_stdevs_based_on_JUM_combined_count_filtered.pdf", sep = ""), device = "pdf", dpi = 600, width = 45, height = 25, units = "cm") +
  ggsave(filename = paste(qualitycheck_results_dir, "barplot_PCA_stdevs_based_on_JUM_combined_count_filtered.svg", sep = ""), device = "svg", dpi = 600, width = 45, height = 25, units = "cm")

# plot loadings

PCA_loadings_filtered <- PCA_combined_count_filtered[["rotation"]] %>% as_tibble(rownames = "sample")
PCA_loadings_filtered <- add_column(PCA_loadings_filtered, timepoint = gsub(x = PCA_loadings_filtered$sample, pattern = "(BM_MSC_to_)(.*)_([0-9]{0,2})(d|h|ud)_(r[1-3])(.*)", replacement = "\\3\\4"))
PCA_loadings_filtered <- add_column(PCA_loadings_filtered, replicatenumber = gsub(x = PCA_loadings_filtered$sample, pattern = "(BM_MSC_to_)(.*)_([0-9]{0,2})(d|h|ud)_(r[1-3])(.*)", replacement = "\\5"))

ggplot(PCA_loadings_filtered) + 
  geom_point(aes(y = PC2, x = PC1, shape = replicatenumber, color = timepoint, size = 2)) +
  scale_color_brewer(palette = "Spectral") +
  ggtitle(paste("PCA standard deviations based on JUM combined count filtered (> 5 in all replicates each timepoint)", sep = "")) +
  xlab(paste("PC1 (", PCA_variance_filtered[1, "variance_explained"] %>% signif(3), "%)", sep = "")) +
  ylab(paste("PC2 (", PCA_variance_filtered[2, "variance_explained"] %>% signif(3), "%)", sep = "")) +
  theme_bw() +
  theme(text = element_text(family = "Helvetica")) +
  ggsave(filename = paste(qualitycheck_results_dir, "PCA_plot_PC2_vs_PC1_based_on_JUM_combined_count_filtered.pdf", sep = ""), device = "pdf", dpi = 600, width = 25, height = 20, units = "cm") +
  ggsave(filename = paste(qualitycheck_results_dir, "PCA_plot_PC2_vs_PC1_based_on_JUM_combined_count_filtered.svg", sep = ""), device = "svg", dpi = 600, width = 25, height = 20, units = "cm")

ggplot(PCA_loadings_filtered) + 
  geom_point(aes(y = PC3, x = PC2, shape = replicatenumber, color = timepoint, size = 2)) +
  scale_color_brewer(palette = "Spectral") +
  ggtitle(paste("PCA standard deviations based on JUM combined count filtered (> 5 in all replicates each timepoint)", sep = "")) +
  xlab(paste("PC2 (", PCA_variance_filtered[2, "variance_explained"] %>% signif(3), "%)", sep = "")) +
  ylab(paste("PC3 (", PCA_variance_filtered[3, "variance_explained"] %>% signif(3), "%)", sep = "")) +
  theme_bw() +
  theme(text = element_text(family = "Helvetica")) +
  ggsave(filename = paste(qualitycheck_results_dir, "PCA_plot_PC3_vs_PC2_based_on_JUM_combined_count_filtered.pdf", sep = ""), device = "pdf", dpi = 600, width = 25, height = 20, units = "cm") +
  ggsave(filename = paste(qualitycheck_results_dir, "PCA_plot_PC3_vs_PC2_based_on_JUM_combined_count_filtered.svg", sep = ""), device = "svg", dpi = 600, width = 25, height = 20, units = "cm")

```


## RUV: removal of unwanted variation in the junction count data

### define packages, paths and functions

```{r}

library(RUVnormalize)

# function to transform a numerical array/matrix/tibble into an RLE plot, assuming genes are given on the y-axis and samples/replicates/timepoints are given on the x axis.

transformRLE <- function(input_array) {
  
  input_array <- log10(input_array)
  
  vec_gene_medians <- apply(X = input_array, MARGIN = 1, FUN = function(X) {median(X)})
  
  RLE_array <- apply(X = input_array, MARGIN = 2, FUN = function(X) {X - vec_gene_medians})
  
  return(RLE_array)
  
}

```


### before normalisation

```{r}

wide_table_of_all_combined_count_files_RLE <- wide_table_of_all_combined_count_files

wide_table_of_all_combined_count_files_RLE[, 2:ncol(wide_table_of_all_combined_count_files_RLE)] <- transformRLE(wide_table_of_all_combined_count_files_RLE[, 2:ncol(wide_table_of_all_combined_count_files_RLE)])

long_table_of_all_combined_count_files_RLE <- reshape2::melt(wide_table_of_all_combined_count_files_RLE, value.name = "junction_counts", id = "sub_junction_id", variable.name = "samplename")

ggplot(long_table_of_all_combined_count_files_RLE) +
  geom_boxplot(aes(x = samplename, y = junction_counts)) +
  # ylim(1, 100000) +
  theme_bw() +
  xlab("replicate name")+
  ylab("relative log10 junction counts (RLE)") +
  ggtitle("RLE plot of raw junction counts") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, colour = "black"), legend.title.align = 0.5, text = element_text(family ="Helvetica")) +
  ggsave(filename = paste(qualitycheck_results_dir, "RLE_boxplot_junctioncounts_raw.pdf", sep = ""), device = "pdf", dpi = 600, width = 45, height = 25, units = "cm") +
  ggsave(filename = paste(qualitycheck_results_dir, "RLE_boxplot_junctioncounts_raw.svg", sep = ""), device = "svg", dpi = 600, width = 45, height = 25, units = "cm")

```

### RUV

Sort genes by their standard deviation

```{r warning=FALSE}

# Sort genes by their standard deviation

wide_table_of_all_combined_count_files <- wide_table_of_all_combined_count_files %>% type_convert

# sd <- apply(wide_table_of_all_combined_count_files[, 2:ncolwide_table_of_all_combined_count_files], 1, FUN = function(X) {sd(X)})

# ssd <- wide_table_of_all_combined_count_files[order(sd, decreasing = TRUE), ]

# som_cluster the samples

# kmres <- kmeans(ssd[, 2:ncol(ssd)], centers = vector_OBseries_timepoints_edited %>% length, nstart = 200)

# vclust <- kmres$som_cluster

# Compute the distance between clustering by replicate and clustering obtained by k-means

# uScore <- clScore(ssd[, 2:4], ssd[, 5:7])

```

centering genes by replicate

```{r eval=FALSE, include=FALSE}

ssd_centred <- apply(ssd[, 2:ncol(ssd)], 2, FUN = function(X) {scale(X)}) %>% as_tibble
ssd_centred <- bind_cols(tibble(sub_junction_id = ssd$sub_junction_id), ssd_centred)

ssd_centred_RLE <- ssd_centred
ssd_centred_RLE[, 2:ncol(ssd_centred_RLE)] <- transformRLE(ssd_centred_RLE[, 2:ncol(ssd_centred_RLE)])
tibble_ssd_centred_RLE_long <- reshape2::melt(ssd_centred_RLE, value.name = "junction_counts", id = "sub_junction_id", variable.name = "samplename")

ggplot(tibble_ssd_centred_RLE_long) +
  geom_boxplot(aes(x = samplename, y = junction_counts)) +
  # ylim(1, 100000) +
  xlab("replicate name")+
  ylab("relative log10 junction counts (RLE)") +
  ggtitle("RLE plot of centred junction counts") +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, colour = "black"), legend.title.align = 0.5, text = element_text(family = "Helvetica")) +
  ggsave(filename = paste(qualitycheck_results_dir, "RLE_boxplot_junctioncounts_centred.pdf", sep = ""), device = "pdf", dpi = 600, width = 45, height = 25, units = "cm") +
  ggsave(filename = paste(qualitycheck_results_dir, "RLE_boxplot_junctioncounts_centred.svg", sep = ""), device = "svg", dpi = 600, width = 45, height = 25, units = "cm")

```

Naive RUV-2 no shrinkage

```{r}

replicate_rownumbers <- tribble(~rep1, ~rep2, ~rep3,
                                1,     2,     3,
                                4,     5,     6,
                                7,     8,     9,
                                10,    11,    12,
                                13,    14,    15,
                                16,    17,    18,
                                19,    20,    21,
                                22,    23,    24) %>% as.matrix

nsY <- naiveReplicateRUV(t(wide_table_of_all_combined_count_files[, 2:ncol(wide_table_of_all_combined_count_files)]), scIdx = replicate_rownumbers, k = 5)

tibble_RUV_wide <- bind_cols(wide_table_of_all_combined_count_files[, "sub_junction_id"], t(nsY$cY) %>% as_tibble)

tibble_RUV_wide_RLE <- tibble_RUV_wide
tibble_RUV_wide_RLE[, 2:ncol(tibble_RUV_wide_RLE)] <- transformRLE(tibble_RUV_wide_RLE[, 2:ncol(tibble_RUV_wide_RLE)])
tibble_RUV_RLE_long <- reshape2::melt(tibble_RUV_wide_RLE, value.name = "junction_counts", id = "sub_junction_id", variable.name = "samplename")

ggplot(tibble_RUV_RLE_long) +
  geom_boxplot(aes(x = samplename, y = junction_counts)) +
  # ylim(1, 100000) +
  xlab("replicate name")+
  ylab("relative log10 junction counts (RLE)") +
  ggtitle("RLE plot of RUV junction counts") +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, colour = "black"), legend.title.align = 0.5, text = element_text(family = "Helvetica")) +
  ggsave(filename = paste(qualitycheck_results_dir, "RLE_boxplot_junctioncounts_RUV.pdf", sep = ""), device = "pdf", dpi = 600, width = 45, height = 25, units = "cm") +
  ggsave(filename = paste(qualitycheck_results_dir, "RLE_boxplot_junctioncounts_RUV.svg", sep = ""), device = "svg", dpi = 600, width = 45, height = 25, units = "cm")

```

plot PCA

```{r}

# repeat the PCA plots
# PCA analysis

PCA_combined_count_filtered <- prcomp(tibble_RUV_wide[, 2:ncol(tibble_RUV_wide)])

# plot standard deviations 

PCA_stdev_filtered <- tibble(PC = 1:(PCA_combined_count_filtered[["sdev"]] %>% length), stdev = PCA_combined_count_filtered[["sdev"]])
PCA_variance_filtered <- tibble(PC = PCA_stdev_filtered$PC, variance = PCA_stdev_filtered$stdev ^ 2)
PCA_variance_filtered <- add_column(PCA_variance_filtered, variance_explained = PCA_variance_filtered$variance/sum(PCA_variance_filtered$variance) * 100)

ggplot(PCA_variance_filtered) + 
  geom_col(aes(y = variance_explained, x = PC, fill = PC)) +
  scale_fill_gradientn(colours = heat.colors(n = (PCA_combined_count_filtered[["sdev"]] %>% length))) +
  ggtitle(paste("PCA variance distribution amongst PCs based on JUM combined count RUV (> 5 in all replicates each timepoint)", sep = "")) +
  xlab("PC") +
  ylab("Variance explained (%)") +
  theme_bw() +
  theme(text = element_text(family = "Helvetica")) +
  ggsave(filename = paste(qualitycheck_results_dir, "barplot_PCA_stdevs_based_on_JUM_combined_count_RUV.pdf", sep = ""), device = "pdf", dpi = 600, width = 45, height = 25, units = "cm") +
  ggsave(filename = paste(qualitycheck_results_dir, "barplot_PCA_stdevs_based_on_JUM_combined_count_RUV.svg", sep = ""), device = "svg", dpi = 600, width = 45, height = 25, units = "cm")

# plot loadings

PCA_loadings_filtered <- PCA_combined_count_filtered[["rotation"]] %>% as_tibble(rownames = "sample")
PCA_loadings_filtered <- add_column(PCA_loadings_filtered, timepoint = gsub(x = PCA_loadings_filtered$sample, pattern = "(BM_MSC_to_)(.*)_([0-9]{0,2})(d|h|ud)_(r[1-3])(.*)", replacement = "\\3\\4"))
PCA_loadings_filtered <- add_column(PCA_loadings_filtered, replicatenumber = gsub(x = PCA_loadings_filtered$sample, pattern = "(BM_MSC_to_)(.*)_([0-9]{0,2})(d|h|ud)_(r[1-3])(.*)", replacement = "\\5"))

ggplot(PCA_loadings_filtered) + 
  geom_point(aes(y = PC2, x = PC1, shape = replicatenumber, color = timepoint, size = 2)) +
  scale_color_brewer(palette = "Spectral") +
  ggtitle(paste("PCA standard deviations based on JUM combined count RUV (> 5 in all replicates each timepoint)", sep = "")) +
  xlab(paste("PC1 (", PCA_variance_filtered[1, "variance_explained"] %>% signif(3), "%)", sep = "")) +
  ylab(paste("PC2 (", PCA_variance_filtered[2, "variance_explained"] %>% signif(3), "%)", sep = "")) +
  theme_bw() +
  theme(text = element_text(family = "Helvetica")) +
  ggsave(filename = paste(qualitycheck_results_dir, "PCA_plot_PC2_vs_PC1_based_on_JUM_combined_count_RUV.pdf", sep = ""), device = "pdf", dpi = 600, width = 45, height = 25, units = "cm") +
  ggsave(filename = paste(qualitycheck_results_dir, "PCA_plot_PC2_vs_PC1_based_on_JUM_combined_count_RUV.svg", sep = ""), device = "svg", dpi = 600, width = 45, height = 25, units = "cm")

ggplot(PCA_loadings_filtered) + 
  geom_point(aes(y = PC3, x = PC2, shape = replicatenumber, color = timepoint, size = 2)) +
  scale_color_brewer(palette = "Spectral") +
  ggtitle(paste("PCA standard deviations based on JUM combined count RUV (> 5 in all replicates each timepoint)", sep = "")) +
  xlab(paste("PC2 (", PCA_variance_filtered[2, "variance_explained"] %>% signif(3), "%)", sep = "")) +
  ylab(paste("PC3 (", PCA_variance_filtered[3, "variance_explained"] %>% signif(3), "%)", sep = "")) +
  theme_bw() +
  theme(text = element_text(family = "Helvetica")) +
  ggsave(filename = paste(qualitycheck_results_dir, "PCA_plot_PC3_vs_PC2_based_on_JUM_combined_count_RUV.pdf", sep = ""), device = "pdf", dpi = 600, width = 45, height = 25, units = "cm") +
  ggsave(filename = paste(qualitycheck_results_dir, "PCA_plot_PC3_vs_PC2_based_on_JUM_combined_count_RUV.svg", sep = ""), device = "svg", dpi = 600, width = 45, height = 25, units = "cm")

```

### export the normalised combined junction count tables

```{r}

RUV_combined_junction_counts <-  paste(qualitycheck_results_dir, "RUV_combined_junction_counts/", sep = "")

if(! dir.exists(RUV_combined_junction_counts) ) {
  dir.create(RUV_combined_junction_counts, recursive = TRUE)}

wide_tibble_junctioncounts_RUV <- tibble_RUV_wide

# move up the values to prevent negative, then x1000 and round to prevent non-integer values and to minimise relative error when we round

wide_tibble_junctioncounts_RUV[, 2:ncol(wide_tibble_junctioncounts_RUV)] <- round((wide_tibble_junctioncounts_RUV[, 2:ncol(wide_tibble_junctioncounts_RUV)] - min(wide_tibble_junctioncounts_RUV[, 2:ncol(wide_tibble_junctioncounts_RUV)])), digits = 0)

for (timepoint in colnames(wide_tibble_junctioncounts_RUV[, 2:ncol(wide_tibble_junctioncounts_RUV)])) {
  
  write.table(x = wide_tibble_junctioncounts_RUV[, c("sub_junction_id", paste(timepoint))], file = paste(RUV_combined_junction_counts, gsub(x = timepoint, pattern = "(.*)_count", replacement = "\\1__combined_count.txt"), sep = ""), sep = "\t", row.names = FALSE, quote = FALSE, col.names = FALSE)
  
}

```

## can we merge the OB series and AD series?? are they comparable??

NOTE: INCOMPLETE. WE NEED TO DO JUM ON ALL THE SAMPLES IN ONE RUN SO IT CAN COMBINE THE JUNCTION COUNTS INTO CONSISTENT IDs

there are missing values so we can use missMDA to impute for PCA

```{r eval=FALSE, include=FALSE}

library(missMDA)

wide_table_of_all_combined_count_files_OBandOBseries <- dplyr::full_join(wide_table_of_all_combined_count_files, wide_table_of_all_combined_count_files, by = "sub_junction_id")

combined_count_files_OBandOBseries_imputePCA <- estim_ncpPCA(wide_table_of_all_combined_count_files_OBandOBseries, method.cv = "Kfold", verbose = FALSE)



```

# COMBINING GENE EXPRESSION DATA WITH THE SPLICEOMIC DATA HERE

## set environment

set directories

```{r}

# the EXACT path of the file, not its containing directory

logCPM_anysig_DEGs_dir <- "Z:/PGNEXUS_kassem_MSC/Kassem_OB/analysis_RSEM/run_2_eRNA/R_processing_results/edgeR_GLM_DEGs_logCPM.txt"

```

define functions

```{r}

## END filteratleast_x_reads_in_anytimepoint

average_counts_from_triplicate <- function(input_matrix, no_annotation_cols) {
  
  input_matrix <- input_matrix %>% as_tibble
  
  a <- seq(from = 1 + no_annotation_cols, to = (input_matrix %>% ncol) - 3 + 1, by = 3)
  b <- seq(from = 3 + no_annotation_cols, to = input_matrix %>% ncol, by = 3)
  c <- purrr::map2(a, b, ~.x:.y)
  
  # generate logical tests for each partition each row. does each timepoint have at least 5 junction reads in all replicates?
  d <- purrr::map(.x = c, .f = ~input_matrix[, .x])
  
  e <- purrr::map(.x = d, .f = ~apply(.x, 1, FUN = mean) %>% as_tibble %>% setNames(gsub(x = colnames(.x), pattern = "(.*)(_r[1-3])", replacement = "\\1_avg") %>% unique))
  
  f <- purrr::reduce(e, bind_cols) %>% as_tibble
  
  output_matrix <- bind_cols(input_matrix[, 1:no_annotation_cols], f)
  
  return(output_matrix)
  
}

## END average_counts_from_triplicate

```

## extract the RBPs, lncRNAs and snRNAs etc... from expression data and combine with PSI data

```{r}

logCPM_anysig_DEGs_import <- read.delim(file = paste(logCPM_anysig_DEGs_dir), sep = "\t", header = TRUE, stringsAsFactors = FALSE, row.names = NULL, na.strings = c("NONE", "NA", "INF", "Inf")) %>% as_tibble

ENSG_to_genesymbol_DEGs <- getBM(filters = "ensembl_gene_id", values = logCPM_anysig_DEGs_import$ensembl_gene_id, attributes = c("ensembl_gene_id", "external_gene_name"), mart = ensembl_mart)

# append official gene symbol to the DEG table and average the counts
logCPM_anysig_DEGs <- dplyr::right_join(ENSG_to_genesymbol_DEGs, logCPM_anysig_DEGs_import, by = "ensembl_gene_id") %>% average_counts_from_triplicate(., 2)

# reorder the columns to make them chronological

logCPM_anysig_DEGs <- logCPM_anysig_DEGs[, c("ensembl_gene_id", "external_gene_name", "logCPM_BM_MSC_to_OB_ud_avg", "logCPM_BM_MSC_to_OB_6h_avg", "logCPM_BM_MSC_to_OB_12h_avg", "logCPM_BM_MSC_to_OB_1d_avg", "logCPM_BM_MSC_to_OB_3d_avg", "logCPM_BM_MSC_to_OB_6d_avg", "logCPM_BM_MSC_to_OB_9d_avg", "logCPM_BM_MSC_to_OB_12d_avg")]

colnames(logCPM_anysig_DEGs) <- c("ensembl_gene_id", "external_gene_name", vector_OBseries_timepoints_edited)

# subset CPM table by biological role

# RBPs
column_RBP_genes <- getBM(filters = c("biotype", "ensembl_gene_id"), values = list("protein_coding", logCPM_anysig_DEGs$ensembl_gene_id), attributes = c("ensembl_gene_id", "name_1006"), mart = ensembl_mart) %>% as_tibble %>% .[.$name_1006 == "RNA binding" | .$name_1006 == "spliceosomal complex", "ensembl_gene_id"]

logCPM_RBP <- dplyr::semi_join(logCPM_anysig_DEGs, column_RBP_genes, by = "ensembl_gene_id") %>%
  add_column(., AS_event_ID = paste("RBP", .$ensembl_gene_id, sep = "_"), splicemode = "RNASeq", sub_LSV_ID = paste("RNASeq", "RBP", .$ensembl_gene_id, sep = "_"), .after = 2)

# lncRNA
column_lncRNA_genes <- getBM(filters = c("biotype", "ensembl_gene_id"), values = list("lncRNA", logCPM_anysig_DEGs$ensembl_gene_id), attributes = "ensembl_gene_id", mart = ensembl_mart) %>% as_tibble

logCPM_lncRNA <- dplyr::semi_join(logCPM_anysig_DEGs, column_lncRNA_genes, by = "ensembl_gene_id") %>%
  add_column(., AS_event_ID = paste("lncRNA", .$ensembl_gene_id, sep = "_"), splicemode = "RNASeq", sub_LSV_ID = paste("RNASeq", "lncRNA", .$ensembl_gene_id, sep = "_"), .after = 2)

# snRNA
column_snRNA_genes <- getBM(filters = c("biotype", "ensembl_gene_id"), values = list("snRNA", logCPM_anysig_DEGs$ensembl_gene_id), attributes = "ensembl_gene_id", mart = ensembl_mart) %>% as_tibble %>% mutate_if(is.logical, as.character)

logCPM_snRNA <- dplyr::semi_join(logCPM_anysig_DEGs, column_snRNA_genes, by = "ensembl_gene_id") %>%
  add_column(., AS_event_ID = paste("snRNA", .$ensembl_gene_id, sep = "_"), splicemode = "RNASeq", sub_LSV_ID = paste("RNASeq", "snRNA", .$ensembl_gene_id, sep = "_"), .after = 2)

# all TF complex 
column_TFcomplex_genes <- getBM(filters = c("biotype", "ensembl_gene_id"), values = list("protein_coding", logCPM_anysig_DEGs$ensembl_gene_id), attributes = c("ensembl_gene_id", "name_1006"), mart = ensembl_mart) %>% as_tibble %>% .[.$name_1006 == "transcription factor complex", "ensembl_gene_id"]

logCPM_TFcomplex <- dplyr::semi_join(logCPM_anysig_DEGs, column_TFcomplex_genes, by = "ensembl_gene_id") %>%
  add_column(., AS_event_ID = paste("TF complex", .$ensembl_gene_id, sep = "_"), splicemode = "RNASeq", sub_LSV_ID = paste("RNASeq", "TF_complex", .$ensembl_gene_id, sep = "_"), .after = 2)

# combine all the individual logCPM tables into one subsetted expression dataset
logCPM_subset <- dplyr::bind_rows(logCPM_RBP, logCPM_lncRNA, logCPM_snRNA, logCPM_TFcomplex)

# get rid of ENSG id
logCPM_subset <- logCPM_subset[, -1]

# rename column before next join

colnames(logCPM_subset)[1] <- "Gene"

# add isoform_number to prevent NA

logCPM_subset <- add_column(logCPM_subset, "isoform_number" = 1)

# combine logCPM and PSI values
tibble_combinedexpr_logCPM_PSI_unscaled <- dplyr::bind_rows(PSI_levels_timeseries_OB_wide %>% as_tibble %>% dplyr::mutate_if(is.factor, as.character), logCPM_subset) 

```

## consensus re-clustering of combined expression and PSI data

```{r}

# SET THESE TWO. script will sweep using the "dot product" of the two ranges.
xdim_range_combinedexpr <- c(3, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 7)
ydim_range_combinedexpr <- c(8, 9, 10, 11, 6, 7, 8, 5, 6, 7, 4, 5, 4)

som_seed_number <- 7

# OB series #####

tibble_combinedexpr_logCPM_PSI_scaled <- tibble_combinedexpr_logCPM_PSI_unscaled

tibble_combinedexpr_logCPM_PSI_scaled[, 6:ncol(tibble_combinedexpr_logCPM_PSI_scaled)] <- tibble_combinedexpr_logCPM_PSI_unscaled[, 6:ncol(tibble_combinedexpr_logCPM_PSI_unscaled)] %>% genescale(m = ., axis = 1, method = "Z")

# LAST TIME ENSEMBL CHANGED HALFWAY THRU THE ANALYSIS. IM NOT REPEATING THAT MISTAKE AGAIN

write.table(tibble_combinedexpr_logCPM_PSI_scaled, paste(R_processing_results_dir, "tibble_combinedexpr_logCPM_PSI_scaled_GRCh38.98.txt", sep = ""), sep = "\t", row.names = FALSE, quote = FALSE, col.names = TRUE)

tibble_combinedexpr_logCPM_PSI_scaled <- read_delim(paste(R_processing_results_dir, "tibble_combinedexpr_logCPM_PSI_scaled_GRCh38.98.txt", sep = ""), delim = "\t")

set.seed(som_seed_number)

wide_table_combinedexpr_som_sweep_clusters <- purrr::map2(.x = xdim_range_combinedexpr, .y = ydim_range_combinedexpr, .f = ~som(tibble_combinedexpr_logCPM_PSI_scaled[, 6:ncol(tibble_combinedexpr_logCPM_PSI_scaled)] %>% as.matrix, grid = somgrid(xdim = .x, ydim = .y, topo = "rectangular", toroidal = FALSE), rlen = 100, keep.data = TRUE, dist.fcts = "sumofsquares") %>% .[["unit.classif"]] %>% tibble::enframe(., name = NULL)) %>% purrr::reduce(bind_cols)

wide_table_combinedexpr_som_sweep_clusters <- wide_table_combinedexpr_som_sweep_clusters %>% as.data.frame

rownames(wide_table_combinedexpr_som_sweep_clusters) <- paste(tibble_combinedexpr_logCPM_PSI_scaled$Gene, "_", tibble_combinedexpr_logCPM_PSI_scaled$sub_LSV_ID, sep = "")


list_matchtest_combinedexpr_som_sweep_byisoform <- purrr::map(wide_table_combinedexpr_som_sweep_clusters %>% array_tree, ~unlist(.x)) %>% purrr::map(.f = ~apply(X = wide_table_combinedexpr_som_sweep_clusters, MARGIN = 1, FUN = function(X){.x == X}))

list_percentage_consensus_byisoform_combinedexpr <- purrr::map(list_matchtest_combinedexpr_som_sweep_byisoform, ~apply(X = .x, MARGIN = 2, FUN = function(X){sum(X)/length(X)}) %>% t(.) %>% as_tibble)

# tibble_consensus_matrix_combinedexpr <- purrr::reduce(list_percentage_consensus_byisoform_combinedexpr, bind_rows)

tibble_consensus_matrix_combinedexpr <- list_percentage_consensus_byisoform_combinedexpr %>% rbindlist

matrix_consensus_matrix_combinedexpr <- tibble_consensus_matrix_combinedexpr %>% as.matrix

rownames(matrix_consensus_matrix_combinedexpr) <- names(list_percentage_consensus_byisoform_combinedexpr)

## HOOOOOOOLY SHIT RBINDLIST IS SO QUICK ##########
# WE DONT EVEN NEED THIS
# write.table(tibble_consensus_matrix_combinedexpr, paste(R_processing_results_dir, "tibble_consensus_matrix_combinedexpr.txt", sep = ""), sep = "\t", row.names = TRUE, quote = FALSE, col.names = TRUE)



# reorder rows of consensus matrix

matrix_consensus_matrix_combinedexpr_dist_result <- matrix_consensus_matrix_combinedexpr %>% Rfast::Dist(method = "euclidean") %>% as.dist
matrix_consensus_matrix_combinedexpr_hclust_result <- fastcluster::hclust(matrix_consensus_matrix_combinedexpr_dist_result, method = "ward.D2")
matrix_consensus_matrix_combinedexpr_consensus_dendrogram <- as.dendrogram(matrix_consensus_matrix_combinedexpr_hclust_result)
# cols/rows should get darker as you move right/down
matrix_consensus_matrix_combinedexpr_rowmeans <- rowMeans(matrix_consensus_matrix_combinedexpr, na.rm = T)
# matrix_consensus_matrix_combinedexpr_PCA_loadings_byrow <- prcomp(matrix_consensus_matrix_combinedexpr) %>% .[["rotation"]] %>% .[, 1]
# matrix_consensus_matrix_combinedexpr_singular_vectors_byrow <- apply(matrix_consensus_matrix_combinedexpr, 1 , FUN = function(X) {svd(X) %>% .$d})

matrix_consensus_matrix_combinedexpr_consensus_dendrogram_reordered <- reorder(matrix_consensus_matrix_combinedexpr_consensus_dendrogram, matrix_consensus_matrix_combinedexpr_rowmeans)

ggdendrogram(matrix_consensus_matrix_combinedexpr_consensus_dendrogram_reordered) +
  xlab("Gene/isoform") +
  theme(axis.text.x = element_text(size = 2), axis.title.x = element_text(margin = margin(r = 300)), text = element_text(family = "Helvetica")) +
  ggsave(filename = paste(R_processing_results_dir, "dendrogram_som_consensus_matrix_", nrow(PSI_levels_timeseries_OB_wide), "_junctions_any_", p_or_q_value, qpvalue_cutoff, "_dPSI_greaterthan_", dPSI_cutoff, "_sweep_from_", min(xdim_range_combinedexpr), "x", min(ydim_range_combinedexpr), "_to_", max(xdim_range_combinedexpr), "x", max(ydim_range_combinedexpr), ".pdf", sep = ""), device = "pdf", dpi = 600, width = 200, height = 150, units = "cm", limitsize = FALSE)

matrix_consensus_matrix_combinedexpr_consensus_dendrogram_reordered_order <- matrix_consensus_matrix_combinedexpr_consensus_dendrogram_reordered %>% unlist

matrix_consensus_matrix_combinedexpr_reordered <- matrix_consensus_matrix_combinedexpr[matrix_consensus_matrix_combinedexpr_consensus_dendrogram_reordered_order, matrix_consensus_matrix_combinedexpr_consensus_dendrogram_reordered_order] %>% as_tibble(rownames = "gene_isoform_ID")

tibble_consensus_matrix_combinedexpr_long <- reshape2::melt(matrix_consensus_matrix_combinedexpr_reordered, id = c("gene_isoform_ID"), value.name = "cocluster_percentage") %>% type_convert %>% as_tibble %>% mutate_if(is.factor, as.character)

write.table(x = matrix_consensus_matrix_combinedexpr_reordered, file = paste(R_processing_results_dir, "heatmap_som_consensus_matrix_combinedexpr_", nrow(PSI_levels_timeseries_OB_wide), "_junctions_any_", p_or_q_value, qpvalue_cutoff, "_dPSI_greaterthan_", dPSI_cutoff, "_sweep_from_", min(xdim_range_combinedexpr), "x", min(ydim_range_combinedexpr), "_to_", max(xdim_range_combinedexpr), "x", max(ydim_range_combinedexpr), ".txt", sep = ""), sep = "\t", row.names = FALSE, quote = FALSE)

ggplot(tibble_consensus_matrix_combinedexpr_long, aes(fill = cocluster_percentage)) +
  geom_tile(aes(x = gene_isoform_ID, y = variable)) +
  ggtitle(paste("OBseries consensus matrix for som of ", nrow(PSI_levels_timeseries_OB_wide), " isoforms, 
                ", nrow(logCPM_RBP), " RBPs, ", nrow(logCPM_lncRNA), " lncRNAs, ", nrow(logCPM_snRNA), " snRNAs, ", nrow(logCPM_TFcomplex), " TFcomplexes", " 
                (any ", p_or_q_value, qpvalue_cutoff, " dPSI greaterthan ", dPSI_cutoff, "), sweep from ", min(xdim_range_combinedexpr), "x", min(ydim_range_combinedexpr), " to ", max(xdim_range_combinedexpr), "x", max(ydim_range_combinedexpr), sep = "")) +
  scale_x_discrete(breaks = matrix_consensus_matrix_combinedexpr_reordered$gene_isoform_ID, labels = matrix_consensus_matrix_combinedexpr_reordered$gene_isoform_ID, limits = matrix_consensus_matrix_combinedexpr_reordered$gene_isoform_ID) +
  scale_y_discrete(breaks = matrix_consensus_matrix_combinedexpr_reordered$gene_isoform_ID, labels = matrix_consensus_matrix_combinedexpr_reordered$gene_isoform_ID, limits = matrix_consensus_matrix_combinedexpr_reordered$gene_isoform_ID) +
  scale_fill_gradientn(colours = c("blue", "white", "yellow", "red", "black"), values = c(0, 0.25, 0.5, 0.75, 1)) + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 0.25, lineheight = 0.75, colour = "black"), legend.title.align = 0.5, axis.text.y = element_text(size = 0.25, lineheight = 0.75, colour = "black"), axis.title.x = element_text(margin = margin(r = 300)), axis.title.y = element_text(margin = margin(r = 50)), text = element_text(family = "Helvetica")) +
  ggsave(filename = paste(R_processing_results_dir, "heatmap_som_consensus_matrix_combinedexpr_", nrow(PSI_levels_timeseries_OB_wide), "_junctions_any_", p_or_q_value, qpvalue_cutoff, "_dPSI_greaterthan_", dPSI_cutoff, "_sweep_from_", min(xdim_range_combinedexpr), "x", min(ydim_range_combinedexpr), "_to_", max(xdim_range_combinedexpr), "x", max(ydim_range_combinedexpr), ".tiff", sep = ""), device = "tiff", dpi = 1200, width = 40, height = 25, units = "cm", limitsize = FALSE)

write.table(x = tibble_consensus_matrix_combinedexpr_long, file = paste(R_processing_results_dir, "heatmap_som_consensus_matrix_combinedexpr_", nrow(PSI_levels_timeseries_OB_wide), "_junctions_any_", p_or_q_value, qpvalue_cutoff, "_dPSI_greaterthan_", dPSI_cutoff, "_sweep_from_", min(xdim_range_combinedexpr), "x", min(ydim_range_combinedexpr), "_to_", max(xdim_range_combinedexpr), "x", max(ydim_range_combinedexpr), "_long.txt", sep = ""), sep = "\t", row.names = FALSE, quote = FALSE)

ggplot(tibble_consensus_matrix_combinedexpr_long[1, ], aes(fill = cocluster_percentage)) +
  geom_tile(aes(x = gene_isoform_ID, y = variable)) +
  ggtitle(paste("OBseries consensus matrix for som of ", nrow(PSI_levels_timeseries_OB_wide), " isoforms, ", nrow(logCPM_RBP), " RBPs, ", nrow(logCPM_lncRNA), " lncRNAs, ", nrow(logCPM_snRNA), " snRNAs, ", nrow(logCPM_TFcomplex), " TFcomplexs", " (any ", p_or_q_value, qpvalue_cutoff, " dPSI greaterthan ", dPSI_cutoff, "), sweep from ", min(xdim_range_combinedexpr), "x", min(ydim_range_combinedexpr), " to ", max(xdim_range_combinedexpr), "x", max(ydim_range_combinedexpr), sep = "")) +
  scale_x_discrete(breaks = matrix_consensus_matrix_combinedexpr_reordered$gene_isoform_ID, labels = matrix_consensus_matrix_combinedexpr_reordered$gene_isoform_ID, limits = matrix_consensus_matrix_combinedexpr_reordered$gene_isoform_ID) +
  scale_fill_gradientn(colours = c("white", "yellow", "red", "black"), values = c(0, 0.33, 0.67, 1)) + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 1, lineheight = 0.75, colour = "black"), legend.title.align = 0.5, axis.text.y = element_text(size = 1, lineheight = 0.75, colour = "black"), axis.title.x = element_text(margin = margin(r = 300)), axis.title.y = element_text(margin = margin(r = 300)), text = element_text(family = "Helvetica")) +
  ggsave(filename = paste(R_processing_results_dir, "xlabs_som_consensus_matrix_combinedexpr_", nrow(PSI_levels_timeseries_OB_wide), "_junctions_any_", p_or_q_value, qpvalue_cutoff, "_dPSI_greaterthan_", dPSI_cutoff, "_sweep_from_", min(xdim_range_combinedexpr), "x", min(ydim_range_combinedexpr), "_to_", max(xdim_range_combinedexpr), "x", max(ydim_range_combinedexpr), ".pdf", sep = ""), device = "pdf", dpi = 400, width = 200, height = 10, units = "cm", limitsize = FALSE)

```

som_cluster determination from consensus matrix

```{r message=FALSE, warning=FALSE}

tibble_consensus_matrix_combinedexpr_long <- read_delim(paste(R_processing_results_dir, "heatmap_som_consensus_matrix_combinedexpr_", nrow(PSI_levels_timeseries_OB_wide), "_junctions_any_", p_or_q_value, qpvalue_cutoff, "_dPSI_greaterthan_", dPSI_cutoff, "_sweep_from_", min(xdim_range_combinedexpr), "x", min(ydim_range_combinedexpr), "_to_", max(xdim_range_combinedexpr), "x", max(ydim_range_combinedexpr), "_long.txt", sep = ""), delim = "\t")

list_genes_or_isoforms_from_combinedexpr <- tibble_consensus_matrix_combinedexpr_long$variable %>% unique %>% array_tree

# testing purposes only 

# list_genes_or_isoforms_from_combinedexpr <- list_genes_or_isoforms_from_combinedexpr[c(1:50, 1000:1050)]

list_genes_or_isoforms_from_combinedexpr_cooccuring <- purrr::map(.x = list_genes_or_isoforms_from_combinedexpr, .f = ~tibble_consensus_matrix_combinedexpr_long[tibble_consensus_matrix_combinedexpr_long$variable == .x & tibble_consensus_matrix_combinedexpr_long$cocluster_percentage >= 0.5, "gene_isoform_ID"])

names(list_genes_or_isoforms_from_combinedexpr_cooccuring) <- list_genes_or_isoforms_from_combinedexpr

# take pairwise intersections

comparisons_genes_or_isoforms_from_combinedexpr <- combn(list_genes_or_isoforms_from_combinedexpr %>% unlist, m = 2) %>% t %>% as_tibble

colnames(comparisons_genes_or_isoforms_from_combinedexpr) <- c("comparison_1", "comparison_2")

# each level 1 element is a comparison of each pairwise intersection

list_comparison_1 <- comparisons_genes_or_isoforms_from_combinedexpr %>% .[, 1] %>% array_tree %>% flatten

list_comparison_2 <- comparisons_genes_or_isoforms_from_combinedexpr %>% .[, 2] %>% array_tree %>% flatten

# NOTE: EACH L1 ELEMENT OF THE LIST MUST BE A TIBBLE. IF IT ISN'T THE WHOLE THING IS STUFFED.

list_genes_or_isoforms_from_combinedexpr_itemwise_intersection <- purrr::map2(.x = list_comparison_1, .y = list_comparison_2, .f = ~dplyr::intersect(list_genes_or_isoforms_from_combinedexpr_cooccuring[[.x]], list_genes_or_isoforms_from_combinedexpr_cooccuring[[.y]]) %>% nrow) %>% unlist %>% as.data.frame %>% as_tibble %>% setNames("coclustering_intersection")

list_genes_or_isoforms_from_combinedexpr_itemwise_setdiff <- purrr::map2(.x = list_comparison_1, .y = list_comparison_2, .f = ~dplyr::setdiff(list_genes_or_isoforms_from_combinedexpr_cooccuring[[.x]], list_genes_or_isoforms_from_combinedexpr_cooccuring[[.y]]) %>% nrow)  %>% unlist %>% as.data.frame %>% as_tibble %>% setNames("coclustering_setdiff")

list_genes_or_isoforms_from_combinedexpr_itemwise_intersection_2 <- bind_cols(comparisons_genes_or_isoforms_from_combinedexpr %>% as_tibble, list_genes_or_isoforms_from_combinedexpr_itemwise_intersection[, 1], list_genes_or_isoforms_from_combinedexpr_itemwise_setdiff[, 1])

list_genes_or_isoforms_from_combinedexpr_itemwise_intersection_2 <- add_column(list_genes_or_isoforms_from_combinedexpr_itemwise_intersection_2, "jaccard" = list_genes_or_isoforms_from_combinedexpr_itemwise_intersection_2$coclustering_intersection/(list_genes_or_isoforms_from_combinedexpr_itemwise_intersection_2$coclustering_setdiff + list_genes_or_isoforms_from_combinedexpr_itemwise_intersection_2$coclustering_intersection))

write.table(x = list_genes_or_isoforms_from_combinedexpr_itemwise_intersection_2, file = paste(R_processing_results_dir, "list_genes_or_isoforms_from_combinedexpr_itemwise_anyintersection_consensus0.5.txt", sep = ""), sep = "\t", row.names = FALSE, quote = FALSE)

list_genes_or_isoforms_from_combinedexpr_itemwise_intersection_2 <- read_delim(paste(R_processing_results_dir, "list_genes_or_isoforms_from_combinedexpr_itemwise_anyintersection_consensus0.5.txt", sep = ""), delim = "\t")


list_genes_or_isoforms_from_combinedexpr_itemwise_intersection_3 <- list_genes_or_isoforms_from_combinedexpr_itemwise_intersection_2[list_genes_or_isoforms_from_combinedexpr_itemwise_intersection_2$coclustering_intersection > 0, ]

plot(density(list_genes_or_isoforms_from_combinedexpr_itemwise_intersection_3$coclustering_intersection %>% as.numeric))

write.table(x = list_genes_or_isoforms_from_combinedexpr_itemwise_intersection_3, file = paste(R_processing_results_dir, "list_genes_or_isoforms_from_combinedexpr_itemwise_intersection1_consensus0.5.txt", sep = ""), sep = "\t", row.names = FALSE, quote = FALSE)

```

### GO TO CYTOSCAPE HERE

```{r}

########### GO TO CYTOSCAPE HERE ###################

tibble_combinedexpr_logCPM_PSI_scaled_2 <- bind_cols(tibble_combinedexpr_logCPM_PSI_scaled, gene_isoform_ID = paste(tibble_combinedexpr_logCPM_PSI_scaled$Gene, "_", tibble_combinedexpr_logCPM_PSI_scaled$sub_LSV_ID, sep = ""))

cytoscape_result <- read_delim(paste(R_processing_results_dir, "consensus_combinedexpr_intersection1_min25_penalty2_haircut0.1_multi_match_overlap0.8_seedeverynode.tab", sep = ""), delim = "\t", col_names = c("som_cluster", "gene_isoform_ID"))

cytoscape_result[, "som_cluster"] <- gsub(x = cytoscape_result$som_cluster, pattern = "som_cluster ", replacement = "") %>% as.numeric

# split the cytoscape som_cluster result into a list, clusterwise
list_cytoscape_cluster_results <- purrr::map(.x = cytoscape_result$som_cluster %>% unique, .f = ~cytoscape_result[cytoscape_result$som_cluster == .x, ])

# bind the standardised PSI information to the som_cluster information
list_combinedexpr_logCPM_PSI_scaled_clustered <- purrr::map(.x = list_cytoscape_cluster_results, .f = ~dplyr::left_join(.x, tibble_combinedexpr_logCPM_PSI_scaled_2, by = "gene_isoform_ID"))

wide_table_combinedexpr_logCPM_PSI_scaled_clustered <- list_combinedexpr_logCPM_PSI_scaled_clustered %>% purrr::reduce(dplyr::bind_rows)

# reorder columns
wide_table_combinedexpr_logCPM_PSI_scaled_clustered <- wide_table_combinedexpr_logCPM_PSI_scaled_clustered[, c("Gene", "AS_event_ID", "splicemode", "isoform_number", "sub_LSV_ID", "gene_isoform_ID", "MSC", "6h", "12h", "1d", "3d", "6d", "9d", "12d", "som_cluster")]

```

### generate expression profile map

the goal of this is to get extract timepoint PSI tables according to each consensus som_cluster

```{r}

# reorder the som_cluster factor for correct facet order

wide_table_combinedexpr_logCPM_PSI_scaled_clustered$som_cluster <- factor(wide_table_combinedexpr_logCPM_PSI_scaled_clustered$som_cluster %>% mixedsort, levels = wide_table_combinedexpr_logCPM_PSI_scaled_clustered$som_cluster %>% unique %>% mixedsort)

### convert the som table to a long form interprable by ggplot

# reshaping into long table

long_table_combinedexpr_logCPM_PSI_scaled_clustered <- reshape2::melt(wide_table_combinedexpr_logCPM_PSI_scaled_clustered, id.vars = c("Gene", "AS_event_ID", "splicemode", "sub_LSV_ID", "gene_isoform_ID", "som_cluster", "isoform_number"), variable.name = "timepoint", value.name = "scaled_psi_value") %>% as_tibble

# ggplot of consensus som PSI profiles

ggplot(long_table_combinedexpr_logCPM_PSI_scaled_clustered, aes(x = timepoint, y = scaled_psi_value)) +
  geom_line(aes(group = gene_isoform_ID)) +
  scale_colour_manual(values = c("black")) +
  facet_wrap(~som_cluster) +
  ggtitle(paste("Time series profiles of ", nrow(PSI_levels_timeseries_OB_wide), " isoforms, ", nrow(logCPM_RBP), " RBPs, ", nrow(logCPM_lncRNA), " lncRNAs, ", nrow(logCPM_snRNA), " snRNAs, ", nrow(logCPM_TFcomplex), " TFcomplexes", " (any ", p_or_q_value, qpvalue_cutoff, " dPSI greaterthan ", dPSI_cutoff, "), 
                sweep from ", min(xdim_range_combinedexpr), "x", min(ydim_range_combinedexpr), " to ", max(xdim_range_combinedexpr), "x", max(ydim_range_combinedexpr), sep = "")) +
  scale_x_discrete(limits = vector_OBseries_timepoints_edited, labels = vector_OBseries_timepoints_edited) +
  xlab("Time-point") +
  ylab("Scaled PSI or logCPM Level") +
  # guides(colour = FALSE) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.background = element_rect(size = 0.5, linetype ="solid", colour = "black"), text = element_text(family = "Helvetica")) +
  ggsave(filename = paste(R_processing_results_dir, "som_consensus_matrix_combinedexpr_", nrow(PSI_levels_timeseries_OB_wide), "_junctions_any_", p_or_q_value, qpvalue_cutoff, "_dPSI_greaterthan_", dPSI_cutoff, "_sweep_from_", min(xdim_range_combinedexpr), "x", min(ydim_range_combinedexpr), "_to_", max(xdim_range_combinedexpr), "x", max(ydim_range_combinedexpr), ".pdf", sep = ""), device = "pdf", dpi = 600, width = 33, height = 20, units = "cm") +
  ggsave(filename = paste(R_processing_results_dir, "som_consensus_matrix_combinedexpr_", nrow(PSI_levels_timeseries_OB_wide), "_junctions_any_", p_or_q_value, qpvalue_cutoff, "_dPSI_greaterthan_", dPSI_cutoff, "_sweep_from_", min(xdim_range_combinedexpr), "x", min(ydim_range_combinedexpr), "_to_", max(xdim_range_combinedexpr), "x", max(ydim_range_combinedexpr), ".svg", sep = ""), device = "svg", dpi = 600, width = 33, height = 20, units = "cm")

write.table(x = wide_table_combinedexpr_logCPM_PSI_scaled_clustered, file = paste(R_processing_results_dir, "som_consensus_matrix_combinedexpr_", nrow(PSI_levels_timeseries_OB_wide), "_junctions_any_", p_or_q_value, qpvalue_cutoff, "_dPSI_greaterthan_", dPSI_cutoff, "_sweep_from_", min(xdim_range_combinedexpr), "x", min(ydim_range_combinedexpr), "_to_", max(xdim_range_combinedexpr), "x", max(ydim_range_combinedexpr), ".txt", sep = ""), sep = "\t", row.names = FALSE, quote = FALSE)

```

#### GO term, family and RBP target enrichment

##### GO term

```{r}

# OB series #####

list_of_timeseries_logCPM_PSI_genes_by_consensus_cluster_all <- purrr::map(.x = list_combinedexpr_logCPM_PSI_scaled_clustered
                                                                           , .f = ~.x$Gene %>% as.vector %>% unique)

list_of_timeseries_logCPM_PSI_genes_by_consensus_cluster_diffsplicedonly <- purrr::map(.x = list_combinedexpr_logCPM_PSI_scaled_clustered
                                                                                       , .f = ~.x[.x$splicemode != "RNASeq", "Gene"] %>% unlist %>% as.vector %>% unique)

number_of_consensus_combinedexpr_clusters <- wide_table_combinedexpr_logCPM_PSI_scaled_clustered$som_cluster %>% unique %>% length

# let's try to do all enrichment at once using purrr

list_of_combinations_of_consensus_combinedexpr_genes_and_GOterms <- cross2(.x = list_of_timeseries_logCPM_PSI_genes_by_consensus_cluster_diffsplicedonly, .y = list("MF", "BP", "CC"))

# note: each element will be [[1]]: gene set, [[2]]: GO term to query

list_of_consensus_combinedexpr_hyperGOresult_allGO_clusterwise_tables <- purrr::map(.x = list_of_combinations_of_consensus_combinedexpr_genes_and_GOterms, .f = ~GOHyperGAll(catdb = catdb, gocat = .x[[2]], Nannot = 2, sample = .x[[1]]) %>% GOHyperGAll_benjamini_correction)

list_of_consensus_combinedexpr_hyperGOresult_allGO_clusterwise_tables_topten <- purrr::map(.x = list_of_consensus_combinedexpr_hyperGOresult_allGO_clusterwise_tables, ~.[order(.$Padj, decreasing = FALSE), ] %>% head(n = 10))

list_of_consensus_combinedexpr_hyperGOresult_allGO_clusterwise_tables_topten <- purrr::map2(.x = list_of_consensus_combinedexpr_hyperGOresult_allGO_clusterwise_tables_topten, .y = 1:number_of_consensus_combinedexpr_clusters %>% rep(., times = 3) %>% as.list, .f = ~cbind(.x, "som_cluster" = .y) %>% as_tibble)

list_of_consensus_combinedexpr_hyperGOresult_allGO_clusterwise_tables_topten_2 <- list(
  "MF" = list_of_consensus_combinedexpr_hyperGOresult_allGO_clusterwise_tables_topten[1:number_of_consensus_combinedexpr_clusters] %>% purrr::reduce(bind_rows), 
  "BP" = list_of_consensus_combinedexpr_hyperGOresult_allGO_clusterwise_tables_topten[(number_of_consensus_combinedexpr_clusters + 1):(number_of_consensus_combinedexpr_clusters*2)] %>% purrr::reduce(bind_rows),
  "CC" = list_of_consensus_combinedexpr_hyperGOresult_allGO_clusterwise_tables_topten[((2*number_of_consensus_combinedexpr_clusters) + 1):(number_of_consensus_combinedexpr_clusters*3)] %>% purrr::reduce(bind_rows)) %>% purrr::map(~type_convert(.x))

# cheeky ggplot

purrr::map2(.x = list_of_consensus_combinedexpr_hyperGOresult_allGO_clusterwise_tables_topten_2, .y = names(list_of_consensus_combinedexpr_hyperGOresult_allGO_clusterwise_tables_topten_2), .f = ~ggplot(.x, aes(x = reorder(Term, -SampleMatch), y = SampleMatch)) +
              geom_col(aes(fill = log10(Padj))) +
              scale_fill_distiller(name = expression(log["10"](P)), type = "seq", palette = "Purples", direction = -1,   aesthetics = "fill", na.value = "yellow") +
              facet_wrap(~som_cluster, scales = "free") +
              ggtitle(paste("Top 10 significantly over-represented", .y, "GO terms for each consensus som_cluster of PSI and select gene expression combined")) +
              scale_x_discrete(labels = function(x) str_wrap(x, width = 35)) +
              xlab("GO term") +
              ylab("Number of genes in GO term") +
              # coord_cartesian(ylim = c(0, 20)) +
              theme_bw() +
              theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 5, lineheight = 0.75, colour = "black"), legend.title.align = 0.5, legend.background = element_rect(size=0.5, linetype="solid", colour ="black"), strip.background = element_blank(), strip.text.x = element_blank(), axis.title.y = element_text(margin = margin(r = 20)), text = element_text(family="Helvetica")) +
              ggsave(filename = paste(R_processing_results_dir, "som_consensus_matrix_combinedexpr_", number_of_consensus_combinedexpr_clusters, "_clusters_",  nrow(PSI_levels_timeseries_OB_wide), "_junctions_any_", p_or_q_value, qpvalue_cutoff, "_dPSI_greaterthan_", dPSI_cutoff, "_sweep_from_", min(xdim_range_combinedexpr), "x", min(ydim_range_combinedexpr), "_to_", max(xdim_range_combinedexpr), "x", max(ydim_range_combinedexpr), "_", .y, "_GO.pdf", sep = ""), device = "pdf", dpi = 600, width = 50, height = 30, units = "cm") +
              ggsave(filename = paste(R_processing_results_dir, "som_consensus_matrix_combinedexpr_", number_of_consensus_combinedexpr_clusters, "_clusters_",  nrow(PSI_levels_timeseries_OB_wide), "_junctions_any_", p_or_q_value, qpvalue_cutoff, "_dPSI_greaterthan_", dPSI_cutoff, "_sweep_from_", min(xdim_range_combinedexpr), "x", min(ydim_range_combinedexpr), "_to_", max(xdim_range_combinedexpr), "x", max(ydim_range_combinedexpr), "_", .y, "_GO.svg", sep = ""), device = "svg", dpi = 600, width = 50, height = 30, units = "cm"))

purrr::map2(.x = list_of_consensus_combinedexpr_hyperGOresult_allGO_clusterwise_tables_topten_2, .y = names(list_of_consensus_combinedexpr_hyperGOresult_allGO_clusterwise_tables_topten_2), .f = ~write.table(x = .x, file = paste(R_processing_results_dir, "som_consensus_matrix_combinedexpr_", number_of_consensus_combinedexpr_clusters, "_clusters_",  nrow(PSI_levels_timeseries_OB_wide), "_junctions_any_", p_or_q_value, qpvalue_cutoff, "_dPSI_greaterthan_", dPSI_cutoff, "_sweep_from_", min(xdim_range_combinedexpr), "x", min(ydim_range_combinedexpr), "_to_", max(xdim_range_combinedexpr), "x", max(ydim_range_combinedexpr), "_", .y, "_GO.txt", sep = ""), sep = "\t", row.names = FALSE, quote = FALSE))

```

##### family enrichment

```{r}

list_of_consensus_combinedexpr_familyenrichment_clusterwise_tables <- purrr::map(.x = list_of_timeseries_logCPM_PSI_genes_by_consensus_cluster_diffsplicedonly, .f = ~enrichment(genes = .x, reference = reference_geneset, genesets = list_of_pfam_gene_family_categories, adj = "BH", verbose = FALSE) %>% bc3net_benjamini_correction %>% cbind(., genes_contained = filtering_genehits_from_background_catalogue(list_of_pfam_gene_family_categories[.$TermID %>% as.character], .x) %>% lapply(toString) %>% paste(sep = ", ") %>% unlist) %>% type_convert %>% as_tibble)

names(list_of_consensus_combinedexpr_familyenrichment_clusterwise_tables) <- 1:number_of_consensus_combinedexpr_clusters

list_of_consensus_combinedexpr_familyenrichment_clusterwise_tables_topten <- purrr::map2(.x = list_of_consensus_combinedexpr_familyenrichment_clusterwise_tables, .y = 1:number_of_consensus_combinedexpr_clusters, .f = ~.x[order(.x$padj, decreasing = FALSE), ] %>% head(n = 10) %>% cbind(., som_cluster = .y) %>% as_tibble)

# bind rows and calculate ggplot facet x and y coordinates
wide_table_of_consensus_combinedexpr_familyenrichment_clusterwise_tables_topten <- purrr::reduce(.x = list_of_consensus_combinedexpr_familyenrichment_clusterwise_tables_topten, .f = bind_rows) %>% type_convert

# ggplot

ggplot(wide_table_of_consensus_combinedexpr_familyenrichment_clusterwise_tables_topten, aes(x = reorder(TermID, padj), y = genes)) +
  geom_col(aes(fill = log10(padj))) +
  scale_fill_distiller(name = expression(log["10"](P["b-hoch"])), type = "seq", palette = "Purples", direction = -1,   aesthetics = "fill", na.value = "yellow") +
  facet_wrap(~som_cluster, scales = "free") +
  ggtitle(paste("Top 10 significantly over-represented PFAM families for each consensus som_cluster of PSI and select gene expression combined")) +
  scale_x_discrete(labels = function(x) str_wrap(x, width = 35)) +
  xlab("PFAM family") +
  ylab("Number of genes in family and in som_cluster") +
  # coord_cartesian(ylim = c(0, 20)) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 5, lineheight = 0.75, colour = "black"), legend.title.align = 0.5, legend.background = element_rect(size=0.5, linetype="solid", colour ="black"), strip.background = element_blank(), strip.text.x = element_blank(), axis.title.y = element_text(margin = margin(r = 20)), text = element_text(family="Helvetica")) +
  ggsave(filename = paste(R_processing_results_dir, "som_consensus_matrix_combinedexpr_", number_of_consensus_combinedexpr_clusters, "_clusters_",  nrow(PSI_levels_timeseries_OB_wide), "_junctions_any_", p_or_q_value, qpvalue_cutoff, "_dPSI_greaterthan_", dPSI_cutoff, "_sweep_from_", min(xdim_range_combinedexpr), "x", min(ydim_range_combinedexpr), "_to_", max(xdim_range_combinedexpr), "x", max(ydim_range_combinedexpr), "_families.pdf", sep = ""), device = "pdf", dpi = 600, width = 50, height = 30, units = "cm") +
  ggsave(filename = paste(R_processing_results_dir, "som_consensus_matrix_combinedexpr_", number_of_consensus_combinedexpr_clusters, "_clusters_",  nrow(PSI_levels_timeseries_OB_wide), "_junctions_any_", p_or_q_value, qpvalue_cutoff, "_dPSI_greaterthan_", dPSI_cutoff, "_sweep_from_", min(xdim_range_combinedexpr), "x", min(ydim_range_combinedexpr), "_to_", max(xdim_range_combinedexpr), "x", max(ydim_range_combinedexpr), "_families.svg", sep = ""), device = "svg", dpi = 600, width = 50, height = 30, units = "cm")

write.table(x = wide_table_of_consensus_combinedexpr_familyenrichment_clusterwise_tables_topten, file = paste(R_processing_results_dir, "som_consensus_matrix_combinedexpr_", number_of_consensus_combinedexpr_clusters, "_clusters_",  nrow(PSI_levels_timeseries_OB_wide), "_junctions_any_", p_or_q_value, qpvalue_cutoff, "_dPSI_greaterthan_", dPSI_cutoff, "_sweep_from_", min(xdim_range_combinedexpr), "x", min(ydim_range_combinedexpr), "_to_", max(xdim_range_combinedexpr), "x", max(ydim_range_combinedexpr), "_families.txt", sep = ""), sep = "\t", row.names = FALSE, quote = FALSE)

```

##### RBP target enrichment

```{r}

list_of_consensus_combinedexpr_RBPenrichment_clusterwise_tables <- purrr::map(.x = list_of_timeseries_logCPM_PSI_genes_by_consensus_cluster_diffsplicedonly, .f = ~enrichment(genes = .x, reference = reference_geneset, genesets = list_of_RBP_target_gene_categories, adj = "BH", verbose = FALSE) %>% bc3net_benjamini_correction %>% cbind(., genes_contained = filtering_genehits_from_background_catalogue(list_of_RBP_target_gene_categories[.$TermID %>% as.character], .x) %>% lapply(toString) %>% paste(sep = ", ") %>% unlist) %>% type_convert %>% as_tibble)

names(list_of_consensus_combinedexpr_RBPenrichment_clusterwise_tables) <- 1:number_of_consensus_combinedexpr_clusters

list_of_consensus_combinedexpr_RBPenrichment_clusterwise_tables_topten <- purrr::map2(.x = list_of_consensus_combinedexpr_RBPenrichment_clusterwise_tables, .y = 1:number_of_consensus_combinedexpr_clusters, .f = ~.x[order(.x$padj, decreasing = FALSE), ] %>% head(n = 10) %>% cbind(., som_cluster = .y) %>% as_tibble)

# bind rows and calculate ggplot facet x and y coordinates
wide_table_of_consensus_combinedexpr_RBPenrichment_clusterwise_tables_topten <- purrr::reduce(.x = list_of_consensus_combinedexpr_RBPenrichment_clusterwise_tables_topten, .f = bind_rows) %>% type_convert

# ggplot

ggplot(wide_table_of_consensus_combinedexpr_RBPenrichment_clusterwise_tables_topten, aes(x = reorder(TermID, pval), y = genes)) +
  geom_col(aes(fill = log10(padj))) +
  scale_fill_distiller(name = expression(log["10"](P["b-hoch"])), type = "seq", palette = "Purples", direction = -1,   aesthetics = "fill", na.value = "yellow") +
  facet_wrap(~som_cluster, scales = "free") +
  ggtitle(paste("Top 10 significantly over-represented upstream RBPs for each CONSENSUS som_cluster in OB series")) +
  scale_x_discrete(labels = function(x) str_wrap(x, width = 3)) +
  xlab("Upstream RBP with literature reference") +
  ylab("Number of genes enriched amongst RBP target genes") +
  # coord_cartesian(ylim = c(0, 20)) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 5, lineheight = 0.75, colour = "black"), legend.title.align = 0.5, legend.background = element_rect(size=0.5, linetype="solid", colour ="black"), axis.title.y = element_text(margin = margin(r = 20)), text = element_text(family="Helvetica")) +
  ggsave(filename = paste(R_processing_results_dir, "som_consensus_matrix_combinedexpr_", number_of_consensus_combinedexpr_clusters, "_clusters_",  nrow(PSI_levels_timeseries_OB_wide), "_junctions_any_", p_or_q_value, qpvalue_cutoff, "_dPSI_greaterthan_", dPSI_cutoff, "_sweep_from_", min(xdim_range_combinedexpr), "x", min(ydim_range_combinedexpr), "_to_", max(xdim_range_combinedexpr), "x", max(ydim_range_combinedexpr), "_upstreamRBP.pdf", sep = ""), device = "pdf", dpi = 600, width = 50, height = 30, units = "cm") +
  ggsave(filename = paste(R_processing_results_dir, "som_consensus_matrix_combinedexpr_", number_of_consensus_combinedexpr_clusters, "_clusters_",  nrow(PSI_levels_timeseries_OB_wide), "_junctions_any_", p_or_q_value, qpvalue_cutoff, "_dPSI_greaterthan_", dPSI_cutoff, "_sweep_from_", min(xdim_range_combinedexpr), "x", min(ydim_range_combinedexpr), "_to_", max(xdim_range_combinedexpr), "x", max(ydim_range_combinedexpr), "_upstreamRBP.svg", sep = ""), device = "svg", dpi = 600, width = 50, height = 30, units = "cm")

write.table(x = wide_table_of_consensus_combinedexpr_RBPenrichment_clusterwise_tables_topten, file = paste(R_processing_results_dir, "som_consensus_matrix_combinedexpr_", number_of_consensus_combinedexpr_clusters, "_clusters_",  nrow(PSI_levels_timeseries_OB_wide), "_junctions_any_", p_or_q_value, qpvalue_cutoff, "_dPSI_greaterthan_", dPSI_cutoff, "_sweep_from_", min(xdim_range_combinedexpr), "x", min(ydim_range_combinedexpr), "_to_", max(xdim_range_combinedexpr), "x", max(ydim_range_combinedexpr), "_upstreamRBP.txt", sep = ""), sep = "\t", row.names = FALSE, quote = FALSE)

```

